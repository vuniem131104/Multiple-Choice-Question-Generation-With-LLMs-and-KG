[
    {
        "topic_description": "Chủ đề này tập trung vào việc phân biệt và hiểu rõ hai loại lỗi trong mô hình học máy: Lỗi thực tế (True Error) và Lỗi thực nghiệm (Empirical Error). Học sinh sẽ được kiểm tra khả năng áp dụng định nghĩa và công thức của chúng, cũng như ví dụ minh họa rõ ràng để nhận biết sự khác biệt giữa lỗi trên dữ liệu huấn luyện và dữ liệu chưa thấy.",
        "output_with_context": {
            "question": "Lỗi thực tế (True Error) và lỗi thực nghiệm (Empirical Error) trong học máy được định nghĩa như thế nào?",
            "answer": "Lỗi thực tế là lỗi trên dữ liệu chưa thấy, trong khi lỗi thực nghiệm là lỗi trên dữ liệu huấn luyện.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n```\n**Dấu hiệu:**\n- Large gap giữa curves\n- Training error tiếp tục giảm\n- Validation error không cải thiện\n\n**Giải pháp:**\n- Get more training data\n- Reduce model complexity\n- Increase regularization\n- Feature selection\n- Dropout, early stopping\n\n**3. Good Fit:**\n```\nTraining error: Thấp\nValidation error: Thấp\nGap: Nhỏ\nBoth converge\n```\n**Dấu hiệu:**\n- Small gap\n- Both errors low\n- Converged performance\n\n**4. More Data Helps:**\n```\nValidation error giảm khi tăng data\nGap đang đóng lại\nChưa plateau\n```\n**Hành động:** Get more data!\n\n**5. More Data Doesn't Help:**\n```\nBoth curves plateau\nAdding data không cải thiện\n```\n**Hành động:** Improve features hoặc model\n\n### Bias-Variance Tradeoff (Sự Đánh Đổi Bias-Variance)\n\n**Công thức:**\n$$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$\n\n**Bias (Thiên Lệch):**\n- Error từ giả định đơn giản hóa\n- Underfitting\n- Model không capture được patterns\n- High bias → Systematic errors\n\n**Variance (Phương Sai):**\n- Error từ sensitivity to training data\n- Overfitting\n- Model learns noise\n- High variance → Different results với different data\n\n**Irreducible Error:**\n- Noise trong data\n- Không thể giảm\n- Comes from data collection\n\n**Tradeoff:**\n- Decrease bias → Increase variance\n- Decrease variance → Increase bias\n- Cần balance\n\n**Strategies:**\n\n**Giảm High Bias:**\n1. Increase model complexity\n2. Add more features/polynomial features\n3. Decrease regularization\n4. Train longer\n5. Use ensemble methods\n\n**Giảm High Variance:**\n1. Get more training data\n2. Reduce model complexity\n3. Increase regularization (L1, L2, dropout)\n4. Feature selection\n5. Early stopping\n6. Ensemble methods (bagging)\n\n**Sweet Spot:**\n- Minimize total error\n- Balance bias và variance\n- Depends on problem và data\n\n**Visualize:**\n```\nTotal Error\n    |     \\\n    |      \\___Bias²\n    |___________\\\n    |            \\___\n    |Variance_____\\___Total\n    |________________\\___\n    |___________________\\___\n    +----------------------->\n    Simple          Complex\n            Model Complexity\n```\n\n### Phương Pháp Ensemble\n\nKết hợp nhiều models để cải thiện hiệu suất.\n\n**\"Wisdom of crowds\"**\n\n**Tại sao hoạt động:**\n- Errors của individual models cancel out\n- Diverse models capture different patterns\n- Reduce variance\n- More robust\n\n**1. Bagging (Bootstrap Aggregating):**\n\n**Nguyên lý:**\n- Train multiple models trên bootstrap samples\n- Average predictions (regression) hoặc vote (classification)\n\n**Bootstrap Sampling:**\n- Sample with replacement\n- Same size as original\n- ~63% unique samples mỗi bootstrap\n\n**Thuật toán:**\n1. For i = 1 to M:\n   - Create bootstrap sample $D_i$\n   - Train model $M_i$ on $D_i$\n2. Combine:\n   - Regression: $\\hat{y} = \frac{1}{M}\\sum_{i=1}^{M}M_i(x)$\n   - Classification: Majority vote\n\n**Ưu điểm:**\n- Reduce variance\n- Parallel training\n- Works với high-variance models\n\n**Nhược điểm:**\n- Không giảm bias\n- Có thể chậm (many models)\n\n**Ví dụ:** Random Forest\n\n**2. Boosting:**\n\n**Nguyên lý:**\n- Sequential training\n- Each model corrects errors của previous models\n- Weighted combination\n\n**Thuật toán (general):**\n1. Initialize equal weights\n2. For i = 1 to M:\n   - Train model $M_i$ on weighted data\n   - Tính error\n   - Update weights (increase for misclassified)\n\n**Các khái niệm quan trọng:**\n- Training error là thước đo hiệu suất của mô hình trên tập dữ liệu huấn luyện, cho biết mô hình học tốt như thế nào trên dữ liệu mà nó đã \"nhìn thấy\" trong quá trình huấn luyện. Giá trị cao cho thấy mô hình chưa học được tốt dữ liệu, trong khi giá trị thấp thường cho thấy mô hình đã học được các mẫu trong dữ liệu huấn luyện. Tuy nhiên, training error thấp không nhất thiết có nghĩa là mô hình sẽ hoạt động tốt trên dữ liệu mới. Khi training error tiếp tục giảm nhưng validation error không cải thiện, đó là dấu hiệu của overfitting.\n- Expected Error là công thức toán học biểu diễn tổng lỗi dự kiến của một mô hình, được định nghĩa là $$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$. Công thức này phân tách tổng lỗi thành ba thành phần: lỗi do thiên lệch (bias), lỗi do phương sai (variance) và lỗi không thể giảm (irreducible error).\n- Variance (Phương sai) là một thành phần của lỗi dự kiến trong học máy, đại diện cho lỗi do sự nhạy cảm của mô hình với các biến động nhỏ hoặc sự thay đổi trong dữ liệu huấn luyện. Nó đề cập đến mức độ mà một mô hình thay đổi khi được huấn luyện trên các tập dữ liệu huấn luyện khác nhau. High variance dẫn đến overfitting, nghĩa là mô hình học cả nhiễu trong dữ liệu huấn luyện, gây ra \"Different results với different data\". Để giảm variance, có thể giảm độ phức tạp của mô hình, tăng regularization, sử dụng nhiều dữ liệu hơn, hoặc giảm số lượng đặc trưng.\n\n**Mối quan hệ:**\n- Model Complexity kiểm soát Variance: tăng độ phức tạp có thể làm tăng Variance (gây overfitting), trong khi giảm độ phức tạp giúp giảm Variance.\n- Underfitting được đặc trưng bởi Training error cao, cho thấy mô hình không học được dữ liệu huấn luyện.\n- Expected Error chứa thành phần Variance, đại diện cho lỗi do sự nhạy cảm của mô hình với dữ liệu huấn luyện.\n- Expected Error chứa thành phần Bias², đại diện cho lỗi do giả định đơn giản hóa của mô hình.\n- Expected Error chứa thành phần Irreducible Error, đại diện cho lỗi không thể giảm được do nhiễu trong dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n- Precision, Recall, F1, AUC\n- Business metrics\n\n**6. Avoid Data Leakage:**\n- **Proper CV:** Fit preprocessors trên train folds only\n- **Time-based splits:** cho time series\n- **No target leakage:** Features không chứa info về target\n- **Test set untouched:** Cho đến cuối\n\n**7. Document Everything:**\n- Experiments log\n- Model versions\n- Hyperparameters\n- Results và insights\n\n**8. Reproducibility:**\n- Set random seeds\n- Version control code\n- Save data versions\n- Document environment\n- Use containers (Docker)\n\n**9. Model Versioning:**\n- MLflow, DVC\n- Track models\n- Compare versions\n- Rollback nếu cần\n\n**10. Validation Strategy:**\n- Robust CV\n- Hold-out test set\n- Temporal validation cho time series\n\n**11. Feature Engineering First:**\n- \"Data > Algorithms\"\n- Good features > Complex models\n- Domain knowledge valuable\n\n**12. Monitor Training:**\n- Training vs validation\n- Learning curves\n- Early signs of overfitting\n\n**13. Consider Production:**\n- Inference time\n- Model size\n- Dependencies\n- Maintenance\n- Explainability\n\n**14. Test on Real Data:**\n- Not just metrics\n- Qualitative analysis\n- Edge cases\n- Failure modes\n\n---\n\n---\n\n## Học Không Giám Sát (Unsupervised Learning)\n\n### Giới Thiệu Về Học Không Giám Sát\n\nHọc không giám sát khám phá các mẫu ẩn trong dữ liệu không có nhãn mà không cần biến mục tiêu tường minh. Nó được sử dụng cho phân tích dữ liệu khám phá, nhận dạng mẫu và nén dữ liệu.\n\n**Đặc điểm chính:**\n- Không có labels (y)\n- Chỉ có features (X)\n- Tìm structure trong data\n- Exploratory analysis\n\n**So với Supervised Learning:**\n| Tiêu chí | Supervised | Unsupervised |\n|----------|-----------|--------------|\n| Labels | Có | Không |\n| Mục tiêu | Dự đoán | Khám phá |\n| Feedback | Có (accuracy) | Không rõ ràng |\n| Ứng dụng | Classification, Regression | Clustering, Dimensionality Reduction |\n\n**Các tác vụ chính:**\n1. **Clustering:** Nhóm dữ liệu tương tự\n2. **Dimensionality Reduction:** Giảm số chiều\n3. **Anomaly Detection:** Phát hiện bất thường\n4. **Association Rule Learning:** Tìm mối quan hệ\n\n**Thách thức:**\n- Không có ground truth để đánh giá\n- Khó xác định số clusters/components\n- Kết quả có thể subjective\n- Cần domain knowledge để interpret\n\n### Clustering (Phân Cụm)\n\nNhóm các điểm dữ liệu tương tự lại với nhau.\n\n**Mục tiêu:**\n- High intra-cluster similarity (trong cùng cluster)\n- Low inter-cluster similarity (giữa các clusters)\n\n**Ứng dụng:**\n- Customer segmentation\n- Document clustering\n- Image segmentation\n- Anomaly detection\n- Data compression\n\n### K-Means Clustering\n\nThuật toán phân cụm phổ biến nhất, chia dữ liệu thành K clusters.\n\n**Thuật toán:**\n\n**Bước 1: Initialization**\n- Chọn K centroids ngẫu nhiên\n- Có thể từ data points hoặc random positions\n\n**Bước 2: Assignment**\n- Gán mỗi điểm đến centroid gần nhất\n- Sử dụng Euclidean distance:\n$$d(x, \\mu_k) = ||x - \\mu_k|| = \\sqrt{\\sum_{j=1}^{n}(x_j - \\mu_{kj})^2}$$\n\n**Bước 3: Update**\n- Cập nhật centroids = mean của các điểm assigned\n$$\\mu_k = \frac{1}{|C_k|}\\sum_{x \\in C_k}x$$\n\n\n**Các khái niệm quan trọng:**\n- Training là quá trình mô hình học các mẫu từ dữ liệu huấn luyện bằng cách điều chỉnh các tham số nội bộ của nó (ví dụ: weights, biases) để tối thiểu hóa hàm loss, nhằm mục đích thực hiện một tác vụ cụ thể như phân loại hoặc hồi quy.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n**Underfitting (High Bias):**\n- Training error cao\n- Validation error cao\n- Mô hình quá đơn giản\n- Giải pháp: Thêm đặc trưng, tăng độ phức tạp, giảm regularization\n\n**Overfitting (High Variance):**\n- Training error thấp\n- Validation error cao (chênh lệch lớn)\n- Mô hình quá phức tạp\n- Giải pháp: Thêm dữ liệu, regularization, giảm đặc trưng, early stopping\n\n**Good fit:**\n- Training error thấp\n- Validation error thấp\n- Chênh lệch nhỏ giữa hai errors\n\n\n---\n\n## Phân Loại (Classification)\n\n### Giới Thiệu Về Phân Loại\n\nPhân loại là một tác vụ học có giám sát trong đó mục tiêu là dự đoán nhãn lớp rời rạc. Khác với hồi quy dự đoán giá trị liên tục, phân loại gán các đầu vào vào các danh mục được định nghĩa trước.\n\n**Ứng dụng thực tế:**\n- Phát hiện thư rác (spam/không spam)\n- Chẩn đoán bệnh (bệnh/không bệnh)\n- Nhận dạng chữ viết tay\n- Phân tích cảm xúc (tích cực/tiêu cực/trung lập)\n- Phát hiện gian lận thẻ tín dụng\n- Nhận dạng khuôn mặt\n- Phân loại văn bản, hình ảnh\n\n### Các Loại Bài Toán Phân Loại\n\n**1. Phân Loại Nhị Phân (Binary Classification):**\n- Hai lớp duy nhất\n- Ví dụ: Email spam/không spam, Bệnh/khỏe mạnh\n- Mã hóa nhãn: 0 và 1, hoặc -1 và +1\n\n**2. Phân Loại Đa Lớp (Multiclass Classification):**\n- Nhiều hơn hai lớp\n- Mỗi mẫu thuộc đúng một lớp\n- Ví dụ: Nhận dạng chữ số (0-9), Phân loại loại hoa\n- Mã hóa nhãn: One-hot encoding\n\n**3. Phân Loại Đa Nhãn (Multilabel Classification):**\n- Mỗi mẫu có thể thuộc nhiều lớp\n- Ví dụ: Gắn thẻ bài viết (công nghệ, kinh tế, chính trị), Phân loại thể loại phim\n\n### Hồi Quy Logistic (Logistic Regression)\n\nMặc dù có tên là \"regression\", hồi quy logistic là thuật toán phân loại mô hình hóa xác suất của kết quả nhị phân.\n\n**Hàm Sigmoid (Logistic Function):**\n$$\\sigma(z) = \frac{1}{1 + e^{-z}}$$\n\nTrong đó: $z = \beta_0 + \beta_1x_1 + ... + \beta_nx_n = \beta^Tx$\n\n**Đặc điểm hàm Sigmoid:**\n- Miền giá trị: $(0, 1)$ - phù hợp để biểu diễn xác suất\n- $\\sigma(0) = 0.5$\n- $\\sigma(z) \to 1$ khi $z \to \\infty$\n- $\\sigma(z) \to 0$ khi $z \to -\\infty$\n- Đạo hàm: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$\n\n**Diễn Giải:**\n\n**Các khái niệm quan trọng:**\n- Training error là thước đo hiệu suất của mô hình trên tập dữ liệu huấn luyện, cho biết mô hình học tốt như thế nào trên dữ liệu mà nó đã \"nhìn thấy\" trong quá trình huấn luyện. Giá trị cao cho thấy mô hình chưa học được tốt dữ liệu, trong khi giá trị thấp thường cho thấy mô hình đã học được các mẫu trong dữ liệu huấn luyện. Tuy nhiên, training error thấp không nhất thiết có nghĩa là mô hình sẽ hoạt động tốt trên dữ liệu mới. Khi training error tiếp tục giảm nhưng validation error không cải thiện, đó là dấu hiệu của overfitting.\n\n**Mối quan hệ:**\n- Underfitting được đặc trưng bởi Training error cao, cho thấy mô hình không học được dữ liệu huấn luyện.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Phân Loại (Classification)\n- Ưu điểm: Mỗi mô hình đơn giản hơn, cân bằng hơn\n- Nhược điểm: Nhiều mô hình (phức tạp khi K lớn)\n\n**Ví dụ:** 3 lớp (A, B, C)\n- Mô hình 1: A vs B\n- Mô hình 2: A vs C\n- Mô hình 3: B vs C\n\n**3. Softmax Regression (Multinomial Logistic Regression):**\n\nMở rộng trực tiếp của logistic regression cho đa lớp.\n\n**Công thức:**\n$$P(y=k|x) = \frac{e^{z_k}}{\\sum_{j=1}^{K}e^{z_j}}$$\n\nTrong đó: $z_k = \beta_k^Tx$ với $\beta_k$ là vector hệ số cho lớp $k$\n\n**Đặc điểm:**\n- Tổng các xác suất = 1: $\\sum_{k=1}^{K}P(y=k|x) = 1$\n- Output là phân phối xác suất trên tất cả lớp\n- Huấn luyện đồng thời tất cả lớp\n\n**Hàm chi phí (Categorical Cross-Entropy):**\n$$J(\beta) = -\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_k^{(i)}\\log(P(y=k|x^{(i)}))$$\n\nTrong đó $y_k^{(i)}$ là one-hot encoding của nhãn.\n\n**Lựa chọn giữa OvR, OvO, và Softmax:**\n- **Softmax:** Tốt nhất khi cần xác suất, K không quá lớn\n- **OvR:** Đơn giản, hiệu quả với K lớn\n- **OvO:** Tốt với SVM, K nhỏ/trung bình\n\n### Naive Bayes Classifier (Bộ Phân Loại Naive Bayes)\n\nDựa trên định lý Bayes với giả định \"ngây thơ\" (naive) về tính độc lập đặc trưng.\n\n**Định Lý Bayes:**\n$$P(C_k|x) = \frac{P(x|C_k)P(C_k)}{P(x)}$$\n\nTrong đó:\n- $P(C_k|x)$: Xác suất hậu nghiệm (posterior) - xác suất lớp $C_k$ cho trước $x$\n- $P(x|C_k)$: Likelihood - xác suất của $x$ trong lớp $C_k$\n- $P(C_k)$: Xác suất tiên nghiệm (prior) của lớp $C_k$\n- $P(x)$: Evidence - xác suất của $x$\n\n**Giả Định Naive (Độc Lập Điều Kiện):**\n$$P(x_1, x_2, ..., x_n|C_k) = \\prod_{i=1}^{n}P(x_i|C_k)$$\n\nCác đặc trưng độc lập với nhau khi biết lớp.\n\n**Công Thức Đầy Đủ:**\n$$P(C_k|x_1,...,x_n) = \frac{P(C_k)\\prod_{i=1}^{n}P(x_i|C_k)}{P(x_1,...,x_n)}$$\n\n**Quyết Định:**\n$$\\hat{y} = \\arg\\max_{k} P(C_k)\\prod_{i=1}^{n}P(x_i|C_k)$$\n\nKhông cần tính $P(x)$ vì nó giống nhau cho tất cả lớp.\n\n**Các Biến Thể:**\n\n**1. Gaussian Naive Bayes:**\n- Cho đặc trưng liên tục\n- Giả định phân phối Gaussian (chuẩn)\n\n**Các khái niệm quan trọng:**\n- Phân loại là một tác vụ trong học máy nhằm gán một nhãn lớp cụ thể cho các mẫu dữ liệu đầu vào dựa trên các đặc trưng của chúng. Mục tiêu là xây dựng một mô hình, ví dụ như Cây Quyết Định, có khả năng dự đoán chính xác nhãn lớp của các mẫu mới, với kết quả dự đoán ở nút lá là một nhãn lớp cụ thể.\n\n**Mối quan hệ:**\n- Softmax Regression là một mô hình được thiết kế để giải quyết các bài toán Phân loại đa lớp, cung cấp xác suất cho mỗi lớp.\n- Naive Bayes Classifier là một mô hình được sử dụng để giải quyết các bài toán Phân loại, đặc biệt hiệu quả với giả định độc lập đặc trưng."
        },
        "output_without_context": {
            "question": "Lỗi thực nghiệm (Empirical Error) trong mô hình học máy được định nghĩa là gì?",
            "answer": "Lỗi thực nghiệm là độ chính xác của mô hình trên dữ liệu huấn luyện."
        }
    },
    {
        "topic_description": "Chủ đề này khám phá hai hiện tượng quan trọng trong việc tối ưu hóa mô hình, đó là Quá khớp (Overfitting) và Dưới khớp (Underfitting). Học sinh sẽ học cách nhận diện và phân tích nguyên nhân gây ra hai vấn đề này, từ đó áp dụng các thay đổi cần thiết để cải thiện mô hình. Các ví dụ thực tế sẽ được cung cấp để minh họa rõ hơn về các hiện tượng này.",
        "output_with_context": {
            "question": "Dấu hiệu nào dưới đây cho thấy một mô hình đang gặp phải vấn đề overfitting?",
            "answer": "Độ lỗi thấp trên tập huấn luyện nhưng độ lỗi cao trên tập kiểm tra.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n```\n**Dấu hiệu:**\n- Large gap giữa curves\n- Training error tiếp tục giảm\n- Validation error không cải thiện\n\n**Giải pháp:**\n- Get more training data\n- Reduce model complexity\n- Increase regularization\n- Feature selection\n- Dropout, early stopping\n\n**3. Good Fit:**\n```\nTraining error: Thấp\nValidation error: Thấp\nGap: Nhỏ\nBoth converge\n```\n**Dấu hiệu:**\n- Small gap\n- Both errors low\n- Converged performance\n\n**4. More Data Helps:**\n```\nValidation error giảm khi tăng data\nGap đang đóng lại\nChưa plateau\n```\n**Hành động:** Get more data!\n\n**5. More Data Doesn't Help:**\n```\nBoth curves plateau\nAdding data không cải thiện\n```\n**Hành động:** Improve features hoặc model\n\n### Bias-Variance Tradeoff (Sự Đánh Đổi Bias-Variance)\n\n**Công thức:**\n$$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$\n\n**Bias (Thiên Lệch):**\n- Error từ giả định đơn giản hóa\n- Underfitting\n- Model không capture được patterns\n- High bias → Systematic errors\n\n**Variance (Phương Sai):**\n- Error từ sensitivity to training data\n- Overfitting\n- Model learns noise\n- High variance → Different results với different data\n\n**Irreducible Error:**\n- Noise trong data\n- Không thể giảm\n- Comes from data collection\n\n**Tradeoff:**\n- Decrease bias → Increase variance\n- Decrease variance → Increase bias\n- Cần balance\n\n**Strategies:**\n\n**Giảm High Bias:**\n1. Increase model complexity\n2. Add more features/polynomial features\n3. Decrease regularization\n4. Train longer\n5. Use ensemble methods\n\n**Giảm High Variance:**\n1. Get more training data\n2. Reduce model complexity\n3. Increase regularization (L1, L2, dropout)\n4. Feature selection\n5. Early stopping\n6. Ensemble methods (bagging)\n\n**Sweet Spot:**\n- Minimize total error\n- Balance bias và variance\n- Depends on problem và data\n\n**Visualize:**\n```\nTotal Error\n    |     \\\n    |      \\___Bias²\n    |___________\\\n    |            \\___\n    |Variance_____\\___Total\n    |________________\\___\n    |___________________\\___\n    +----------------------->\n    Simple          Complex\n            Model Complexity\n```\n\n### Phương Pháp Ensemble\n\nKết hợp nhiều models để cải thiện hiệu suất.\n\n**\"Wisdom of crowds\"**\n\n**Tại sao hoạt động:**\n- Errors của individual models cancel out\n- Diverse models capture different patterns\n- Reduce variance\n- More robust\n\n**1. Bagging (Bootstrap Aggregating):**\n\n**Nguyên lý:**\n- Train multiple models trên bootstrap samples\n- Average predictions (regression) hoặc vote (classification)\n\n**Bootstrap Sampling:**\n- Sample with replacement\n- Same size as original\n- ~63% unique samples mỗi bootstrap\n\n**Thuật toán:**\n1. For i = 1 to M:\n   - Create bootstrap sample $D_i$\n   - Train model $M_i$ on $D_i$\n2. Combine:\n   - Regression: $\\hat{y} = \frac{1}{M}\\sum_{i=1}^{M}M_i(x)$\n   - Classification: Majority vote\n\n**Ưu điểm:**\n- Reduce variance\n- Parallel training\n- Works với high-variance models\n\n**Nhược điểm:**\n- Không giảm bias\n- Có thể chậm (many models)\n\n**Ví dụ:** Random Forest\n\n**2. Boosting:**\n\n**Nguyên lý:**\n- Sequential training\n- Each model corrects errors của previous models\n- Weighted combination\n\n**Thuật toán (general):**\n1. Initialize equal weights\n2. For i = 1 to M:\n   - Train model $M_i$ on weighted data\n   - Tính error\n   - Update weights (increase for misclassified)\n\n**Các khái niệm quan trọng:**\n- Overfitting (học quá mức/quá khớp) là một vấn đề phổ biến trong học máy khi mô hình học quá sát với dữ liệu huấn luyện, bao gồm cả nhiễu, các mẫu ngẫu nhiên, và các chi tiết không tổng quát. Điều này dẫn đến hiệu suất rất tốt (độ lỗi thấp, độ chính xác cao) trên tập huấn luyện nhưng lại kém (độ lỗi cao, độ chính xác thấp) trên dữ liệu mới, chưa từng thấy (tập kiểm tra/validation).\n\nCác dấu hiệu của overfitting bao gồm:\n- Độ lỗi thấp trên tập huấn luyện nhưng độ lỗi cao trên tập kiểm tra.\n- Khoảng cách lớn giữa learning curves của training và validation.\n- Training error tiếp tục giảm nhưng validation error không cải thiện hoặc thậm chí tăng.\n- Mô hình có high variance và generalization kém.\n\nCác mô hình phức tạp, đặc biệt là các mô hình có nhiều tham số như Deep Learning, Transformers, hoặc Cây Quyết định quá sâu/phức tạp, có nguy cơ cao bị overfitting nếu không có đủ dữ liệu để huấn luyện tốt.\n\nĐể ngăn chặn overfitting, các kỹ thuật sau thường được sử dụng:\n- **Regularization**: Bao gồm L1 Regularization (Lasso), L2 Regularization, và Dropout, giúp đơn giản hóa mô hình và khuyến khích tính tổng quát hóa tốt hơn.\n- **Early Stopping**: Dừng quá trình huấn luyện khi hiệu suất trên tập validation bắt đầu giảm hoặc không cải thiện.\n- **Data Augmentation**: Tăng cường dữ liệu huấn luyện bằng cách tạo ra các biến thể của dữ liệu hiện có.\n- **Giảm độ phức tạp của mô hình**: Ví dụ, giảm số lượng đặc trưng, hoặc cắt tỉa (pruning) cây quyết định.\n- **Thêm dữ liệu huấn luyện**: Cung cấp nhiều dữ liệu hơn để mô hình học các mẫu tổng quát thay vì ghi nhớ nhiễu.\n- **Các kỹ thuật khác**: Pooling và Global Average Pooling cũng có thể giúp giảm overfitting.\n\nNgược lại, Underfitting (học dưới mức) là vấn đề khi mô hình quá đơn giản để nắm bắt các mẫu cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả dữ liệu huấn luyện và dữ liệu mới. Underfitting liên quan đến High Bias, với dấu hiệu là training error cao và validation error cao, cùng với một khoảng cách nhỏ giữa chúng trên Learning Curves.\n- Overfitting là vấn đề xảy ra khi mô hình học quá sát với dữ liệu huấn luyện, bao gồm cả nhiễu, dẫn đến hiệu suất kém trên dữ liệu mới chưa từng thấy. Trong Transfer Learning, Feature Extraction giúp giảm overfitting do ít tham số được huấn luyện, trong khi Fine-tuning có nguy cơ overfitting nếu dữ liệu ít.\n- Overfitting và Underfitting là hai vấn đề phổ biến trong Machine Learning. Overfitting xảy ra khi mô hình học quá sát dữ liệu huấn luyện, bao gồm cả nhiễu và các chi tiết không tổng quát, dẫn đến hiệu suất kém trên dữ liệu mới. Trong k-NN, k quá nhỏ (ví dụ k=1) có thể gây overfitting, tạo ra decision boundary phức tạp. Ngược lại, Underfitting xảy ra khi mô hình quá đơn giản để nắm bắt mối quan hệ cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả tập huấn luyện và tập kiểm tra. Trong k-NN, k quá lớn có thể gây underfitting, tạo ra decision boundary quá mượt và không đủ chi tiết.\n\n**Mối quan hệ:**\n- Overfitting là vấn đề xảy ra khi mô hình có High Variance, nghĩa là mô hình quá nhạy cảm với dữ liệu huấn luyện và học cả nhiễu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n\n### Giới Thiệu\n\nLựa chọn đặc trưng (feature selection) và tối ưu hóa mô hình là các bước quan trọng trong việc xây dựng mô hình học máy hiệu quả. Chúng cải thiện hiệu suất mô hình, giảm overfitting, giảm thời gian huấn luyện và tăng khả năng diễn giải.\n\n**Tại sao quan trọng:**\n\n**1. Cải Thiện Hiệu Suất:**\n- Loại bỏ noise và đặc trưng không liên quan\n- Tăng accuracy và generalization\n- Mô hình tập trung vào signal thực sự\n\n**2. Giảm Overfitting:**\n- Ít đặc trưng → mô hình đơn giản hơn\n- Giảm variance\n- Better generalization\n\n**3. Giảm Thời Gian Training:**\n- Ít dữ liệu để xử lý\n- Training nhanh hơn\n- Prediction nhanh hơn\n\n**4. Tăng Khả Năng Diễn Giải:**\n- Dễ hiểu mô hình\n- Ít đặc trưng để phân tích\n- Better insights\n\n**5. Giảm Chi Phí:**\n- Ít đặc trưng cần thu thập\n- Tiết kiệm storage\n- Giảm computational resources\n\n### Lựa Chọn Đặc Trưng (Feature Selection)\n\nXác định các đặc trưng liên quan nhất cho việc xây dựng mô hình, giảm số chiều và cải thiện hiệu suất.\n\n**Ba nhóm phương pháp chính:**\n1. **Filter Methods:** Đánh giá độc lập với mô hình\n2. **Wrapper Methods:** Đánh giá bằng hiệu suất mô hình\n3. **Embedded Methods:** Lựa chọn trong quá trình training\n\n### Filter Methods (Phương Pháp Lọc)\n\nĐánh giá đặc trưng độc lập với mô hình sử dụng các đo lường thống kê.\n\n**Đặc điểm:**\n- Nhanh, hiệu quả\n- Không phụ thuộc vào thuật toán học\n- Tốt cho high-dimensional data\n- Có thể bỏ lỡ feature interactions\n\n**1. Correlation-Based Methods (Phương Pháp Dựa Trên Tương Quan):**\n\n**Pearson Correlation Coefficient:**\n$$r = \frac{\\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$\n\n- Giá trị: -1 đến +1\n- |r| gần 1: Tương quan mạnh\n- |r| gần 0: Không tương quan\n\n**Ứng dụng:**\n- **Feature-Target Correlation:** Chọn features có correlation cao với target\n- **Feature-Feature Correlation:** Loại bỏ features tương quan cao với nhau (multicollinearity)\n\n**Threshold:**\n- |r| > 0.8 hoặc 0.9: Multicollinearity\n- |r| < 0.1: Ít liên quan với target\n\n**Lưu ý:**\n- Chỉ bắt được mối quan hệ tuyến tính\n- Không phù hợp với categorical features\n- Có thể bỏ lỡ quan hệ phi tuyến\n\n**2. Statistical Tests (Kiểm Định Thống Kê):**\n\n\n**Các khái niệm quan trọng:**\n- Overfitting là vấn đề xảy ra khi mô hình học quá sát với dữ liệu huấn luyện, bao gồm cả nhiễu, dẫn đến hiệu suất kém trên dữ liệu mới chưa từng thấy. Trong Transfer Learning, Feature Extraction giúp giảm overfitting do ít tham số được huấn luyện, trong khi Fine-tuning có nguy cơ overfitting nếu dữ liệu ít.\n- Overfitting và Underfitting là hai vấn đề phổ biến trong Machine Learning. Overfitting xảy ra khi mô hình học quá sát dữ liệu huấn luyện, bao gồm cả nhiễu và các chi tiết không tổng quát, dẫn đến hiệu suất kém trên dữ liệu mới. Trong k-NN, k quá nhỏ (ví dụ k=1) có thể gây overfitting, tạo ra decision boundary phức tạp. Ngược lại, Underfitting xảy ra khi mô hình quá đơn giản để nắm bắt mối quan hệ cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả tập huấn luyện và tập kiểm tra. Trong k-NN, k quá lớn có thể gây underfitting, tạo ra decision boundary quá mượt và không đủ chi tiết.\n- Overfitting (học quá mức/quá khớp) là một vấn đề phổ biến trong học máy khi mô hình học quá sát với dữ liệu huấn luyện, bao gồm cả nhiễu, các mẫu ngẫu nhiên, và các chi tiết không tổng quát. Điều này dẫn đến hiệu suất rất tốt (độ lỗi thấp, độ chính xác cao) trên tập huấn luyện nhưng lại kém (độ lỗi cao, độ chính xác thấp) trên dữ liệu mới, chưa từng thấy (tập kiểm tra/validation).\n\nCác dấu hiệu của overfitting bao gồm:\n- Độ lỗi thấp trên tập huấn luyện nhưng độ lỗi cao trên tập kiểm tra.\n- Khoảng cách lớn giữa learning curves của training và validation.\n- Training error tiếp tục giảm nhưng validation error không cải thiện hoặc thậm chí tăng.\n- Mô hình có high variance và generalization kém.\n\nCác mô hình phức tạp, đặc biệt là các mô hình có nhiều tham số như Deep Learning, Transformers, hoặc Cây Quyết định quá sâu/phức tạp, có nguy cơ cao bị overfitting nếu không có đủ dữ liệu để huấn luyện tốt.\n\nĐể ngăn chặn overfitting, các kỹ thuật sau thường được sử dụng:\n- **Regularization**: Bao gồm L1 Regularization (Lasso), L2 Regularization, và Dropout, giúp đơn giản hóa mô hình và khuyến khích tính tổng quát hóa tốt hơn.\n- **Early Stopping**: Dừng quá trình huấn luyện khi hiệu suất trên tập validation bắt đầu giảm hoặc không cải thiện.\n- **Data Augmentation**: Tăng cường dữ liệu huấn luyện bằng cách tạo ra các biến thể của dữ liệu hiện có.\n- **Giảm độ phức tạp của mô hình**: Ví dụ, giảm số lượng đặc trưng, hoặc cắt tỉa (pruning) cây quyết định.\n- **Thêm dữ liệu huấn luyện**: Cung cấp nhiều dữ liệu hơn để mô hình học các mẫu tổng quát thay vì ghi nhớ nhiễu.\n- **Các kỹ thuật khác**: Pooling và Global Average Pooling cũng có thể giúp giảm overfitting.\n\nNgược lại, Underfitting (học dưới mức) là vấn đề khi mô hình quá đơn giản để nắm bắt các mẫu cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả dữ liệu huấn luyện và dữ liệu mới. Underfitting liên quan đến High Bias, với dấu hiệu là training error cao và validation error cao, cùng với một khoảng cách nhỏ giữa chúng trên Learning Curves.\n\n**Mối quan hệ:**\n- Overfitting là vấn đề xảy ra khi mô hình có High Variance, nghĩa là mô hình quá nhạy cảm với dữ liệu huấn luyện và học cả nhiễu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n**Underfitting (High Bias):**\n- Training error cao\n- Validation error cao\n- Mô hình quá đơn giản\n- Giải pháp: Thêm đặc trưng, tăng độ phức tạp, giảm regularization\n\n**Overfitting (High Variance):**\n- Training error thấp\n- Validation error cao (chênh lệch lớn)\n- Mô hình quá phức tạp\n- Giải pháp: Thêm dữ liệu, regularization, giảm đặc trưng, early stopping\n\n**Good fit:**\n- Training error thấp\n- Validation error thấp\n- Chênh lệch nhỏ giữa hai errors\n\n\n---\n\n## Phân Loại (Classification)\n\n### Giới Thiệu Về Phân Loại\n\nPhân loại là một tác vụ học có giám sát trong đó mục tiêu là dự đoán nhãn lớp rời rạc. Khác với hồi quy dự đoán giá trị liên tục, phân loại gán các đầu vào vào các danh mục được định nghĩa trước.\n\n**Ứng dụng thực tế:**\n- Phát hiện thư rác (spam/không spam)\n- Chẩn đoán bệnh (bệnh/không bệnh)\n- Nhận dạng chữ viết tay\n- Phân tích cảm xúc (tích cực/tiêu cực/trung lập)\n- Phát hiện gian lận thẻ tín dụng\n- Nhận dạng khuôn mặt\n- Phân loại văn bản, hình ảnh\n\n### Các Loại Bài Toán Phân Loại\n\n**1. Phân Loại Nhị Phân (Binary Classification):**\n- Hai lớp duy nhất\n- Ví dụ: Email spam/không spam, Bệnh/khỏe mạnh\n- Mã hóa nhãn: 0 và 1, hoặc -1 và +1\n\n**2. Phân Loại Đa Lớp (Multiclass Classification):**\n- Nhiều hơn hai lớp\n- Mỗi mẫu thuộc đúng một lớp\n- Ví dụ: Nhận dạng chữ số (0-9), Phân loại loại hoa\n- Mã hóa nhãn: One-hot encoding\n\n**3. Phân Loại Đa Nhãn (Multilabel Classification):**\n- Mỗi mẫu có thể thuộc nhiều lớp\n- Ví dụ: Gắn thẻ bài viết (công nghệ, kinh tế, chính trị), Phân loại thể loại phim\n\n### Hồi Quy Logistic (Logistic Regression)\n\nMặc dù có tên là \"regression\", hồi quy logistic là thuật toán phân loại mô hình hóa xác suất của kết quả nhị phân.\n\n**Hàm Sigmoid (Logistic Function):**\n$$\\sigma(z) = \frac{1}{1 + e^{-z}}$$\n\nTrong đó: $z = \beta_0 + \beta_1x_1 + ... + \beta_nx_n = \beta^Tx$\n\n**Đặc điểm hàm Sigmoid:**\n- Miền giá trị: $(0, 1)$ - phù hợp để biểu diễn xác suất\n- $\\sigma(0) = 0.5$\n- $\\sigma(z) \to 1$ khi $z \to \\infty$\n- $\\sigma(z) \to 0$ khi $z \to -\\infty$\n- Đạo hàm: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$\n\n**Diễn Giải:**\n\n**Các khái niệm quan trọng:**\n- Overfitting (học quá mức/quá khớp) là một vấn đề phổ biến trong học máy khi mô hình học quá sát với dữ liệu huấn luyện, bao gồm cả nhiễu, các mẫu ngẫu nhiên, và các chi tiết không tổng quát. Điều này dẫn đến hiệu suất rất tốt (độ lỗi thấp, độ chính xác cao) trên tập huấn luyện nhưng lại kém (độ lỗi cao, độ chính xác thấp) trên dữ liệu mới, chưa từng thấy (tập kiểm tra/validation).\n\nCác dấu hiệu của overfitting bao gồm:\n- Độ lỗi thấp trên tập huấn luyện nhưng độ lỗi cao trên tập kiểm tra.\n- Khoảng cách lớn giữa learning curves của training và validation.\n- Training error tiếp tục giảm nhưng validation error không cải thiện hoặc thậm chí tăng.\n- Mô hình có high variance và generalization kém.\n\nCác mô hình phức tạp, đặc biệt là các mô hình có nhiều tham số như Deep Learning, Transformers, hoặc Cây Quyết định quá sâu/phức tạp, có nguy cơ cao bị overfitting nếu không có đủ dữ liệu để huấn luyện tốt.\n\nĐể ngăn chặn overfitting, các kỹ thuật sau thường được sử dụng:\n- **Regularization**: Bao gồm L1 Regularization (Lasso), L2 Regularization, và Dropout, giúp đơn giản hóa mô hình và khuyến khích tính tổng quát hóa tốt hơn.\n- **Early Stopping**: Dừng quá trình huấn luyện khi hiệu suất trên tập validation bắt đầu giảm hoặc không cải thiện.\n- **Data Augmentation**: Tăng cường dữ liệu huấn luyện bằng cách tạo ra các biến thể của dữ liệu hiện có.\n- **Giảm độ phức tạp của mô hình**: Ví dụ, giảm số lượng đặc trưng, hoặc cắt tỉa (pruning) cây quyết định.\n- **Thêm dữ liệu huấn luyện**: Cung cấp nhiều dữ liệu hơn để mô hình học các mẫu tổng quát thay vì ghi nhớ nhiễu.\n- **Các kỹ thuật khác**: Pooling và Global Average Pooling cũng có thể giúp giảm overfitting.\n\nNgược lại, Underfitting (học dưới mức) là vấn đề khi mô hình quá đơn giản để nắm bắt các mẫu cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả dữ liệu huấn luyện và dữ liệu mới. Underfitting liên quan đến High Bias, với dấu hiệu là training error cao và validation error cao, cùng với một khoảng cách nhỏ giữa chúng trên Learning Curves.\n- Overfitting là vấn đề xảy ra khi mô hình học quá sát với dữ liệu huấn luyện, bao gồm cả nhiễu, dẫn đến hiệu suất kém trên dữ liệu mới chưa từng thấy. Trong Transfer Learning, Feature Extraction giúp giảm overfitting do ít tham số được huấn luyện, trong khi Fine-tuning có nguy cơ overfitting nếu dữ liệu ít.\n- Overfitting và Underfitting là hai vấn đề phổ biến trong Machine Learning. Overfitting xảy ra khi mô hình học quá sát dữ liệu huấn luyện, bao gồm cả nhiễu và các chi tiết không tổng quát, dẫn đến hiệu suất kém trên dữ liệu mới. Trong k-NN, k quá nhỏ (ví dụ k=1) có thể gây overfitting, tạo ra decision boundary phức tạp. Ngược lại, Underfitting xảy ra khi mô hình quá đơn giản để nắm bắt mối quan hệ cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả tập huấn luyện và tập kiểm tra. Trong k-NN, k quá lớn có thể gây underfitting, tạo ra decision boundary quá mượt và không đủ chi tiết.\n\n**Mối quan hệ:**\n- Overfitting là vấn đề xảy ra khi mô hình có High Variance, nghĩa là mô hình quá nhạy cảm với dữ liệu huấn luyện và học cả nhiễu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n- Precision, Recall, F1, AUC\n- Business metrics\n\n**6. Avoid Data Leakage:**\n- **Proper CV:** Fit preprocessors trên train folds only\n- **Time-based splits:** cho time series\n- **No target leakage:** Features không chứa info về target\n- **Test set untouched:** Cho đến cuối\n\n**7. Document Everything:**\n- Experiments log\n- Model versions\n- Hyperparameters\n- Results và insights\n\n**8. Reproducibility:**\n- Set random seeds\n- Version control code\n- Save data versions\n- Document environment\n- Use containers (Docker)\n\n**9. Model Versioning:**\n- MLflow, DVC\n- Track models\n- Compare versions\n- Rollback nếu cần\n\n**10. Validation Strategy:**\n- Robust CV\n- Hold-out test set\n- Temporal validation cho time series\n\n**11. Feature Engineering First:**\n- \"Data > Algorithms\"\n- Good features > Complex models\n- Domain knowledge valuable\n\n**12. Monitor Training:**\n- Training vs validation\n- Learning curves\n- Early signs of overfitting\n\n**13. Consider Production:**\n- Inference time\n- Model size\n- Dependencies\n- Maintenance\n- Explainability\n\n**14. Test on Real Data:**\n- Not just metrics\n- Qualitative analysis\n- Edge cases\n- Failure modes\n\n---\n\n---\n\n## Học Không Giám Sát (Unsupervised Learning)\n\n### Giới Thiệu Về Học Không Giám Sát\n\nHọc không giám sát khám phá các mẫu ẩn trong dữ liệu không có nhãn mà không cần biến mục tiêu tường minh. Nó được sử dụng cho phân tích dữ liệu khám phá, nhận dạng mẫu và nén dữ liệu.\n\n**Đặc điểm chính:**\n- Không có labels (y)\n- Chỉ có features (X)\n- Tìm structure trong data\n- Exploratory analysis\n\n**So với Supervised Learning:**\n| Tiêu chí | Supervised | Unsupervised |\n|----------|-----------|--------------|\n| Labels | Có | Không |\n| Mục tiêu | Dự đoán | Khám phá |\n| Feedback | Có (accuracy) | Không rõ ràng |\n| Ứng dụng | Classification, Regression | Clustering, Dimensionality Reduction |\n\n**Các tác vụ chính:**\n1. **Clustering:** Nhóm dữ liệu tương tự\n2. **Dimensionality Reduction:** Giảm số chiều\n3. **Anomaly Detection:** Phát hiện bất thường\n4. **Association Rule Learning:** Tìm mối quan hệ\n\n**Thách thức:**\n- Không có ground truth để đánh giá\n- Khó xác định số clusters/components\n- Kết quả có thể subjective\n- Cần domain knowledge để interpret\n\n### Clustering (Phân Cụm)\n\nNhóm các điểm dữ liệu tương tự lại với nhau.\n\n**Mục tiêu:**\n- High intra-cluster similarity (trong cùng cluster)\n- Low inter-cluster similarity (giữa các clusters)\n\n**Ứng dụng:**\n- Customer segmentation\n- Document clustering\n- Image segmentation\n- Anomaly detection\n- Data compression\n\n### K-Means Clustering\n\nThuật toán phân cụm phổ biến nhất, chia dữ liệu thành K clusters.\n\n**Thuật toán:**\n\n**Bước 1: Initialization**\n- Chọn K centroids ngẫu nhiên\n- Có thể từ data points hoặc random positions\n\n**Bước 2: Assignment**\n- Gán mỗi điểm đến centroid gần nhất\n- Sử dụng Euclidean distance:\n$$d(x, \\mu_k) = ||x - \\mu_k|| = \\sqrt{\\sum_{j=1}^{n}(x_j - \\mu_{kj})^2}$$\n\n**Bước 3: Update**\n- Cập nhật centroids = mean của các điểm assigned\n$$\\mu_k = \frac{1}{|C_k|}\\sum_{x \\in C_k}x$$\n\n\n**Các khái niệm quan trọng:**\n- Overfitting và Underfitting là hai vấn đề phổ biến trong Machine Learning. Overfitting xảy ra khi mô hình học quá sát dữ liệu huấn luyện, bao gồm cả nhiễu và các chi tiết không tổng quát, dẫn đến hiệu suất kém trên dữ liệu mới. Trong k-NN, k quá nhỏ (ví dụ k=1) có thể gây overfitting, tạo ra decision boundary phức tạp. Ngược lại, Underfitting xảy ra khi mô hình quá đơn giản để nắm bắt mối quan hệ cơ bản trong dữ liệu, dẫn đến hiệu suất kém trên cả tập huấn luyện và tập kiểm tra. Trong k-NN, k quá lớn có thể gây underfitting, tạo ra decision boundary quá mượt và không đủ chi tiết.\n\n**Mối quan hệ:**\n- Overfitting là vấn đề xảy ra khi mô hình có High Variance, nghĩa là mô hình quá nhạy cảm với dữ liệu huấn luyện và học cả nhiễu."
        },
        "output_without_context": {
            "question": "Trong quá trình tối ưu hóa mô hình, hiện tượng nào xảy ra khi mô hình học quá nhiều từ dữ liệu huấn luyện và không thể tổng quát hóa tốt cho dữ liệu mới?",
            "answer": "Quá khớp (Overfitting)"
        }
    },
    {
        "topic_description": "Chủ đề này đi sâu vào khái niệm Đánh đổi Độ lệch - Phương sai (Bias-Variance Trade-off), giúp học sinh hiểu sự cân bằng giữa độ lệch và phương sai trong mô hình học máy. Học sinh sẽ được yêu cầu giải thích định nghĩa, ví dụ minh họa cũng như xúc tiến việc áp dụng phương pháp này trong xây dựng mô hình hiệu quả.",
        "output_with_context": {
            "question": "Trong mối quan hệ giữa độ lệch và phương sai, công thức nào mô tả tổng lỗi dự kiến của một mô hình học máy?",
            "answer": "Expected Error = Bias² + Variance + Irreducible Error",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n```\n**Dấu hiệu:**\n- Large gap giữa curves\n- Training error tiếp tục giảm\n- Validation error không cải thiện\n\n**Giải pháp:**\n- Get more training data\n- Reduce model complexity\n- Increase regularization\n- Feature selection\n- Dropout, early stopping\n\n**3. Good Fit:**\n```\nTraining error: Thấp\nValidation error: Thấp\nGap: Nhỏ\nBoth converge\n```\n**Dấu hiệu:**\n- Small gap\n- Both errors low\n- Converged performance\n\n**4. More Data Helps:**\n```\nValidation error giảm khi tăng data\nGap đang đóng lại\nChưa plateau\n```\n**Hành động:** Get more data!\n\n**5. More Data Doesn't Help:**\n```\nBoth curves plateau\nAdding data không cải thiện\n```\n**Hành động:** Improve features hoặc model\n\n### Bias-Variance Tradeoff (Sự Đánh Đổi Bias-Variance)\n\n**Công thức:**\n$$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$\n\n**Bias (Thiên Lệch):**\n- Error từ giả định đơn giản hóa\n- Underfitting\n- Model không capture được patterns\n- High bias → Systematic errors\n\n**Variance (Phương Sai):**\n- Error từ sensitivity to training data\n- Overfitting\n- Model learns noise\n- High variance → Different results với different data\n\n**Irreducible Error:**\n- Noise trong data\n- Không thể giảm\n- Comes from data collection\n\n**Tradeoff:**\n- Decrease bias → Increase variance\n- Decrease variance → Increase bias\n- Cần balance\n\n**Strategies:**\n\n**Giảm High Bias:**\n1. Increase model complexity\n2. Add more features/polynomial features\n3. Decrease regularization\n4. Train longer\n5. Use ensemble methods\n\n**Giảm High Variance:**\n1. Get more training data\n2. Reduce model complexity\n3. Increase regularization (L1, L2, dropout)\n4. Feature selection\n5. Early stopping\n6. Ensemble methods (bagging)\n\n**Sweet Spot:**\n- Minimize total error\n- Balance bias và variance\n- Depends on problem và data\n\n**Visualize:**\n```\nTotal Error\n    |     \\\n    |      \\___Bias²\n    |___________\\\n    |            \\___\n    |Variance_____\\___Total\n    |________________\\___\n    |___________________\\___\n    +----------------------->\n    Simple          Complex\n            Model Complexity\n```\n\n### Phương Pháp Ensemble\n\nKết hợp nhiều models để cải thiện hiệu suất.\n\n**\"Wisdom of crowds\"**\n\n**Tại sao hoạt động:**\n- Errors của individual models cancel out\n- Diverse models capture different patterns\n- Reduce variance\n- More robust\n\n**1. Bagging (Bootstrap Aggregating):**\n\n**Nguyên lý:**\n- Train multiple models trên bootstrap samples\n- Average predictions (regression) hoặc vote (classification)\n\n**Bootstrap Sampling:**\n- Sample with replacement\n- Same size as original\n- ~63% unique samples mỗi bootstrap\n\n**Thuật toán:**\n1. For i = 1 to M:\n   - Create bootstrap sample $D_i$\n   - Train model $M_i$ on $D_i$\n2. Combine:\n   - Regression: $\\hat{y} = \frac{1}{M}\\sum_{i=1}^{M}M_i(x)$\n   - Classification: Majority vote\n\n**Ưu điểm:**\n- Reduce variance\n- Parallel training\n- Works với high-variance models\n\n**Nhược điểm:**\n- Không giảm bias\n- Có thể chậm (many models)\n\n**Ví dụ:** Random Forest\n\n**2. Boosting:**\n\n**Nguyên lý:**\n- Sequential training\n- Each model corrects errors của previous models\n- Weighted combination\n\n**Thuật toán (general):**\n1. Initialize equal weights\n2. For i = 1 to M:\n   - Train model $M_i$ on weighted data\n   - Tính error\n   - Update weights (increase for misclassified)\n\n**Các khái niệm quan trọng:**\n- Bias-Variance Tradeoff là một khái niệm trung tâm trong học máy, mô tả mối quan hệ nghịch đảo giữa bias (thiên lệch) và variance (phương sai) của một mô hình. Mục tiêu là tìm điểm cân bằng để cực tiểu hóa tổng lỗi dự kiến (Expected Error = Bias² + Variance + Irreducible Error). Giảm bias thường làm tăng variance và ngược lại.\n- Bias-Variance Tradeoff là một khái niệm quan trọng trong học máy và các thuật toán ước lượng, mô tả sự đánh đổi giữa lỗi do giả định sai (bias) và lỗi do sự nhạy cảm với các biến động nhỏ trong tập huấn luyện (variance). Trong học tăng cường (RL), các phương pháp như Monte Carlo có bias thấp nhưng variance cao, trong khi TD(0) có bias cao hơn nhưng variance thấp hơn. Các phương pháp như n-Step TD và TD(λ) được thiết kế để cân bằng giữa hai yếu tố này.\n- Variance (Phương sai) là một thành phần của lỗi dự kiến trong học máy, đại diện cho lỗi do sự nhạy cảm của mô hình với các biến động nhỏ hoặc sự thay đổi trong dữ liệu huấn luyện. Nó đề cập đến mức độ mà một mô hình thay đổi khi được huấn luyện trên các tập dữ liệu huấn luyện khác nhau. High variance dẫn đến overfitting, nghĩa là mô hình học cả nhiễu trong dữ liệu huấn luyện, gây ra \"Different results với different data\". Để giảm variance, có thể giảm độ phức tạp của mô hình, tăng regularization, sử dụng nhiều dữ liệu hơn, hoặc giảm số lượng đặc trưng.\n- Bias (độ chệch) là lỗi do các giả định sai trong mô hình học. Trong RL, Monte Carlo có bias bằng 0 (ước lượng không chệch), trong khi TD(0) có bias lớn hơn 0 vì nó phụ thuộc vào ước lượng V hiện tại (bootstrapping).\n- Bias (Thiên Lệch) là một thành phần của lỗi dự kiến, đại diện cho lỗi do các giả định đơn giản hóa của mô hình. High bias dẫn đến underfitting, nghĩa là mô hình không đủ phức tạp để nắm bắt các mẫu cơ bản trong dữ liệu, gây ra \"Systematic errors\". Giảm bias thường đòi hỏi tăng độ phức tạp của mô hình hoặc thêm nhiều đặc trưng hơn.\n\n**Mối quan hệ:**\n- Expected Error chứa thành phần Variance, đại diện cho lỗi do sự nhạy cảm của mô hình với dữ liệu huấn luyện.\n- Expected Error chứa thành phần Bias², đại diện cho lỗi do giả định đơn giản hóa của mô hình.\n- Model Complexity kiểm soát Bias: tăng độ phức tạp giúp giảm Bias (giảm underfitting), trong khi giảm độ phức tạp có thể làm tăng Bias.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n\n### Giới Thiệu\n\nLựa chọn đặc trưng (feature selection) và tối ưu hóa mô hình là các bước quan trọng trong việc xây dựng mô hình học máy hiệu quả. Chúng cải thiện hiệu suất mô hình, giảm overfitting, giảm thời gian huấn luyện và tăng khả năng diễn giải.\n\n**Tại sao quan trọng:**\n\n**1. Cải Thiện Hiệu Suất:**\n- Loại bỏ noise và đặc trưng không liên quan\n- Tăng accuracy và generalization\n- Mô hình tập trung vào signal thực sự\n\n**2. Giảm Overfitting:**\n- Ít đặc trưng → mô hình đơn giản hơn\n- Giảm variance\n- Better generalization\n\n**3. Giảm Thời Gian Training:**\n- Ít dữ liệu để xử lý\n- Training nhanh hơn\n- Prediction nhanh hơn\n\n**4. Tăng Khả Năng Diễn Giải:**\n- Dễ hiểu mô hình\n- Ít đặc trưng để phân tích\n- Better insights\n\n**5. Giảm Chi Phí:**\n- Ít đặc trưng cần thu thập\n- Tiết kiệm storage\n- Giảm computational resources\n\n### Lựa Chọn Đặc Trưng (Feature Selection)\n\nXác định các đặc trưng liên quan nhất cho việc xây dựng mô hình, giảm số chiều và cải thiện hiệu suất.\n\n**Ba nhóm phương pháp chính:**\n1. **Filter Methods:** Đánh giá độc lập với mô hình\n2. **Wrapper Methods:** Đánh giá bằng hiệu suất mô hình\n3. **Embedded Methods:** Lựa chọn trong quá trình training\n\n### Filter Methods (Phương Pháp Lọc)\n\nĐánh giá đặc trưng độc lập với mô hình sử dụng các đo lường thống kê.\n\n**Đặc điểm:**\n- Nhanh, hiệu quả\n- Không phụ thuộc vào thuật toán học\n- Tốt cho high-dimensional data\n- Có thể bỏ lỡ feature interactions\n\n**1. Correlation-Based Methods (Phương Pháp Dựa Trên Tương Quan):**\n\n**Pearson Correlation Coefficient:**\n$$r = \frac{\\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$\n\n- Giá trị: -1 đến +1\n- |r| gần 1: Tương quan mạnh\n- |r| gần 0: Không tương quan\n\n**Ứng dụng:**\n- **Feature-Target Correlation:** Chọn features có correlation cao với target\n- **Feature-Feature Correlation:** Loại bỏ features tương quan cao với nhau (multicollinearity)\n\n**Threshold:**\n- |r| > 0.8 hoặc 0.9: Multicollinearity\n- |r| < 0.1: Ít liên quan với target\n\n**Lưu ý:**\n- Chỉ bắt được mối quan hệ tuyến tính\n- Không phù hợp với categorical features\n- Có thể bỏ lỡ quan hệ phi tuyến\n\n**2. Statistical Tests (Kiểm Định Thống Kê):**\n\n\n**Các khái niệm quan trọng:**\n- Variance (Phương sai) là một thành phần của lỗi dự kiến trong học máy, đại diện cho lỗi do sự nhạy cảm của mô hình với các biến động nhỏ hoặc sự thay đổi trong dữ liệu huấn luyện. Nó đề cập đến mức độ mà một mô hình thay đổi khi được huấn luyện trên các tập dữ liệu huấn luyện khác nhau. High variance dẫn đến overfitting, nghĩa là mô hình học cả nhiễu trong dữ liệu huấn luyện, gây ra \"Different results với different data\". Để giảm variance, có thể giảm độ phức tạp của mô hình, tăng regularization, sử dụng nhiều dữ liệu hơn, hoặc giảm số lượng đặc trưng.\n\n**Mối quan hệ:**\n- Expected Error chứa thành phần Variance, đại diện cho lỗi do sự nhạy cảm của mô hình với dữ liệu huấn luyện.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n\n### Nhược Điểm\n\n**1. Dễ Overfitting:**\n- Cây sâu học cả noise\n- Mô hình phức tạp không generalize tốt\n- Cần pruning hoặc ensemble\n\n**2. Không Ổn Định:**\n- Thay đổi nhỏ trong dữ liệu → cây hoàn toàn khác\n- High variance\n- Giải pháp: Ensemble methods (Random Forest)\n\n**3. Thiên Vị Về Đặc Trưng Có Nhiều Mức:**\n- Đặc trưng với nhiều giá trị unique được ưu tiên\n- Information Gain thiên vị\n- Giải pháp: Gain Ratio (C4.5)\n\n**4. Không Tối Ưu Cho Extrapolation:**\n- Hồi quy chỉ dự đoán trong phạm vi training data\n- Không thể dự đoán ngoài min/max đã thấy\n- Dự đoán là hằng số ở nút lá\n\n**5. Tạo Cây Thiên Vị Với Imbalanced Data:**\n- Ưu tiên lớp đa số\n- Cần class_weight hoặc resampling\n\n**6. Greedy Algorithm:**\n- Chọn phân chia tốt nhất tại thời điểm hiện tại\n- Không đảm bảo cây tối ưu toàn cục\n- Có thể bỏ lỡ cây tốt hơn\n\n**7. Khó Bắt Mối Quan Hệ Tuyến Tính:**\n- Cần nhiều phân chia để xấp xỉ đường thẳng\n- Linear model đơn giản hơn cho quan hệ tuyến tính\n\n### Phương Pháp Ensemble Với Cây\n\n**1. Random Forest (Rừng Ngẫu Nhiên):**\n\n**Nguyên lý:**\n- Xây dựng nhiều cây quyết định\n- Mỗi cây trên bootstrap sample khác nhau\n- Random subset đặc trưng tại mỗi split\n- Kết hợp dự đoán: Voting (classification) hoặc averaging (regression)\n\n**Tham số chính:**\n- `n_estimators`: Số cây (50-500)\n- `max_features`: Số đặc trưng xem xét (sqrt(n) cho classification, n/3 cho regression)\n- `max_depth`: Độ sâu mỗi cây\n- `min_samples_split`, `min_samples_leaf`\n\n**Ưu điểm:**\n- Giảm variance, ít overfitting\n- Ổn định hơn cây đơn\n- Feature importance đáng tin cậy hơn\n- Xử lý tốt high-dimensional data\n- Out-of-bag error estimation\n\n**2. Gradient Boosting:**\n\n**Nguyên lý:**\n- Xây dựng cây tuần tự\n- Mỗi cây học sửa lỗi của cây trước\n- Mỗi cây nhỏ (weak learner)\n- Kết hợp có trọng số\n\n**Công thức:**\n$$F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$$\n\nTrong đó:\n- $F_m$ là mô hình tại iteration $m$\n- $h_m$ là cây mới\n- $\nu$ là learning rate\n\n**Implementations phổ biến:**\n- **XGBoost:** Nhanh, regularization tốt, xử lý missing values\n- **LightGBM:** Rất nhanh, hiệu quả bộ nhớ, leaf-wise growth\n- **CatBoost:** Tốt cho categorical features, ít overfitting\n\n**Ưu điểm:**\n- Hiệu suất cao nhất trong nhiều competition\n- Có thể đạt accuracy rất cao\n- Xử lý tốt heterogeneous features\n\n**Nhược điểm:**\n\n**Các khái niệm quan trọng:**\n- High variance là một vấn đề trong học máy khi mô hình quá nhạy cảm với các thay đổi nhỏ trong dữ liệu huấn luyện, dẫn đến sự thay đổi lớn trong mô hình được học. Đối với Cây Quyết định, high variance thể hiện ở việc một thay đổi nhỏ trong dữ liệu có thể dẫn đến một cây hoàn toàn khác. Vấn đề này khiến mô hình không ổn định. Giải pháp cho high variance là sử dụng các phương pháp ensemble như Random Forest.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n- CV cho stable estimate\n\n**1. K-Fold Cross-Validation:**\n\n**Thuật toán:**\n1. Chia data thành k folds\n2. For i = 1 to k:\n   - Use fold i làm validation\n   - Use k-1 folds còn lại làm training\n   - Train và evaluate\n3. Average metrics across k folds\n\n**Chọn k:**\n- k=5: Standard, good balance\n- k=10: More stable, more computational\n- Larger k: Less bias, more variance, more expensive\n\n**Ưu điểm:**\n- Sử dụng toàn bộ data\n- Stable estimate\n- Reduce variance\n\n**Nhược điểm:**\n- k lần training (expensive)\n- Có thể chậm\n\n**2. Stratified K-Fold:**\n\n**Nguyên lý:**\n- Maintain class distribution trong mỗi fold\n- Each fold representative\n\n**Khi nào dùng:**\n- Imbalanced datasets\n- Classification tasks\n- Đảm bảo mỗi fold có đủ samples mỗi class\n\n**Ưu điểm:**\n- Fair evaluation với imbalanced data\n- Consistent class proportions\n\n**3. Leave-One-Out (LOO):**\n\n**Nguyên lý:**\n- k = n (n = số samples)\n- Mỗi sample là một fold\n\n**Ưu điểm:**\n- Maximum data cho training\n- No randomness\n- Deterministic\n\n**Nhược điểm:**\n- Rất chậm (n iterations)\n- High variance\n- Chỉ khả thi với small datasets (< 1000)\n\n**Khi nào dùng:**\n- Very small datasets\n- Need maximum training data\n- Computational resources available\n\n**4. Time Series Cross-Validation:**\n\n**Nguyên lý:**\n- Respect temporal order\n- Train on past, validate on future\n- No data leakage from future\n\n**Expanding Window:**\n```\nFold 1: Train [1:100] → Test [101:120]\nFold 2: Train [1:120] → Test [121:140]\nFold 3: Train [1:140] → Test [141:160]\n```\n\n**Rolling Window:**\n```\nFold 1: Train [1:100] → Test [101:120]\nFold 2: Train [21:120] → Test [121:140]\nFold 3: Train [41:140] → Test [141:160]\n```\n\n**Quan trọng:**\n- **KHÔNG shuffle data**\n- Maintain temporal order\n- Avoid look-ahead bias\n\n**5. Nested Cross-Validation:**\n\n**Nguyên lý:**\n- Outer loop: Model evaluation\n- Inner loop: Hyperparameter tuning\n- Prevents overfitting in parameter selection\n\n**Structure:**\n```\nOuter CV (5-fold):\n  For each outer fold:\n    Inner CV (5-fold):\n      Hyperparameter tuning\n    Train with best params\n    Evaluate on outer fold\n```\n\n**Ưu điểm:**\n- Unbiased performance estimate\n- Proper hyperparameter tuning\n- Gold standard\n\n**Nhược điểm:**\n- Very expensive (k_outer × k_inner trainings)\n- Overkill cho simple problems\n\n**Khi nào dùng:**\n- Need unbiased estimate\n- Publishing results\n- Critical applications\n- Have computational resources\n\n### Learning Curves (Đường Cong Học)\n\nPhân tích hiệu suất mô hình vs kích thước training set.\n\n**Vẽ gì:**\n- X-axis: Training set size\n- Y-axis: Error (hoặc Score)\n- Two curves: Training error & Validation error\n\n**Chẩn Đoán:**\n\n**1. High Bias (Underfitting):**\n```\nTraining error: Cao\nValidation error: Cao\nGap: Nhỏ\nBoth plateau at high error\n```\n**Dấu hiệu:**\n- Cả hai curves plateau\n- Performance kém ngay cả với nhiều data\n- Thêm data không giúp\n\n**Giải pháp:**\n- Increase model complexity\n- Add features\n- Reduce regularization\n- Try complex model\n\n**2. High Variance (Overfitting):**\n```\nTraining error: Thấp\nValidation error: Cao\nGap: Lớn\nGap doesn't close with more data\n\n**Các khái niệm quan trọng:**\n- High Bias (thiên vị cao) là một vấn đề trong học máy, còn được gọi là Underfitting (học dưới mức). Nó xảy ra khi mô hình quá đơn giản để nắm bắt được mối quan hệ phức tạp trong dữ liệu, dẫn đến hiệu suất kém trên cả tập huấn luyện và tập validation. Trên Learning Curves, cả Training error và Validation error đều cao và có khoảng cách nhỏ, cả hai đường đều đạt đến một mức cao và không cải thiện khi thêm dữ liệu.\n\n**Mối quan hệ:**\n- Learning Curves chẩn đoán vấn đề High Bias (Underfitting) khi cả training error và validation error đều cao và có khoảng cách nhỏ, cả hai đường đều đạt đến một mức cao và không cải thiện khi thêm dữ liệu."
        },
        "output_without_context": {
            "question": "Trong đánh đổi giữa độ lệch và phương sai, điều gì xảy ra khi độ lệch giảm xuống?",
            "answer": "Phương sai thường tăng lên."
        }
    },
    {
        "topic_description": "Chủ đề này thảo luận về Lựa chọn đặc trưng (Feature Selection) như một kỹ thuật quan trọng trong tối ưu hóa mô hình. Học sinh sẽ phải nắm vững các phương pháp có giám sát và không giám sát, cùng các ví dụ áp dụng cụ thể từ thực tiễn, tương tự như khái niệm Information Gain và các phương pháp Wrapper, Filter, Embedded.",
        "output_with_context": {
            "question": "Trong phương pháp Lựa Chọn Đặc Trưng, công thức nào được sử dụng để tính độ lợi thông tin giữa biến mục tiêu Y và đặc trưng X?",
            "answer": "IG(Y|X) = H(Y) - H(Y|X)",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n**Chi-squared Test ($\\chi^2$) - Cho Categorical Features:**\n$$\\chi^2 = \\sum_{i,j}\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$\n\nTrong đó:\n- $O_{ij}$ là observed frequency\n- $E_{ij}$ là expected frequency\n\n**Khi nào dùng:**\n- Cả feature và target đều categorical\n- Test độc lập giữa feature và target\n- P-value nhỏ: Feature quan trọng\n\n**ANOVA F-test - Cho Continuous Features, Classification:**\n$$F = \frac{MS_{between}}{MS_{within}}$$\n\n- Test khác biệt means giữa các groups\n- Continuous features, categorical target\n- F-statistic cao: Feature discriminative\n\n**Mutual Information (Thông Tin Tương Hỗ):**\n$$MI(X,Y) = \\sum_{x \\in X}\\sum_{y \\in Y}P(x,y)\\log\frac{P(x,y)}{P(x)P(y)}$$\n\n**Đặc điểm:**\n- Đo lường phụ thuộc giữa hai biến\n- Bắt được cả quan hệ phi tuyến\n- Giá trị ≥ 0\n- MI = 0: Độc lập\n- MI cao: Phụ thuộc mạnh\n\n**Ưu điểm:**\n- Không giả định về phân phối\n- Bắt được quan hệ phức tạp\n- Phù hợp với mọi loại dữ liệu\n\n**Variance Threshold:**\n- Loại bỏ features có variance thấp\n- Low variance → ít thông tin\n- Threshold: Variance < 0.01 hoặc 0.1\n- Đặc biệt hữu ích cho sparse data\n\n**3. Information Gain (Độ Lợi Thông Tin):**\n$$IG(Y|X) = H(Y) - H(Y|X)$$\n\nTrong đó:\n- $H(Y)$ là entropy của target\n- $H(Y|X)$ là conditional entropy của Y cho trước X\n\n**Diễn giải:**\n- Giảm uncertainty về Y khi biết X\n- Cao hơn → Feature quan trọng hơn\n- Dựa trên entropy từ Decision Trees\n\n**Ưu điểm Filter Methods:**\n- Rất nhanh\n- Scale tốt với nhiều features\n- Độc lập với model\n- Không overfit\n\n**Nhược điểm:**\n- Không xem xét feature interactions\n- Bỏ qua model-specific patterns\n- Có thể loại bỏ features hữu ích\n\n### Wrapper Methods (Phương Pháp Bao)\n\nĐánh giá subsets đặc trưng bằng hiệu suất mô hình.\n\n**Đặc điểm:**\n- Sử dụng mô hình cụ thể để đánh giá\n- Xem xét feature interactions\n- Chậm hơn filter methods\n- Có thể overfit nếu không cẩn thận\n\n**1. Forward Selection (Lựa Chọn Tiến):**\n\n**Thuật toán:**\n1. Bắt đầu với tập rỗng: $S = \\emptyset$\n2. Với mỗi feature $f$ chưa chọn:\n   - Training model với $S \\cup \\{f\\}$\n   - Đánh giá performance\n3. Thêm feature tốt nhất vào $S$\n4. Lặp lại cho đến khi đạt điều kiện dừng\n\n**Điều kiện dừng:**\n- Đạt số features mong muốn\n- Performance không cải thiện\n- Tất cả features đã thêm\n\n**Ưu điểm:**\n- Đơn giản, trực quan\n- Tốt khi số features quan trọng nhỏ\n- Bắt đầu từ đơn giản\n\n**Nhược điểm:**\n- Không thể remove features đã thêm\n\n**Các khái niệm quan trọng:**\n- Forward Selection (Lựa Chọn Tiến) là một thuật toán lựa chọn đặc trưng thuộc nhóm Wrapper Methods. Nó bắt đầu với một tập đặc trưng rỗng ($S = \\emptyset$), sau đó lặp đi lặp lại thêm feature tốt nhất (dựa trên hiệu suất mô hình) vào tập $S$ cho đến khi đạt điều kiện dừng (ví dụ: đạt số features mong muốn hoặc performance không cải thiện). Ưu điểm là đơn giản, trực quan và tốt khi số features quan trọng nhỏ, nhưng không thể loại bỏ các features đã thêm.\n\n**Mối quan hệ:**\n- Forward Selection (Lựa Chọn Tiến) sử dụng quá trình Training model để đánh giá hiệu suất của các tập con đặc trưng.\n- Forward Selection (Lựa Chọn Tiến) sử dụng quá trình Đánh giá performance để chọn feature tốt nhất.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n\n### Giới Thiệu\n\nLựa chọn đặc trưng (feature selection) và tối ưu hóa mô hình là các bước quan trọng trong việc xây dựng mô hình học máy hiệu quả. Chúng cải thiện hiệu suất mô hình, giảm overfitting, giảm thời gian huấn luyện và tăng khả năng diễn giải.\n\n**Tại sao quan trọng:**\n\n**1. Cải Thiện Hiệu Suất:**\n- Loại bỏ noise và đặc trưng không liên quan\n- Tăng accuracy và generalization\n- Mô hình tập trung vào signal thực sự\n\n**2. Giảm Overfitting:**\n- Ít đặc trưng → mô hình đơn giản hơn\n- Giảm variance\n- Better generalization\n\n**3. Giảm Thời Gian Training:**\n- Ít dữ liệu để xử lý\n- Training nhanh hơn\n- Prediction nhanh hơn\n\n**4. Tăng Khả Năng Diễn Giải:**\n- Dễ hiểu mô hình\n- Ít đặc trưng để phân tích\n- Better insights\n\n**5. Giảm Chi Phí:**\n- Ít đặc trưng cần thu thập\n- Tiết kiệm storage\n- Giảm computational resources\n\n### Lựa Chọn Đặc Trưng (Feature Selection)\n\nXác định các đặc trưng liên quan nhất cho việc xây dựng mô hình, giảm số chiều và cải thiện hiệu suất.\n\n**Ba nhóm phương pháp chính:**\n1. **Filter Methods:** Đánh giá độc lập với mô hình\n2. **Wrapper Methods:** Đánh giá bằng hiệu suất mô hình\n3. **Embedded Methods:** Lựa chọn trong quá trình training\n\n### Filter Methods (Phương Pháp Lọc)\n\nĐánh giá đặc trưng độc lập với mô hình sử dụng các đo lường thống kê.\n\n**Đặc điểm:**\n- Nhanh, hiệu quả\n- Không phụ thuộc vào thuật toán học\n- Tốt cho high-dimensional data\n- Có thể bỏ lỡ feature interactions\n\n**1. Correlation-Based Methods (Phương Pháp Dựa Trên Tương Quan):**\n\n**Pearson Correlation Coefficient:**\n$$r = \frac{\\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$\n\n- Giá trị: -1 đến +1\n- |r| gần 1: Tương quan mạnh\n- |r| gần 0: Không tương quan\n\n**Ứng dụng:**\n- **Feature-Target Correlation:** Chọn features có correlation cao với target\n- **Feature-Feature Correlation:** Loại bỏ features tương quan cao với nhau (multicollinearity)\n\n**Threshold:**\n- |r| > 0.8 hoặc 0.9: Multicollinearity\n- |r| < 0.1: Ít liên quan với target\n\n**Lưu ý:**\n- Chỉ bắt được mối quan hệ tuyến tính\n- Không phù hợp với categorical features\n- Có thể bỏ lỡ quan hệ phi tuyến\n\n**2. Statistical Tests (Kiểm Định Thống Kê):**\n\n\n**Các khái niệm quan trọng:**\n- Feature Selection (Lựa chọn đặc trưng) là một kỹ thuật trong học máy nhằm chọn ra một tập hợp con các đặc trưng phù hợp, liên quan và quan trọng nhất từ tập dữ liệu gốc. Mục tiêu chính của kỹ thuật này là giảm số chiều dữ liệu (dimensionality), loại bỏ các đặc trưng không liên quan, dư thừa hoặc nhiễu, từ đó cải thiện hiệu suất mô hình, giảm overfitting (giảm High Variance), tăng tốc độ và giảm thời gian huấn luyện, cũng như tăng khả năng diễn giải của mô hình. Các phương pháp Feature Selection bao gồm filter methods, wrapper methods và embedded methods (như Lasso). Trong ngữ cảnh Cây Quyết Định, Feature Importance được sử dụng như một công cụ tự nhiên để thực hiện feature selection, và Decision Tree cũng có thể được sử dụng trực tiếp cho mục đích này. Trong k-NN, Feature Selection giúp giảm \"curse of dimensionality\".\n- Feature-Target Correlation và Feature-Feature Correlation là hai kỹ thuật lựa chọn đặc trưng. Feature-Target Correlation đánh giá mối quan hệ giữa từng đặc trưng và biến mục tiêu bằng cách tính hệ số tương quan, giữ lại các đặc trưng có hệ số tương quan cao do khả năng dự đoán tốt. Ngược lại, Feature-Feature Correlation tính toán hệ số tương quan giữa các cặp đặc trưng với nhau, loại bỏ các đặc trưng có hệ số tương quan cao (đa cộng tuyến) để tránh dư thừa thông tin và cải thiện sự ổn định của mô hình.\n\n**Mối quan hệ:**\n- Wrapper Methods là một trong ba nhóm phương pháp chính mà Feature Selection áp dụng để lựa chọn đặc trưng.\n- Filter Methods là một trong ba nhóm phương pháp chính mà Feature Selection áp dụng để lựa chọn đặc trưng.\n- Embedded Methods là một trong ba nhóm phương pháp chính mà Feature Selection áp dụng để lựa chọn đặc trưng.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n1. Xây dựng cây đầy đủ\n2. Tính $\\alpha$ cho mỗi subtree\n3. Loại bỏ subtree có $\\alpha$ nhỏ nhất (đóng góp ít nhất)\n4. Lặp lại cho đến khi còn gốc\n5. Chọn cây tối ưu bằng cross-validation\n\n**Ưu điểm:**\n- Thường cho kết quả tốt hơn pre-pruning\n- Không bỏ lỡ phân chia tốt\n\n**Nhược điểm:**\n- Tốn thời gian (xây dựng cây đầy đủ trước)\n- Phức tạp hơn\n\n### Feature Importance (Tầm Quan Trọng Đặc Trưng)\n\nCây quyết định tự động tính toán mức độ quan trọng của mỗi đặc trưng.\n\n**Công Thức:**\n$$Importance(f) = \\sum_{t \\in T} p(t) \\cdot \\Delta impurity(t, f)$$\n\nTrong đó:\n- $p(t)$ là tỷ lệ mẫu tại nút $t$\n- $\\Delta impurity(t, f)$ là giảm impurity khi phân chia theo đặc trưng $f$ tại nút $t$\n- Tổng trên tất cả nút sử dụng đặc trưng $f$\n\n**Diễn giải:**\n- Giá trị càng cao, đặc trưng càng quan trọng\n- Tổng tất cả importance = 1\n- Đặc trưng không xuất hiện có importance = 0\n\n**Ứng dụng:**\n- Feature selection\n- Hiểu mô hình\n- Phát hiện đặc trưng không cần thiết\n- Giải thích cho stakeholders\n\n**Lưu ý:**\n- Thiên vị về đặc trưng có nhiều giá trị unique\n- Đặc trưng tương quan cao có importance phân tán\n- Sử dụng permutation importance để khắc phục\n\n### Ưu Điểm Của Cây Quyết Định\n\n**1. Dễ hiểu và diễn giải:**\n- Trực quan, giống cách con người quyết định\n- Có thể vẽ và giải thích bằng lời\n- Không cần kiến thức thống kê sâu\n- Phù hợp cho business users\n\n**2. Yêu cầu ít tiền xử lý dữ liệu:**\n- Không cần feature scaling\n- Không cần one-hot encoding cho categorical\n- Xử lý được missing values (surrogate splits)\n- Không cần assumption về phân phối\n\n**3. Xử lý dữ liệu số và phân loại:**\n- Linh hoạt với nhiều loại đặc trưng\n- Không cần encoding phức tạp\n- Mixed data types\n\n**4. Non-parametric:**\n- Không giả định về phân phối dữ liệu\n- Linh hoạt với mọi dạng data\n- Không cần chọn hàm phân phối\n\n**5. Bắt được mối quan hệ phi tuyến:**\n- Decision boundary phức tạp\n- Tương tác giữa các đặc trưng\n- Không giới hạn bởi tuyến tính\n\n**6. Tính toán Feature Importance tự nhiên:**\n- Không cần phương pháp bên ngoài\n- Tích hợp trong thuật toán\n\n**7. Nhanh với dự đoán:**\n- Độ phức tạp: O(log n) với cây cân bằng\n- Hiệu quả cho production\n\n**Các khái niệm quan trọng:**\n- Feature Selection (Lựa chọn đặc trưng) là một kỹ thuật trong học máy nhằm chọn ra một tập hợp con các đặc trưng phù hợp, liên quan và quan trọng nhất từ tập dữ liệu gốc. Mục tiêu chính của kỹ thuật này là giảm số chiều dữ liệu (dimensionality), loại bỏ các đặc trưng không liên quan, dư thừa hoặc nhiễu, từ đó cải thiện hiệu suất mô hình, giảm overfitting (giảm High Variance), tăng tốc độ và giảm thời gian huấn luyện, cũng như tăng khả năng diễn giải của mô hình. Các phương pháp Feature Selection bao gồm filter methods, wrapper methods và embedded methods (như Lasso). Trong ngữ cảnh Cây Quyết Định, Feature Importance được sử dụng như một công cụ tự nhiên để thực hiện feature selection, và Decision Tree cũng có thể được sử dụng trực tiếp cho mục đích này. Trong k-NN, Feature Selection giúp giảm \"curse of dimensionality\".\n- Feature selection là kỹ thuật chọn một tập hợp con các đặc trưng (features) quan trọng nhất từ tập dữ liệu gốc để sử dụng trong mô hình. Lasso Regression có khả năng thực hiện feature selection tự động bằng cách đưa các hệ số của các đặc trưng không quan trọng về 0.\n\n**Mối quan hệ:**\n- Feature Importance được ứng dụng trong feature selection để chọn ra các đặc trưng quan trọng nhất.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n**Đặc điểm:**\n- Đưa một số coefficients về chính xác 0\n- Automatic feature selection\n- Sparse solutions\n\n**Tại sao L1 tạo sparsity:**\n- L1 penalty có góc nhọn tại 0\n- Optimization dễ chạm đến 0\n- L2 có hình tròn → không về 0\n\n**Ưu điểm:**\n- Tự động và efficient\n- Feature selection + training cùng lúc\n- Tốt cho high-dimensional data\n- Diễn giải dễ (chỉ giữ features quan trọng)\n\n**Nhược điểm:**\n- Có thể chọn ngẫu nhiên giữa correlated features\n- Không stable với correlated features\n- Sensitive to scaling\n\n**Tuning:**\n- $\\lambda$ (alpha trong sklearn)\n- Cross-validation để chọn\n- LassoCV: Automatic tuning\n\n**2. Tree-Based Feature Importance:**\n\n**Random Forest Feature Importance:**\n$$Importance_j = \frac{1}{N_T}\\sum_{T}\\sum_{t \\in T}\\mathbb{1}_{split(t)=j} \\cdot \\Delta impurity(t)$$\n\n**Đặc điểm:**\n- Dựa trên giảm impurity\n- Average across all trees\n- Normalized to sum to 1\n\n**Gradient Boosting Feature Importance:**\n- Tương tự RF nhưng weighted\n- Trees sau có ảnh hưởng khác\n- Thường reliable hơn RF\n\n**Ưu điểm:**\n- Capture non-linear relationships\n- Handle feature interactions\n- Không cần feature scaling\n- Built-in trong tree models\n\n**Nhược điểm:**\n- Thiên vị về high-cardinality features\n- Không reliable với correlated features\n- Khác nhau giữa random states\n\n**Cải thiện - Permutation Importance:**\n- Shuffle feature và đo impact\n- Không thiên vị\n- Computationally expensive\n\n**3. Elastic Net:**\n$$J(\beta) = MSE + \\lambda_1\\sum_{j=1}^{n}|\beta_j| + \\lambda_2\\sum_{j=1}^{n}\beta_j^2$$\n\n**Đặc điểm:**\n- Kết hợp L1 và L2\n- Balance giữa feature selection và shrinkage\n- Tốt hơn Lasso với correlated features\n\n**Tham số:**\n- $\\alpha$: Tổng strength của regularization\n- $l1\\_ratio$: Tỷ lệ L1 vs L2\n  - $l1\\_ratio = 1$: Pure Lasso\n  - $l1\\_ratio = 0$: Pure Ridge\n  - $l1\\_ratio = 0.5$: Equal mix\n\n**Khi nào dùng:**\n- Correlated features\n- Muốn cả feature selection và shrinkage\n- Groups of correlated features (chọn cả group)\n\n**So sánh Embedded Methods:**\n\n| Method | Type | Feature Selection | Best for |\n|--------|------|------------------|----------|\n| Lasso | Linear | Strong | High-dim, independent features |\n| Elastic Net | Linear | Moderate | Correlated features |\n| RF Importance | Tree | Moderate | Non-linear, interactions |\n| GB Importance | Tree | Strong | Complex relationships |\n\n### Giảm Số Chiều (Dimensionality Reduction)\n\nBiến đổi đặc trưng sang không gian ít chiều hơn.\n\n**Feature Selection vs Dimensionality Reduction:**\n- **Feature Selection:** Giữ subset features gốc\n- **Dimensionality Reduction:** Tạo features mới (combinations)\n\n**1. Principal Component Analysis (PCA):**\n\n**Nguyên lý:**\n- Biến đổi tuyến tính sang orthogonal components\n- Components sắp xếp theo variance\n- Component đầu tiên: Direction của maximum variance\n\n**Toán học:**\n$$X_{reduced} = X \\cdot W_k$$\n\nTrong đó $W_k$ là matrix của k eigenvectors hàng đầu.\n\n**Thuật toán:**\n1. Standardize data\n2. Tính covariance matrix: $\\Sigma = \frac{1}{n}X^TX$\n\n**Các khái niệm quan trọng:**\n- Feature Selection (Lựa chọn đặc trưng) là một kỹ thuật trong học máy nhằm chọn ra một tập hợp con các đặc trưng phù hợp, liên quan và quan trọng nhất từ tập dữ liệu gốc. Mục tiêu chính của kỹ thuật này là giảm số chiều dữ liệu (dimensionality), loại bỏ các đặc trưng không liên quan, dư thừa hoặc nhiễu, từ đó cải thiện hiệu suất mô hình, giảm overfitting (giảm High Variance), tăng tốc độ và giảm thời gian huấn luyện, cũng như tăng khả năng diễn giải của mô hình. Các phương pháp Feature Selection bao gồm filter methods, wrapper methods và embedded methods (như Lasso). Trong ngữ cảnh Cây Quyết Định, Feature Importance được sử dụng như một công cụ tự nhiên để thực hiện feature selection, và Decision Tree cũng có thể được sử dụng trực tiếp cho mục đích này. Trong k-NN, Feature Selection giúp giảm \"curse of dimensionality\".\n\n**Mối quan hệ:**\n- Wrapper Methods là một trong ba nhóm phương pháp chính mà Feature Selection áp dụng để lựa chọn đặc trưng.\n- Filter Methods là một trong ba nhóm phương pháp chính mà Feature Selection áp dụng để lựa chọn đặc trưng."
        },
        "output_without_context": {
            "question": "Trong các phương pháp lựa chọn đặc trưng, phương pháp nào sử dụng thông tin từ mô hình để đánh giá độ quan trọng của các đặc trưng?",
            "answer": "Phương pháp Embedded"
        }
    },
    {
        "topic_description": "Chủ đề này tìm hiểu về điều chuẩn (Regularization) như một kỹ thuật giảm thiểu hiện tượng quá khớp. Học sinh sẽ được kiểm tra khả năng hiểu các phương pháp điều chuẩn khác nhau như Lasso và Rigid Regression, công thức liên quan, và ứng dụng thực tế trong việc cải thiện mô hình học máy.",
        "output_with_context": {
            "question": "Trong kỹ thuật hồi quy Lasso, thành phần phạt nào được thêm vào hàm chi phí để thực hiện việc chọn đặc trưng tự động?",
            "answer": "Tổng giá trị tuyệt đối của các hệ số.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n```\n**Dấu hiệu:**\n- Large gap giữa curves\n- Training error tiếp tục giảm\n- Validation error không cải thiện\n\n**Giải pháp:**\n- Get more training data\n- Reduce model complexity\n- Increase regularization\n- Feature selection\n- Dropout, early stopping\n\n**3. Good Fit:**\n```\nTraining error: Thấp\nValidation error: Thấp\nGap: Nhỏ\nBoth converge\n```\n**Dấu hiệu:**\n- Small gap\n- Both errors low\n- Converged performance\n\n**4. More Data Helps:**\n```\nValidation error giảm khi tăng data\nGap đang đóng lại\nChưa plateau\n```\n**Hành động:** Get more data!\n\n**5. More Data Doesn't Help:**\n```\nBoth curves plateau\nAdding data không cải thiện\n```\n**Hành động:** Improve features hoặc model\n\n### Bias-Variance Tradeoff (Sự Đánh Đổi Bias-Variance)\n\n**Công thức:**\n$$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$\n\n**Bias (Thiên Lệch):**\n- Error từ giả định đơn giản hóa\n- Underfitting\n- Model không capture được patterns\n- High bias → Systematic errors\n\n**Variance (Phương Sai):**\n- Error từ sensitivity to training data\n- Overfitting\n- Model learns noise\n- High variance → Different results với different data\n\n**Irreducible Error:**\n- Noise trong data\n- Không thể giảm\n- Comes from data collection\n\n**Tradeoff:**\n- Decrease bias → Increase variance\n- Decrease variance → Increase bias\n- Cần balance\n\n**Strategies:**\n\n**Giảm High Bias:**\n1. Increase model complexity\n2. Add more features/polynomial features\n3. Decrease regularization\n4. Train longer\n5. Use ensemble methods\n\n**Giảm High Variance:**\n1. Get more training data\n2. Reduce model complexity\n3. Increase regularization (L1, L2, dropout)\n4. Feature selection\n5. Early stopping\n6. Ensemble methods (bagging)\n\n**Sweet Spot:**\n- Minimize total error\n- Balance bias và variance\n- Depends on problem và data\n\n**Visualize:**\n```\nTotal Error\n    |     \\\n    |      \\___Bias²\n    |___________\\\n    |            \\___\n    |Variance_____\\___Total\n    |________________\\___\n    |___________________\\___\n    +----------------------->\n    Simple          Complex\n            Model Complexity\n```\n\n### Phương Pháp Ensemble\n\nKết hợp nhiều models để cải thiện hiệu suất.\n\n**\"Wisdom of crowds\"**\n\n**Tại sao hoạt động:**\n- Errors của individual models cancel out\n- Diverse models capture different patterns\n- Reduce variance\n- More robust\n\n**1. Bagging (Bootstrap Aggregating):**\n\n**Nguyên lý:**\n- Train multiple models trên bootstrap samples\n- Average predictions (regression) hoặc vote (classification)\n\n**Bootstrap Sampling:**\n- Sample with replacement\n- Same size as original\n- ~63% unique samples mỗi bootstrap\n\n**Thuật toán:**\n1. For i = 1 to M:\n   - Create bootstrap sample $D_i$\n   - Train model $M_i$ on $D_i$\n2. Combine:\n   - Regression: $\\hat{y} = \frac{1}{M}\\sum_{i=1}^{M}M_i(x)$\n   - Classification: Majority vote\n\n**Ưu điểm:**\n- Reduce variance\n- Parallel training\n- Works với high-variance models\n\n**Nhược điểm:**\n- Không giảm bias\n- Có thể chậm (many models)\n\n**Ví dụ:** Random Forest\n\n**2. Boosting:**\n\n**Nguyên lý:**\n- Sequential training\n- Each model corrects errors của previous models\n- Weighted combination\n\n**Thuật toán (general):**\n1. Initialize equal weights\n2. For i = 1 to M:\n   - Train model $M_i$ on weighted data\n   - Tính error\n   - Update weights (increase for misclassified)\n\n**Các khái niệm quan trọng:**\n- Regularization là một kỹ thuật được sử dụng trong Continual Learning (ví dụ: EWC) để ngăn chặn Catastrophic Forgetting bằng cách thêm các ràng buộc hoặc penalty vào hàm loss, khuyến khích mô hình giữ lại các tham số quan trọng cho các tác vụ cũ khi học các tác vụ mới.\n- Regularization là một kỹ thuật quan trọng trong học máy được sử dụng để ngăn chặn overfitting và cải thiện khả năng tổng quát hóa của mô hình trên dữ liệu mới. Kỹ thuật này hoạt động bằng cách thêm một \"penalty term\" (thành phần phạt) vào hàm loss (hàm chi phí) của mô hình. Penalty term này khuyến khích mô hình có các tham số (weights/hệ số) nhỏ hơn, đơn giản hơn hoặc ít phức tạp hơn, từ đó hạn chế độ lớn của chúng. Điều này giúp mô hình học các mẫu tổng quát hơn thay vì ghi nhớ dữ liệu huấn luyện. Tăng regularization giúp giảm variance (overfitting), trong khi giảm regularization giúp giảm bias (underfitting). Regularization cũng có thể giúp giải quyết vấn đề đa cộng tuyến. Các loại regularization phổ biến bao gồm L1 (Lasso), L2 (Ridge) và Dropout. Trong các mô hình như SVM/SVR, tham số C đóng vai trò là một dạng regularization tích hợp, kiểm soát mức độ mà mô hình được phép mắc lỗi trên dữ liệu huấn luyện; giá trị C nhỏ tương đương với regularization mạnh hơn. Feature Scaling là cần thiết để đảm bảo regularization hoạt động đúng, không thiên vị các đặc trưng có độ lớn lớn. Một số mô hình như XGBoost tích hợp sẵn regularization, và các kỹ thuật như Pooling (đặc biệt là Global Average Pooling) cũng có tác dụng regularization bằng cách giảm số lượng tham số và độ phức tạp của mô hình.\n\n**Mối quan hệ:**\n- Regularization là kỹ thuật giúp giảm overfitting bằng cách thêm penalty vào hàm chi phí, khuyến khích mô hình học các patterns tổng quát hơn.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n- Giải pháp nếu vi phạm: Biến đổi đặc trưng (log, căn bậc hai, đa thức)\n\n**2. Tính Độc Lập (Independence):**\n- Các quan sát độc lập với nhau\n- Quan trọng với dữ liệu chuỗi thời gian\n- Vi phạm: Tự tương quan (autocorrelation)\n- Kiểm tra: Durbin-Watson test\n\n**3. Phương Sai Đồng Nhất (Homoscedasticity):**\n- Phương sai của phần dư không đổi theo giá trị dự đoán\n- Kiểm tra: Vẽ biểu đồ phần dư vs giá trị dự đoán\n- Nếu vi phạm (heteroscedasticity): Sử dụng weighted least squares hoặc biến đổi log\n\n**4. Tính Chuẩn (Normality):**\n- Phần dư tuân theo phân phối chuẩn\n- Kiểm tra: Q-Q plot, Shapiro-Wilk test\n- Quan trọng cho suy diễn thống kê (khoảng tin cậy, kiểm định giả thuyết)\n\n**5. Không Có Đa Cộng Tuyến (No Multicollinearity):**\n- Các đặc trưng không tương quan cao với nhau\n- Kiểm tra: VIF (Variance Inflation Factor)\n- VIF > 10 cho thấy đa cộng tuyến nghiêm trọng\n- Giải pháp: Loại bỏ đặc trưng tương quan cao, PCA, regularization\n\n**Công Thức VIF:**\n$$VIF_j = \frac{1}{1 - R_j^2}$$\nTrong đó $R_j^2$ là $R^2$ khi hồi quy $x_j$ với các đặc trưng còn lại.\n\n### Tối Ưu Hóa Bằng Gradient Descent\n\nGradient Descent là phương pháp lặp để tìm hệ số tối ưu, đặc biệt hữu ích với dữ liệu lớn.\n\n**Thuật Toán:**\n$$\beta_j := \beta_j - \\alpha\frac{\\partial J(\beta)}{\\partial\beta_j}$$\n\nTrong đó:\n- $\\alpha$ là tốc độ học (learning rate)\n- $\frac{\\partial J(\beta)}{\\partial\beta_j}$ là đạo hàm riêng của hàm chi phí\n\n**Đạo Hàm Riêng:**\n$$\frac{\\partial J(\beta)}{\\partial\beta_j} = \frac{1}{m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n\n**Các Loại Gradient Descent:**\n\n**1. Batch Gradient Descent:**\n- Sử dụng toàn bộ tập dữ liệu trong mỗi lần cập nhật\n- Ưu điểm: Hội tụ ổn định, tối ưu toàn cục\n- Nhược điểm: Chậm với dữ liệu lớn\n- Công thức cập nhật: $\beta := \beta - \\alpha\nabla J(\beta)$\n\n**2. Stochastic Gradient Descent (SGD):**\n- Sử dụng từng mẫu một để cập nhật\n- Ưu điểm: Nhanh, có thể thoát khỏi cực tiểu địa phương\n- Nhược điểm: Dao động nhiều, không hội tụ chính xác\n- Phù hợp: Dữ liệu rất lớn, học trực tuyến\n\n**3. Mini-batch Gradient Descent:**\n- Sử dụng các batch nhỏ (thường 32-256 mẫu)\n\n**Các khái niệm quan trọng:**\n- Regularization là một kỹ thuật được sử dụng trong Continual Learning (ví dụ: EWC) để ngăn chặn Catastrophic Forgetting bằng cách thêm các ràng buộc hoặc penalty vào hàm loss, khuyến khích mô hình giữ lại các tham số quan trọng cho các tác vụ cũ khi học các tác vụ mới.\n- Regularization là một kỹ thuật quan trọng trong học máy được sử dụng để ngăn chặn overfitting và cải thiện khả năng tổng quát hóa của mô hình trên dữ liệu mới. Kỹ thuật này hoạt động bằng cách thêm một \"penalty term\" (thành phần phạt) vào hàm loss (hàm chi phí) của mô hình. Penalty term này khuyến khích mô hình có các tham số (weights/hệ số) nhỏ hơn, đơn giản hơn hoặc ít phức tạp hơn, từ đó hạn chế độ lớn của chúng. Điều này giúp mô hình học các mẫu tổng quát hơn thay vì ghi nhớ dữ liệu huấn luyện. Tăng regularization giúp giảm variance (overfitting), trong khi giảm regularization giúp giảm bias (underfitting). Regularization cũng có thể giúp giải quyết vấn đề đa cộng tuyến. Các loại regularization phổ biến bao gồm L1 (Lasso), L2 (Ridge) và Dropout. Trong các mô hình như SVM/SVR, tham số C đóng vai trò là một dạng regularization tích hợp, kiểm soát mức độ mà mô hình được phép mắc lỗi trên dữ liệu huấn luyện; giá trị C nhỏ tương đương với regularization mạnh hơn. Feature Scaling là cần thiết để đảm bảo regularization hoạt động đúng, không thiên vị các đặc trưng có độ lớn lớn. Một số mô hình như XGBoost tích hợp sẵn regularization, và các kỹ thuật như Pooling (đặc biệt là Global Average Pooling) cũng có tác dụng regularization bằng cách giảm số lượng tham số và độ phức tạp của mô hình.\n\n**Mối quan hệ:**\n- Regularization là kỹ thuật giúp giảm overfitting bằng cách thêm penalty vào hàm chi phí, khuyến khích mô hình học các patterns tổng quát hơn.\n- Regularization là một kỹ thuật ngăn chặn Overfitting bằng cách thêm thành phần phạt vào hàm loss, khuyến khích mô hình đơn giản hơn và tổng quát hóa tốt hơn.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n| Hệ số về 0 | Gần 0 | Chính xác 0 |\n| Đa cộng tuyến | Tốt | Chọn ngẫu nhiên 1 trong nhóm |\n| Nghiệm đóng | Có | Không |\n| Mô hình | Dense | Sparse |\n\n### Cân Nhắc Thực Tế\n\n**1. Feature Scaling (Chuẩn Hóa Đặc Trưng):**\n\n**Tại sao cần thiết:**\n- Gradient descent hội tụ nhanh hơn\n- Các đặc trưng có tầm ảnh hưởng công bằng\n- Regularization hoạt động đúng (không thiên vị về đặc trưng có độ lớn lớn)\n\n**Phương pháp:**\n\n**Standardization (Z-score normalization):**\n$$x_{scaled} = \frac{x - \\mu}{\\sigma}$$\n- Kết quả: Trung bình = 0, độ lệch chuẩn = 1\n- Phù hợp khi dữ liệu có phân phối gần chuẩn\n- Không bị ảnh hưởng bởi outliers nhiều\n\n**Min-Max Normalization:**\n$$x_{scaled} = \frac{x - x_{min}}{x_{max} - x_{min}}$$\n- Kết quả: Giá trị trong khoảng [0, 1]\n- Nhạy cảm với outliers\n- Phù hợp khi cần giới hạn trong khoảng cụ thể\n\n**2. Phát Hiện Outliers:**\n\n**Phương pháp:**\n- **Residual plots:** Vẽ biểu đồ phần dư\n- **Cook's distance:** Đo lường ảnh hưởng của từng điểm\n  - $D_i > \frac{4}{n}$ cho thấy điểm có ảnh hưởng cao\n- **Leverage:** Điểm xa trung tâm dữ liệu\n- **Studentized residuals:** Phần dư chuẩn hóa\n\n**Xử lý outliers:**\n- Kiểm tra xem có phải lỗi dữ liệu không\n- Xem xét loại bỏ hoặc biến đổi\n- Sử dụng robust regression (ít nhạy cảm với outliers)\n\n**3. Feature Engineering (Kỹ Thuật Đặc Trưng):**\n\n**Polynomial Features (Đặc trưng đa thức):**\n- Tạo mối quan hệ phi tuyến từ đặc trưng tuyến tính\n- Ví dụ: $x_1, x_2 \rightarrow x_1, x_2, x_1^2, x_1x_2, x_2^2$\n- Tăng khả năng biểu diễn nhưng dễ overfitting\n\n**Interaction terms (Tương tác):**\n- Tích của hai đặc trưng\n- Ví dụ: Diện tích × Vị trí trong dự đoán giá nhà\n\n**Logarithmic transformation:**\n- Giảm skewness (độ lệch)\n- Xử lý mối quan hệ exponential\n- Ví dụ: Thu nhập, giá nhà thường lệch phải\n\n**4. Cross-Validation (Kiểm Định Chéo):**\n\n**K-Fold Cross-Validation:**\n- Chia dữ liệu thành k phần\n- Lần lượt sử dụng mỗi phần làm validation set\n- Trung bình kết quả từ k lần\n- Thường dùng k = 5 hoặc k = 10\n\n**Lợi ích:**\n- Đánh giá chính xác hơn\n- Sử dụng toàn bộ dữ liệu cho cả training và validation\n- Phát hiện overfitting/underfitting\n- Chọn hyperparameter tối ưu\n\n**5. Chẩn Đoán Mô Hình:**\n\n\n**Các khái niệm quan trọng:**\n- Regularization là một kỹ thuật được sử dụng trong Continual Learning (ví dụ: EWC) để ngăn chặn Catastrophic Forgetting bằng cách thêm các ràng buộc hoặc penalty vào hàm loss, khuyến khích mô hình giữ lại các tham số quan trọng cho các tác vụ cũ khi học các tác vụ mới.\n- Regularization là một kỹ thuật quan trọng trong học máy được sử dụng để ngăn chặn overfitting và cải thiện khả năng tổng quát hóa của mô hình trên dữ liệu mới. Kỹ thuật này hoạt động bằng cách thêm một \"penalty term\" (thành phần phạt) vào hàm loss (hàm chi phí) của mô hình. Penalty term này khuyến khích mô hình có các tham số (weights/hệ số) nhỏ hơn, đơn giản hơn hoặc ít phức tạp hơn, từ đó hạn chế độ lớn của chúng. Điều này giúp mô hình học các mẫu tổng quát hơn thay vì ghi nhớ dữ liệu huấn luyện. Tăng regularization giúp giảm variance (overfitting), trong khi giảm regularization giúp giảm bias (underfitting). Regularization cũng có thể giúp giải quyết vấn đề đa cộng tuyến. Các loại regularization phổ biến bao gồm L1 (Lasso), L2 (Ridge) và Dropout. Trong các mô hình như SVM/SVR, tham số C đóng vai trò là một dạng regularization tích hợp, kiểm soát mức độ mà mô hình được phép mắc lỗi trên dữ liệu huấn luyện; giá trị C nhỏ tương đương với regularization mạnh hơn. Feature Scaling là cần thiết để đảm bảo regularization hoạt động đúng, không thiên vị các đặc trưng có độ lớn lớn. Một số mô hình như XGBoost tích hợp sẵn regularization, và các kỹ thuật như Pooling (đặc biệt là Global Average Pooling) cũng có tác dụng regularization bằng cách giảm số lượng tham số và độ phức tạp của mô hình.\n\n**Mối quan hệ:**\n- Regularization là kỹ thuật giúp giảm overfitting bằng cách thêm penalty vào hàm chi phí, khuyến khích mô hình học các patterns tổng quát hơn.\n- Regularization là một kỹ thuật ngăn chặn Overfitting bằng cách thêm thành phần phạt vào hàm loss, khuyến khích mô hình đơn giản hơn và tổng quát hóa tốt hơn.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n$$MAPE = \frac{100\\%}{m}\\sum_{i=1}^{m}\\left|\frac{y_i - \\hat{y}_i}{y_i}\right|$$\n- Sai số phần trăm trung bình\n- Dễ diễn giải cho người không chuyên\n- Vấn đề: Không xác định khi $y_i = 0$\n\n### Kỹ Thuật Regularization\n\nRegularization giúp giảm overfitting bằng cách thêm penalty vào hàm chi phí.\n\n**1. Ridge Regression (L2 Regularization - Hồi Quy Ridge):**\n$$J(\beta) = \frac{1}{2m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})^2 + \\lambda\\sum_{j=1}^{n}\beta_j^2$$\n\n**Đặc điểm:**\n- Thêm penalty là tổng bình phương các hệ số\n- Làm co nhỏ (shrink) các hệ số về gần 0\n- Không đưa hệ số về chính xác 0\n- Hiệu quả với đa cộng tuyến\n- Nghiệm dạng đóng: $\boldsymbol{\beta} = (\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{y}$\n\n**Khi nào sử dụng:**\n- Nhiều đặc trưng tương quan\n- Muốn giữ tất cả đặc trưng\n- Dữ liệu có đa cộng tuyến\n\n**2. Lasso Regression (L1 Regularization - Hồi Quy Lasso):**\n$$J(\beta) = \frac{1}{2m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})^2 + \\lambda\\sum_{j=1}^{n}|\beta_j|$$\n\n**Đặc điểm:**\n- Thêm penalty là tổng giá trị tuyệt đối các hệ số\n- Có thể đưa một số hệ số về chính xác 0\n- Thực hiện feature selection tự động\n- Tạo ra mô hình sparse (thưa)\n- Không có nghiệm dạng đóng\n\n**Khi nào sử dụng:**\n- Muốn loại bỏ đặc trưng không quan trọng\n- Cần mô hình đơn giản, dễ diễn giải\n- Có nhiều đặc trưng nhưng ít quan trọng\n\n**3. Elastic Net:**\n$$J(\beta) = \frac{1}{2m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})^2 + \\lambda_1\\sum_{j=1}^{n}|\beta_j| + \\lambda_2\\sum_{j=1}^{n}\beta_j^2$$\n\n**Đặc điểm:**\n- Kết hợp L1 và L2\n- Cân bằng giữa feature selection và shrinkage\n- Tốt với các đặc trưng tương quan nhóm\n- Ổn định hơn Lasso khi đặc trưng tương quan cao\n\n**Tham số $\\lambda$ (Lambda):**\n- $\\lambda = 0$: Không có regularization (hồi quy tuyến tính thông thường)\n- $\\lambda$ nhỏ: Ít regularization\n- $\\lambda$ lớn: Nhiều regularization, hệ số bị co nhỏ mạnh\n- Chọn $\\lambda$: Cross-validation\n\n**So Sánh Ridge vs Lasso:**\n| Tiêu chí | Ridge (L2) | Lasso (L1) |\n|----------|-----------|------------|\n| Feature Selection | Không | Có |\n\n**Các khái niệm quan trọng:**\n- Regularization là một kỹ thuật được sử dụng trong Continual Learning (ví dụ: EWC) để ngăn chặn Catastrophic Forgetting bằng cách thêm các ràng buộc hoặc penalty vào hàm loss, khuyến khích mô hình giữ lại các tham số quan trọng cho các tác vụ cũ khi học các tác vụ mới.\n- Regularization là một kỹ thuật quan trọng trong học máy được sử dụng để ngăn chặn overfitting và cải thiện khả năng tổng quát hóa của mô hình trên dữ liệu mới. Kỹ thuật này hoạt động bằng cách thêm một \"penalty term\" (thành phần phạt) vào hàm loss (hàm chi phí) của mô hình. Penalty term này khuyến khích mô hình có các tham số (weights/hệ số) nhỏ hơn, đơn giản hơn hoặc ít phức tạp hơn, từ đó hạn chế độ lớn của chúng. Điều này giúp mô hình học các mẫu tổng quát hơn thay vì ghi nhớ dữ liệu huấn luyện. Tăng regularization giúp giảm variance (overfitting), trong khi giảm regularization giúp giảm bias (underfitting). Regularization cũng có thể giúp giải quyết vấn đề đa cộng tuyến. Các loại regularization phổ biến bao gồm L1 (Lasso), L2 (Ridge) và Dropout. Trong các mô hình như SVM/SVR, tham số C đóng vai trò là một dạng regularization tích hợp, kiểm soát mức độ mà mô hình được phép mắc lỗi trên dữ liệu huấn luyện; giá trị C nhỏ tương đương với regularization mạnh hơn. Feature Scaling là cần thiết để đảm bảo regularization hoạt động đúng, không thiên vị các đặc trưng có độ lớn lớn. Một số mô hình như XGBoost tích hợp sẵn regularization, và các kỹ thuật như Pooling (đặc biệt là Global Average Pooling) cũng có tác dụng regularization bằng cách giảm số lượng tham số và độ phức tạp của mô hình.\n\n**Mối quan hệ:**\n- Regularization là kỹ thuật giúp giảm overfitting bằng cách thêm penalty vào hàm chi phí, khuyến khích mô hình học các patterns tổng quát hơn."
        },
        "output_without_context": {
            "question": "Trong các phương pháp điều chuẩn, phương pháp nào sử dụng hình phạt L1 để giảm thiểu hiện tượng quá khớp trong mô hình học máy?",
            "answer": "Lasso Regression"
        }
    },
    {
        "topic_description": "Chủ đề này giới thiệu về Bagging (Bootstrap Aggregating) như một kỹ thuật tập hợp mạnh mẽ trong học máy. Học sinh sẽ phải làm quen với khái niệm, công thức và ứng dụng của Bagging trong xây dựng các mô hình phân loại, cũng như hiểu vai trò của việc lấy mẫu bootstrap trong kỹ thuật này.",
        "output_with_context": {
            "question": "Bagging (Bootstrap Aggregating) là một phương pháp trong học máy nhằm mục đích gì?",
            "answer": "Giảm variance bằng cách kết hợp nhiều mô hình được huấn luyện trên các bootstrap samples.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n```\n**Dấu hiệu:**\n- Large gap giữa curves\n- Training error tiếp tục giảm\n- Validation error không cải thiện\n\n**Giải pháp:**\n- Get more training data\n- Reduce model complexity\n- Increase regularization\n- Feature selection\n- Dropout, early stopping\n\n**3. Good Fit:**\n```\nTraining error: Thấp\nValidation error: Thấp\nGap: Nhỏ\nBoth converge\n```\n**Dấu hiệu:**\n- Small gap\n- Both errors low\n- Converged performance\n\n**4. More Data Helps:**\n```\nValidation error giảm khi tăng data\nGap đang đóng lại\nChưa plateau\n```\n**Hành động:** Get more data!\n\n**5. More Data Doesn't Help:**\n```\nBoth curves plateau\nAdding data không cải thiện\n```\n**Hành động:** Improve features hoặc model\n\n### Bias-Variance Tradeoff (Sự Đánh Đổi Bias-Variance)\n\n**Công thức:**\n$$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$\n\n**Bias (Thiên Lệch):**\n- Error từ giả định đơn giản hóa\n- Underfitting\n- Model không capture được patterns\n- High bias → Systematic errors\n\n**Variance (Phương Sai):**\n- Error từ sensitivity to training data\n- Overfitting\n- Model learns noise\n- High variance → Different results với different data\n\n**Irreducible Error:**\n- Noise trong data\n- Không thể giảm\n- Comes from data collection\n\n**Tradeoff:**\n- Decrease bias → Increase variance\n- Decrease variance → Increase bias\n- Cần balance\n\n**Strategies:**\n\n**Giảm High Bias:**\n1. Increase model complexity\n2. Add more features/polynomial features\n3. Decrease regularization\n4. Train longer\n5. Use ensemble methods\n\n**Giảm High Variance:**\n1. Get more training data\n2. Reduce model complexity\n3. Increase regularization (L1, L2, dropout)\n4. Feature selection\n5. Early stopping\n6. Ensemble methods (bagging)\n\n**Sweet Spot:**\n- Minimize total error\n- Balance bias và variance\n- Depends on problem và data\n\n**Visualize:**\n```\nTotal Error\n    |     \\\n    |      \\___Bias²\n    |___________\\\n    |            \\___\n    |Variance_____\\___Total\n    |________________\\___\n    |___________________\\___\n    +----------------------->\n    Simple          Complex\n            Model Complexity\n```\n\n### Phương Pháp Ensemble\n\nKết hợp nhiều models để cải thiện hiệu suất.\n\n**\"Wisdom of crowds\"**\n\n**Tại sao hoạt động:**\n- Errors của individual models cancel out\n- Diverse models capture different patterns\n- Reduce variance\n- More robust\n\n**1. Bagging (Bootstrap Aggregating):**\n\n**Nguyên lý:**\n- Train multiple models trên bootstrap samples\n- Average predictions (regression) hoặc vote (classification)\n\n**Bootstrap Sampling:**\n- Sample with replacement\n- Same size as original\n- ~63% unique samples mỗi bootstrap\n\n**Thuật toán:**\n1. For i = 1 to M:\n   - Create bootstrap sample $D_i$\n   - Train model $M_i$ on $D_i$\n2. Combine:\n   - Regression: $\\hat{y} = \frac{1}{M}\\sum_{i=1}^{M}M_i(x)$\n   - Classification: Majority vote\n\n**Ưu điểm:**\n- Reduce variance\n- Parallel training\n- Works với high-variance models\n\n**Nhược điểm:**\n- Không giảm bias\n- Có thể chậm (many models)\n\n**Ví dụ:** Random Forest\n\n**2. Boosting:**\n\n**Nguyên lý:**\n- Sequential training\n- Each model corrects errors của previous models\n- Weighted combination\n\n**Thuật toán (general):**\n1. Initialize equal weights\n2. For i = 1 to M:\n   - Train model $M_i$ on weighted data\n   - Tính error\n   - Update weights (increase for misclassified)\n\n**Các khái niệm quan trọng:**\n- Ensemble methods là một kỹ thuật học máy kết hợp nhiều mô hình học yếu (weak learners) để tạo ra một mô hình mạnh hơn và ổn định hơn. Các phương pháp ensemble như Random Forest và Gradient Boosting được sử dụng để giải quyết các vấn đề của Cây Quyết định như overfitting và tính không ổn định. Chúng giúp giảm variance và cải thiện khả năng generalize của mô hình.\n- Bagging (Bootstrap Aggregating) là một phương pháp ensemble trong đó nhiều mô hình được huấn luyện độc lập trên các tập con dữ liệu được tạo ra bằng kỹ thuật bootstrap sampling. Các dự đoán của các mô hình riêng lẻ sau đó được kết hợp (trung bình cho hồi quy, bỏ phiếu đa số cho phân loại) để đưa ra dự đoán cuối cùng. Bagging giúp \"Reduce variance\" và \"Parallel training\".\n- Bootstrap sampling là một kỹ thuật resampling (lấy mẫu lại) được sử dụng trong Bagging và Random Forest. Kỹ thuật này tạo ra các mẫu con bằng cách lấy mẫu ngẫu nhiên có thay thế (có hoàn lại) từ tập dữ liệu gốc. Mỗi mẫu con có cùng kích thước với tập dữ liệu gốc và chứa khoảng 63% các mẫu duy nhất từ dữ liệu gốc. Trong Random Forest, mỗi Cây Quyết định được huấn luyện trên một bootstrap sample khác nhau, giúp tạo ra sự đa dạng giữa các cây, giảm variance và cải thiện hiệu suất tổng thể của mô hình ensemble. Kỹ thuật này tạo ra sự đa dạng trong dữ liệu huấn luyện cho các mô hình riêng lẻ.\n- Ensemble methods là một kỹ thuật trong học máy kết hợp nhiều mô hình học máy (individual models) để tạo ra một mô hình dự đoán mạnh mẽ hơn. Các phương pháp này hoạt động dựa trên nguyên lý \"Wisdom of crowds\", giúp giảm variance, cải thiện độ mạnh mẽ và thường đạt hiệu suất tốt hơn so với một mô hình đơn lẻ. Các ví dụ bao gồm Bagging và Boosting.\n\n**Mối quan hệ:**\n- Bagging sử dụng Bootstrap Sampling để tạo ra các tập con dữ liệu huấn luyện đa dạng cho các mô hình riêng lẻ.\n- Random Forest là một ví dụ cụ thể của phương pháp ensemble Bagging, sử dụng nhiều cây quyết định được huấn luyện trên các bootstrap samples.\n- Ensemble methods, đặc biệt là Bagging, giúp giảm Variance bằng cách kết hợp nhiều mô hình đa dạng, làm cho lỗi của các mô hình riêng lẻ triệt tiêu lẫn nhau.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Phân Loại (Classification)\n- Tập trung vào lớp dương\n- AUPRC (Area Under Precision-Recall Curve)\n\n**Khi nào dùng gì:**\n- **Balanced data:** ROC-AUC\n- **Imbalanced data:** Precision-Recall Curve, F1-Score, MCC\n- **Cost-sensitive:** Tùy chỉnh threshold, F-beta\n\n**Lựa Chọn Threshold:**\n- Default: 0.5\n- Điều chỉnh dựa trên business requirements\n- Tăng threshold: Tăng Precision, giảm Recall\n- Giảm threshold: Tăng Recall, giảm Precision\n\n### Xử Lý Dữ Liệu Mất Cân Bằng (Imbalanced Data)\n\nKhi một lớp chiếm đa số (ví dụ: 95% negative, 5% positive).\n\n**Vấn Đề:**\n- Mô hình thiên vị về lớp đa số\n- Accuracy cao nhưng không phát hiện được lớp thiểu số\n- Mô hình có thể chỉ dự đoán lớp đa số\n\n**1. Resampling Techniques:**\n\n**Oversampling (Lấy Mẫu Tăng):**\n- Tăng số lượng mẫu lớp thiểu số\n- **Random Oversampling:** Nhân đôi mẫu thiểu số\n  - Dễ triển khai\n  - Nguy cơ overfitting\n  \n- **SMOTE (Synthetic Minority Over-sampling Technique):**\n  - Tạo mẫu synthetic từ kNN\n  - Nội suy giữa các mẫu thiểu số\n  - Công thức: $x_{new} = x_i + \\lambda \times (x_{nn} - x_i)$\n  - $\\lambda \\in [0,1]$, $x_{nn}$ là láng giềng gần\n  - Giảm overfitting hơn random oversampling\n\n- **ADASYN (Adaptive Synthetic Sampling):**\n  - Tập trung vào mẫu khó phân loại\n  - Tạo nhiều mẫu hơn ở vùng khó\n\n**Undersampling (Lấy Mẫu Giảm):**\n- Giảm số lượng mẫu lớp đa số\n- **Random Undersampling:** Loại bỏ ngẫu nhiên\n  - Nhanh, đơn giản\n  - Mất thông tin\n  \n- **Tomek Links:** Loại bỏ mẫu biên\n- **NearMiss:** Chọn mẫu đa số gần thiểu số\n- **Cluster Centroids:** K-means cho lớp đa số\n\n**Kết Hợp Over và Under:**\n- SMOTE + Tomek Links\n- SMOTE + ENN (Edited Nearest Neighbors)\n\n**2. Class Weights (Trọng Số Lớp):**\n- Gán trọng số cao hơn cho lớp thiểu số\n- Penalty cho misclassification của thiểu số lớn hơn\n$$w_k = \frac{n_{samples}}{n_{classes} \times n_{samples\\_k}}$$\n- Tích hợp trong hầu hết thuật toán (sklearn: class_weight='balanced')\n\n**3. Ensemble Methods:**\n\n**Balanced Random Forest:**\n- Bootstrap undersampling cho mỗi tree\n- Cân bằng classes trong mỗi tree\n\n**EasyEnsemble:**\n- Nhiều balanced subsets\n- AdaBoost trên mỗi subset\n\n**BalancedBagging:**\n- Undersampling + Bagging\n\n**4. Anomaly Detection Approach:**\n- Xem lớp thiểu số như anomaly\n- One-class SVM, Isolation Forest\n- Học chỉ từ lớp đa số\n\n**5. Cost-Sensitive Learning:**\n- Định nghĩa cost matrix\n- Misclassification cost khác nhau cho mỗi lớp\n- Tối ưu hóa total cost thay vì accuracy\n\n**6. Ensemble of Different Techniques:**\n- Kết hợp nhiều phương pháp\n- Voting hoặc stacking\n\n**Best Practices:**\n\n**Các khái niệm quan trọng:**\n- BalancedBagging là một phương pháp ensemble kết hợp kỹ thuật undersampling với Bagging. Trong mỗi lần bootstrap của Bagging, một tập con cân bằng được tạo ra bằng cách undersampling lớp đa số. Sau đó, một mô hình cơ sở được huấn luyện trên tập con cân bằng này. Các dự đoán từ tất cả các mô hình cơ sở được kết hợp để đưa ra dự đoán cuối cùng, giúp cải thiện hiệu suất trên dữ liệu mất cân bằng.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n\n### Nhược Điểm\n\n**1. Dễ Overfitting:**\n- Cây sâu học cả noise\n- Mô hình phức tạp không generalize tốt\n- Cần pruning hoặc ensemble\n\n**2. Không Ổn Định:**\n- Thay đổi nhỏ trong dữ liệu → cây hoàn toàn khác\n- High variance\n- Giải pháp: Ensemble methods (Random Forest)\n\n**3. Thiên Vị Về Đặc Trưng Có Nhiều Mức:**\n- Đặc trưng với nhiều giá trị unique được ưu tiên\n- Information Gain thiên vị\n- Giải pháp: Gain Ratio (C4.5)\n\n**4. Không Tối Ưu Cho Extrapolation:**\n- Hồi quy chỉ dự đoán trong phạm vi training data\n- Không thể dự đoán ngoài min/max đã thấy\n- Dự đoán là hằng số ở nút lá\n\n**5. Tạo Cây Thiên Vị Với Imbalanced Data:**\n- Ưu tiên lớp đa số\n- Cần class_weight hoặc resampling\n\n**6. Greedy Algorithm:**\n- Chọn phân chia tốt nhất tại thời điểm hiện tại\n- Không đảm bảo cây tối ưu toàn cục\n- Có thể bỏ lỡ cây tốt hơn\n\n**7. Khó Bắt Mối Quan Hệ Tuyến Tính:**\n- Cần nhiều phân chia để xấp xỉ đường thẳng\n- Linear model đơn giản hơn cho quan hệ tuyến tính\n\n### Phương Pháp Ensemble Với Cây\n\n**1. Random Forest (Rừng Ngẫu Nhiên):**\n\n**Nguyên lý:**\n- Xây dựng nhiều cây quyết định\n- Mỗi cây trên bootstrap sample khác nhau\n- Random subset đặc trưng tại mỗi split\n- Kết hợp dự đoán: Voting (classification) hoặc averaging (regression)\n\n**Tham số chính:**\n- `n_estimators`: Số cây (50-500)\n- `max_features`: Số đặc trưng xem xét (sqrt(n) cho classification, n/3 cho regression)\n- `max_depth`: Độ sâu mỗi cây\n- `min_samples_split`, `min_samples_leaf`\n\n**Ưu điểm:**\n- Giảm variance, ít overfitting\n- Ổn định hơn cây đơn\n- Feature importance đáng tin cậy hơn\n- Xử lý tốt high-dimensional data\n- Out-of-bag error estimation\n\n**2. Gradient Boosting:**\n\n**Nguyên lý:**\n- Xây dựng cây tuần tự\n- Mỗi cây học sửa lỗi của cây trước\n- Mỗi cây nhỏ (weak learner)\n- Kết hợp có trọng số\n\n**Công thức:**\n$$F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$$\n\nTrong đó:\n- $F_m$ là mô hình tại iteration $m$\n- $h_m$ là cây mới\n- $\nu$ là learning rate\n\n**Implementations phổ biến:**\n- **XGBoost:** Nhanh, regularization tốt, xử lý missing values\n- **LightGBM:** Rất nhanh, hiệu quả bộ nhớ, leaf-wise growth\n- **CatBoost:** Tốt cho categorical features, ít overfitting\n\n**Ưu điểm:**\n- Hiệu suất cao nhất trong nhiều competition\n- Có thể đạt accuracy rất cao\n- Xử lý tốt heterogeneous features\n\n**Nhược điểm:**\n\n**Các khái niệm quan trọng:**\n- Ensemble methods là một kỹ thuật học máy kết hợp nhiều mô hình học yếu (weak learners) để tạo ra một mô hình mạnh hơn và ổn định hơn. Các phương pháp ensemble như Random Forest và Gradient Boosting được sử dụng để giải quyết các vấn đề của Cây Quyết định như overfitting và tính không ổn định. Chúng giúp giảm variance và cải thiện khả năng generalize của mô hình.\n- Gradient Boosting là một mô hình học máy mạnh mẽ thuộc họ các thuật toán ensemble, xây dựng một mô hình dự đoán mạnh bằng cách kết hợp nhiều mô hình yếu (thường là cây quyết định) một cách tuần tự. Mỗi mô hình yếu mới được huấn luyện để sửa chữa lỗi của các mô hình trước đó. Early Stopping là một kỹ thuật quan trọng được áp dụng cho Gradient Boosting để kiểm soát quá trình huấn luyện và ngăn chặn overfitting.\n- Ensemble methods là một kỹ thuật trong học máy kết hợp nhiều mô hình học máy (individual models) để tạo ra một mô hình dự đoán mạnh mẽ hơn. Các phương pháp này hoạt động dựa trên nguyên lý \"Wisdom of crowds\", giúp giảm variance, cải thiện độ mạnh mẽ và thường đạt hiệu suất tốt hơn so với một mô hình đơn lẻ. Các ví dụ bao gồm Bagging và Boosting.\n- Gradient Boosting là một phương pháp ensemble mạnh mẽ khác, xây dựng các Cây Quyết định một cách tuần tự. Thay vì xây dựng các cây độc lập như Random Forest, Gradient Boosting xây dựng mỗi cây mới để học và sửa lỗi của các cây trước đó. Mỗi cây mới thường là một \"weak learner\" (cây nhỏ). Các dự đoán của các cây được kết hợp có trọng số. Công thức cập nhật mô hình là $F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$, trong đó $F_m$ là mô hình tại iteration $m$, $h_m$ là cây mới, và $\nu$ là learning rate. Các triển khai phổ biến bao gồm XGBoost, LightGBM và CatBoost. Gradient Boosting nổi tiếng với hiệu suất cao nhất trong nhiều cuộc thi và khả năng đạt độ chính xác rất cao, xử lý tốt các đặc trưng không đồng nhất.\n\n**Mối quan hệ:**\n- Ensemble methods, đặc biệt là Bagging, giúp giảm Variance bằng cách kết hợp nhiều mô hình đa dạng, làm cho lỗi của các mô hình riêng lẻ triệt tiêu lẫn nhau.\n- Gradient Boosting huấn luyện các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó, nhằm giảm thiểu lỗi."
        },
        "output_without_context": {
            "question": "Bagging (Bootstrap Aggregating) là một kỹ thuật được sử dụng trong học máy để làm gì?",
            "answer": "Tăng cường độ chính xác của mô hình phân loại."
        }
    },
    {
        "topic_description": "Chủ đề này tập trung vào Boosting như một kỹ thuật cải tiến mô hình, đặc biệt là qua thuật toán AdaBoost. Học sinh sẽ học cách hoạt động của AdaBoost, sự khác biệt với Bagging và ứng dụng thực tiễn trong cải thiện tính chính xác của mô hình phân loại. Học sinh sẽ áp dụng kiến thức này vào các bài toán thực tiễn để nâng cao hiểu biết về các phương pháp học máy.",
        "output_with_context": {
            "question": "Trong thuật toán AdaBoost, cách nào để điều chỉnh trọng số của các mẫu trong quá trình huấn luyện?",
            "answer": "Tăng trọng số cho các mẫu bị phân loại sai.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n   - Calculate model weight\n3. Combine: Weighted vote/average\n\n**Variants:**\n- **AdaBoost:** Adjust sample weights\n- **Gradient Boosting:** Fit residuals\n- **XGBoost:** Optimized GBM\n- **LightGBM:** Leaf-wise GBM\n- **CatBoost:** Handle categorical\n\n**Ưu điểm:**\n- Reduce bias và variance\n- Often best performance\n- Handle complex patterns\n\n**Nhược điểm:**\n- Sequential (không parallel)\n- Sensitive to noise\n- Easy overfit\n- Nhiều hyperparameters\n\n**3. Stacking (Stacked Generalization):**\n\n**Nguyên lý:**\n- Train meta-model trên predictions của base models\n- Combine diverse models\n\n**Architecture:**\n```\nBase Models: Model1, Model2, Model3, ...\n    ↓          ↓       ↓        ↓\nPredictions: pred1, pred2, pred3, ...\n    ↓\nMeta-Model: Learns to combine predictions\n    ↓\nFinal Prediction\n```\n\n**Thuật toán:**\n1. Split data: Train + Holdout\n2. Train base models trên Train set\n3. Generate predictions trên Holdout set\n4. Train meta-model:\n   - Input: Base model predictions\n   - Output: True labels\n5. Final prediction: Meta-model(base predictions)\n\n**Base Models:**\n- Diverse algorithms (RF, SVM, NN, etc.)\n- Different architectures\n- Different feature sets\n\n**Meta-Model:**\n- Usually simple (Linear, Logistic Regression)\n- Can be any model\n\n**Ưu điểm:**\n- Combine strengths của different models\n- Often best performance\n- Flexible\n\n**Nhược điểm:**\n- Complex pipeline\n- Risk overfitting\n- Computationally expensive\n- Hard to interpret\n\n**4. Voting:**\n\n**Hard Voting (Classification):**\n- Each model votes\n- Majority class wins\n- Simple democracy\n\n**Soft Voting (Classification):**\n- Average predicted probabilities\n- More nuanced\n- Usually better than hard\n\n**Averaging (Regression):**\n- Simple average\n- Weighted average possible\n\n**Ưu điểm:**\n- Simple\n- Reduce variance\n- No additional training\n\n**Nhược điểm:**\n- All models equal weight (hard voting)\n- Không learn to combine\n\n**Best Practices Ensemble:**\n1. **Diverse models:** Different algorithms, features, architectures\n2. **Not too many:** 5-10 models often enough\n3. **Strong individual models:** Garbage in, garbage out\n4. **Cross-validation:** Avoid overfitting in stacking\n5. **Computational cost:** Consider inference time\n\n### Tiêu Chí Lựa Chọn Mô Hình\n\n**1. Akaike Information Criterion (AIC):**\n$$AIC = 2k - 2\\ln(\\hat{L})$$\n\nTrong đó:\n- $k$ là số parameters\n- $\\hat{L}$ là maximized likelihood\n\n**Diễn giải:**\n- Lower AIC = better model\n- Penalizes model complexity\n- Trade-off fit vs complexity\n\n**2. Bayesian Information Criterion (BIC):**\n$$BIC = k\\ln(n) - 2\\ln(\\hat{L})$$\n\nTrong đó $n$ là số observations.\n\n**So với AIC:**\n- BIC penalizes complexity nhiều hơn\n- Prefers simpler models\n- Better với large $n$\n\n**3. Adjusted R-squared:**\n$$R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-k-1}$$\n\n**Đặc điểm:**\n- Penalizes thêm predictors\n- Không tăng khi thêm useless features\n- Tốt hơn $R^2$ cho model comparison\n\n**Khi nào dùng:**\n- AIC/BIC: Model comparison, likelihood-based\n- Adjusted R²: Linear regression\n- Cross-validation: General, most reliable\n\n### Tối Ưu Pipeline\n\n**1. Pipeline Construction:**\n\n**Sklearn Pipeline:**\n```python\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('pca', PCA(n_components=10)),\n    ('classifier', RandomForestClassifier())\n])\n```\n\n**Ưu điểm:**\n- Consistent transformations\n- Avoid data leakage\n- Easy to deploy\n\n**Các khái niệm quan trọng:**\n- Gradient Boosting là một mô hình học máy mạnh mẽ thuộc họ các thuật toán ensemble, xây dựng một mô hình dự đoán mạnh bằng cách kết hợp nhiều mô hình yếu (thường là cây quyết định) một cách tuần tự. Mỗi mô hình yếu mới được huấn luyện để sửa chữa lỗi của các mô hình trước đó. Early Stopping là một kỹ thuật quan trọng được áp dụng cho Gradient Boosting để kiểm soát quá trình huấn luyện và ngăn chặn overfitting.\n- Gradient Boosting là một biến thể của thuật toán Boosting, hoạt động bằng cách xây dựng các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó. Thay vì điều chỉnh trọng số mẫu, Gradient Boosting tập trung vào việc giảm thiểu lỗi bằng cách học từ sai sót của các mô hình trước.\n\n**Mối quan hệ:**\n- Gradient Boosting huấn luyện các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó, nhằm giảm thiểu lỗi.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n- Dễ overfit nếu không tune cẩn thận\n- Chậm hơn Random Forest (sequential)\n- Khó tune (nhiều hyperparameters)\n\n**3. AdaBoost (Adaptive Boosting):**\n\n**Nguyên lý:**\n- Tăng trọng số cho mẫu bị misclassified\n- Mỗi cây tập trung vào mẫu khó\n- Trọng số cho mô hình dựa trên accuracy\n\n**Ưu điểm:**\n- Đơn giản, hiệu quả\n- Ít tham số hơn Gradient Boosting\n- Tốt cho binary classification\n\n**Nhược điểm:**\n- Nhạy cảm với noise và outliers\n- Có thể overfit\n\n### Điều Chỉnh Hyperparameters\n\n**Tham số quan trọng:**\n\n**1. max_depth (Độ sâu tối đa):**\n- Giá trị nhỏ: Underfitting, mô hình đơn giản\n- Giá trị lớn: Overfitting, mô hình phức tạp\n- Thường: 3-10 cho cây đơn, 5-20 cho ensemble\n\n**2. min_samples_split:**\n- Số mẫu tối thiểu để split nút\n- Tăng lên: Giảm overfitting, cây đơn giản hơn\n- Thường: 2-100\n\n**3. min_samples_leaf:**\n- Số mẫu tối thiểu trong mỗi lá\n- Làm mượt decision boundary\n- Thường: 1-50\n\n**4. max_features:**\n- Số đặc trưng xem xét cho mỗi split\n- 'auto'/'sqrt': √n (cho classification)\n- 'log2': log₂(n)\n- None: Tất cả đặc trưng\n\n**5. criterion:**\n- 'gini': Gini impurity (mặc định, nhanh)\n- 'entropy': Information gain (chậm hơn)\n- 'squared_error': Cho regression\n\n**6. splitter:**\n- 'best': Chọn phân chia tốt nhất (mặc định)\n- 'random': Chọn ngẫu nhiên (nhanh hơn, thêm randomness)\n\n**Strategies cho Tuning:**\n- **Grid Search:** Thử tất cả combinations\n- **Random Search:** Sample ngẫu nhiên, hiệu quả hơn\n- **Bayesian Optimization:** Thông minh, ít iterations\n- **Cross-validation:** Luôn dùng CV để đánh giá\n\n**Tips:**\n- Bắt đầu với default parameters\n- Tune max_depth trước\n- Sau đó min_samples_split và min_samples_leaf\n- Cuối cùng các tham số khác\n- Monitor training vs validation performance\n\n### Ứng Dụng Thực Tế\n\n**1. Chẩn Đoán Y Tế:**\n- Chuỗi quyết định dựa trên triệu chứng\n- Dự đoán bệnh từ test results\n- Giải thích dễ dàng cho bác sĩ\n\n**2. Đánh Giá Rủi Ro Tín Dụng:**\n- Quyết định cho vay\n- Dự đoán default risk\n- Tuân thủ quy định (interpretability)\n\n**3. Dự Đoán Customer Churn:**\n- Xác định khách hàng có khả năng rời đi\n- Hành động marketing có mục tiêu\n- Hiểu lý do churn\n\n**4. Phát Hiện Gian Lận:**\n- Phát hiện transactions đáng ngờ\n- Real-time scoring\n- Giải thích cho investigation team\n\n**5. Feature Selection:**\n- Xác định đặc trưng quan trọng\n- Giảm dimensionality\n- Chuẩn bị cho mô hình khác\n\n**6. Hệ Thống Gợi Ý:**\n- Quyết định sản phẩm recommend\n- Personalization rules\n\n**Các khái niệm quan trọng:**\n- Gradient Boosting là một mô hình học máy mạnh mẽ thuộc họ các thuật toán ensemble, xây dựng một mô hình dự đoán mạnh bằng cách kết hợp nhiều mô hình yếu (thường là cây quyết định) một cách tuần tự. Mỗi mô hình yếu mới được huấn luyện để sửa chữa lỗi của các mô hình trước đó. Early Stopping là một kỹ thuật quan trọng được áp dụng cho Gradient Boosting để kiểm soát quá trình huấn luyện và ngăn chặn overfitting.\n- Gradient Boosting là một biến thể của thuật toán Boosting, hoạt động bằng cách xây dựng các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó. Thay vì điều chỉnh trọng số mẫu, Gradient Boosting tập trung vào việc giảm thiểu lỗi bằng cách học từ sai sót của các mô hình trước.\n- Gradient Boosting là một thuật toán boosting khác, thường có nhiều tham số hơn AdaBoost. Nó được so sánh với AdaBoost về số lượng tham số.\n- Gradient Boosting là một phương pháp ensemble mạnh mẽ khác, xây dựng các Cây Quyết định một cách tuần tự. Thay vì xây dựng các cây độc lập như Random Forest, Gradient Boosting xây dựng mỗi cây mới để học và sửa lỗi của các cây trước đó. Mỗi cây mới thường là một \"weak learner\" (cây nhỏ). Các dự đoán của các cây được kết hợp có trọng số. Công thức cập nhật mô hình là $F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$, trong đó $F_m$ là mô hình tại iteration $m$, $h_m$ là cây mới, và $\nu$ là learning rate. Các triển khai phổ biến bao gồm XGBoost, LightGBM và CatBoost. Gradient Boosting nổi tiếng với hiệu suất cao nhất trong nhiều cuộc thi và khả năng đạt độ chính xác rất cao, xử lý tốt các đặc trưng không đồng nhất.\n\n**Mối quan hệ:**\n- Gradient Boosting huấn luyện các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó, nhằm giảm thiểu lỗi.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n\n### Nhược Điểm\n\n**1. Dễ Overfitting:**\n- Cây sâu học cả noise\n- Mô hình phức tạp không generalize tốt\n- Cần pruning hoặc ensemble\n\n**2. Không Ổn Định:**\n- Thay đổi nhỏ trong dữ liệu → cây hoàn toàn khác\n- High variance\n- Giải pháp: Ensemble methods (Random Forest)\n\n**3. Thiên Vị Về Đặc Trưng Có Nhiều Mức:**\n- Đặc trưng với nhiều giá trị unique được ưu tiên\n- Information Gain thiên vị\n- Giải pháp: Gain Ratio (C4.5)\n\n**4. Không Tối Ưu Cho Extrapolation:**\n- Hồi quy chỉ dự đoán trong phạm vi training data\n- Không thể dự đoán ngoài min/max đã thấy\n- Dự đoán là hằng số ở nút lá\n\n**5. Tạo Cây Thiên Vị Với Imbalanced Data:**\n- Ưu tiên lớp đa số\n- Cần class_weight hoặc resampling\n\n**6. Greedy Algorithm:**\n- Chọn phân chia tốt nhất tại thời điểm hiện tại\n- Không đảm bảo cây tối ưu toàn cục\n- Có thể bỏ lỡ cây tốt hơn\n\n**7. Khó Bắt Mối Quan Hệ Tuyến Tính:**\n- Cần nhiều phân chia để xấp xỉ đường thẳng\n- Linear model đơn giản hơn cho quan hệ tuyến tính\n\n### Phương Pháp Ensemble Với Cây\n\n**1. Random Forest (Rừng Ngẫu Nhiên):**\n\n**Nguyên lý:**\n- Xây dựng nhiều cây quyết định\n- Mỗi cây trên bootstrap sample khác nhau\n- Random subset đặc trưng tại mỗi split\n- Kết hợp dự đoán: Voting (classification) hoặc averaging (regression)\n\n**Tham số chính:**\n- `n_estimators`: Số cây (50-500)\n- `max_features`: Số đặc trưng xem xét (sqrt(n) cho classification, n/3 cho regression)\n- `max_depth`: Độ sâu mỗi cây\n- `min_samples_split`, `min_samples_leaf`\n\n**Ưu điểm:**\n- Giảm variance, ít overfitting\n- Ổn định hơn cây đơn\n- Feature importance đáng tin cậy hơn\n- Xử lý tốt high-dimensional data\n- Out-of-bag error estimation\n\n**2. Gradient Boosting:**\n\n**Nguyên lý:**\n- Xây dựng cây tuần tự\n- Mỗi cây học sửa lỗi của cây trước\n- Mỗi cây nhỏ (weak learner)\n- Kết hợp có trọng số\n\n**Công thức:**\n$$F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$$\n\nTrong đó:\n- $F_m$ là mô hình tại iteration $m$\n- $h_m$ là cây mới\n- $\nu$ là learning rate\n\n**Implementations phổ biến:**\n- **XGBoost:** Nhanh, regularization tốt, xử lý missing values\n- **LightGBM:** Rất nhanh, hiệu quả bộ nhớ, leaf-wise growth\n- **CatBoost:** Tốt cho categorical features, ít overfitting\n\n**Ưu điểm:**\n- Hiệu suất cao nhất trong nhiều competition\n- Có thể đạt accuracy rất cao\n- Xử lý tốt heterogeneous features\n\n**Nhược điểm:**\n\n**Các khái niệm quan trọng:**\n- Gradient Boosting là một mô hình học máy mạnh mẽ thuộc họ các thuật toán ensemble, xây dựng một mô hình dự đoán mạnh bằng cách kết hợp nhiều mô hình yếu (thường là cây quyết định) một cách tuần tự. Mỗi mô hình yếu mới được huấn luyện để sửa chữa lỗi của các mô hình trước đó. Early Stopping là một kỹ thuật quan trọng được áp dụng cho Gradient Boosting để kiểm soát quá trình huấn luyện và ngăn chặn overfitting.\n- Gradient Boosting là một biến thể của thuật toán Boosting, hoạt động bằng cách xây dựng các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó. Thay vì điều chỉnh trọng số mẫu, Gradient Boosting tập trung vào việc giảm thiểu lỗi bằng cách học từ sai sót của các mô hình trước.\n- Gradient Boosting là một thuật toán boosting khác, thường có nhiều tham số hơn AdaBoost. Nó được so sánh với AdaBoost về số lượng tham số.\n- Gradient Boosting là một phương pháp ensemble mạnh mẽ khác, xây dựng các Cây Quyết định một cách tuần tự. Thay vì xây dựng các cây độc lập như Random Forest, Gradient Boosting xây dựng mỗi cây mới để học và sửa lỗi của các cây trước đó. Mỗi cây mới thường là một \"weak learner\" (cây nhỏ). Các dự đoán của các cây được kết hợp có trọng số. Công thức cập nhật mô hình là $F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$, trong đó $F_m$ là mô hình tại iteration $m$, $h_m$ là cây mới, và $\nu$ là learning rate. Các triển khai phổ biến bao gồm XGBoost, LightGBM và CatBoost. Gradient Boosting nổi tiếng với hiệu suất cao nhất trong nhiều cuộc thi và khả năng đạt độ chính xác rất cao, xử lý tốt các đặc trưng không đồng nhất.\n\n**Mối quan hệ:**\n- Gradient Boosting huấn luyện các mô hình tuần tự để phù hợp với phần dư (residuals) của các dự đoán từ các mô hình trước đó, nhằm giảm thiểu lỗi."
        },
        "output_without_context": {
            "question": "Trong thuật toán AdaBoost, yếu tố nào được điều chỉnh để cải thiện độ chính xác của mô hình phân loại qua các vòng lặp học tập?",
            "answer": "Trọng số của các mẫu dữ liệu."
        }
    },
    {
        "topic_description": "Chủ đề này khám phá kỹ thuật Stacking trong việc tập hợp các mô hình phân loại. Học sinh sẽ tìm hiểu sự khác biệt giữa Stacking và các phương pháp tập hợp khác, cùng với ví dụ minh họa cách thức hoạt động của nó trong học máy. Việc nắm vững kỹ thuật này giúp học sinh có cái nhìn toàn diện về các phương pháp tối ưu hóa mô hình.",
        "output_with_context": {
            "question": "Kỹ thuật Stacking trong học máy sử dụng mô hình nào để kết hợp các dự đoán từ các mô hình cơ sở?",
            "answer": "Meta-model",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n   - Calculate model weight\n3. Combine: Weighted vote/average\n\n**Variants:**\n- **AdaBoost:** Adjust sample weights\n- **Gradient Boosting:** Fit residuals\n- **XGBoost:** Optimized GBM\n- **LightGBM:** Leaf-wise GBM\n- **CatBoost:** Handle categorical\n\n**Ưu điểm:**\n- Reduce bias và variance\n- Often best performance\n- Handle complex patterns\n\n**Nhược điểm:**\n- Sequential (không parallel)\n- Sensitive to noise\n- Easy overfit\n- Nhiều hyperparameters\n\n**3. Stacking (Stacked Generalization):**\n\n**Nguyên lý:**\n- Train meta-model trên predictions của base models\n- Combine diverse models\n\n**Architecture:**\n```\nBase Models: Model1, Model2, Model3, ...\n    ↓          ↓       ↓        ↓\nPredictions: pred1, pred2, pred3, ...\n    ↓\nMeta-Model: Learns to combine predictions\n    ↓\nFinal Prediction\n```\n\n**Thuật toán:**\n1. Split data: Train + Holdout\n2. Train base models trên Train set\n3. Generate predictions trên Holdout set\n4. Train meta-model:\n   - Input: Base model predictions\n   - Output: True labels\n5. Final prediction: Meta-model(base predictions)\n\n**Base Models:**\n- Diverse algorithms (RF, SVM, NN, etc.)\n- Different architectures\n- Different feature sets\n\n**Meta-Model:**\n- Usually simple (Linear, Logistic Regression)\n- Can be any model\n\n**Ưu điểm:**\n- Combine strengths của different models\n- Often best performance\n- Flexible\n\n**Nhược điểm:**\n- Complex pipeline\n- Risk overfitting\n- Computationally expensive\n- Hard to interpret\n\n**4. Voting:**\n\n**Hard Voting (Classification):**\n- Each model votes\n- Majority class wins\n- Simple democracy\n\n**Soft Voting (Classification):**\n- Average predicted probabilities\n- More nuanced\n- Usually better than hard\n\n**Averaging (Regression):**\n- Simple average\n- Weighted average possible\n\n**Ưu điểm:**\n- Simple\n- Reduce variance\n- No additional training\n\n**Nhược điểm:**\n- All models equal weight (hard voting)\n- Không learn to combine\n\n**Best Practices Ensemble:**\n1. **Diverse models:** Different algorithms, features, architectures\n2. **Not too many:** 5-10 models often enough\n3. **Strong individual models:** Garbage in, garbage out\n4. **Cross-validation:** Avoid overfitting in stacking\n5. **Computational cost:** Consider inference time\n\n### Tiêu Chí Lựa Chọn Mô Hình\n\n**1. Akaike Information Criterion (AIC):**\n$$AIC = 2k - 2\\ln(\\hat{L})$$\n\nTrong đó:\n- $k$ là số parameters\n- $\\hat{L}$ là maximized likelihood\n\n**Diễn giải:**\n- Lower AIC = better model\n- Penalizes model complexity\n- Trade-off fit vs complexity\n\n**2. Bayesian Information Criterion (BIC):**\n$$BIC = k\\ln(n) - 2\\ln(\\hat{L})$$\n\nTrong đó $n$ là số observations.\n\n**So với AIC:**\n- BIC penalizes complexity nhiều hơn\n- Prefers simpler models\n- Better với large $n$\n\n**3. Adjusted R-squared:**\n$$R^2_{adj} = 1 - \frac{(1-R^2)(n-1)}{n-k-1}$$\n\n**Đặc điểm:**\n- Penalizes thêm predictors\n- Không tăng khi thêm useless features\n- Tốt hơn $R^2$ cho model comparison\n\n**Khi nào dùng:**\n- AIC/BIC: Model comparison, likelihood-based\n- Adjusted R²: Linear regression\n- Cross-validation: General, most reliable\n\n### Tối Ưu Pipeline\n\n**1. Pipeline Construction:**\n\n**Sklearn Pipeline:**\n```python\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('pca', PCA(n_components=10)),\n    ('classifier', RandomForestClassifier())\n])\n```\n\n**Ưu điểm:**\n- Consistent transformations\n- Avoid data leakage\n- Easy to deploy\n\n**Các khái niệm quan trọng:**\n- Base models là các mô hình học máy riêng lẻ được huấn luyện trên cùng một tập dữ liệu (hoặc các tập con) trong các kỹ thuật ensemble như Stacking hoặc Voting. Các base models có thể là các thuật toán khác nhau (ví dụ: RF, SVM, NN) hoặc cùng một thuật toán với các kiến trúc/tham số khác nhau.\n- Stacking (Stacked Generalization) là một kỹ thuật ensemble học máy trong đó một \"meta-model\" được huấn luyện để kết hợp các dự đoán từ nhiều \"base models\" khác nhau. Meta-model học cách trọng số hóa hoặc kết hợp các dự đoán của base models để đưa ra dự đoán cuối cùng, thường mang lại hiệu suất tốt nhất.\n- Meta-model là một mô hình học máy được huấn luyện để kết hợp các dự đoán từ các \"base models\" khác trong kỹ thuật Stacking. Nó học cách trọng số hóa hoặc kết hợp các đầu ra của base models để đưa ra dự đoán cuối cùng, thường là một mô hình đơn giản như Linear Regression hoặc Logistic Regression.\n\n**Mối quan hệ:**\n- Stacking sử dụng nhiều base models đa dạng để tạo ra các dự đoán đầu vào cho meta-model.\n- Stacking huấn luyện một meta-model trên các dự đoán của các base models để kết hợp chúng.\n- Stacking có nguy cơ bị overfitting nếu meta-model quá phức tạp hoặc không được huấn luyện cẩn thận, đặc biệt là khi không sử dụng cross-validation.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n- Grid search toàn pipeline\n\n**2. Feature Union:**\n\n```python\nfrom sklearn.pipeline import FeatureUnion\n\nfeature_union = FeatureUnion([\n    ('numeric', numeric_pipeline),\n    ('text', text_pipeline),\n    ('categorical', categorical_pipeline)\n])\n```\n\n**Đặc điểm:**\n- Parallel processing\n- Combine different feature types\n- Modular design\n\n**3. Caching:**\n\n```python\npipeline = Pipeline([...], memory='cache_folder')\n```\n\n**Ưu điểm:**\n- Cache intermediate results\n- Speed up grid search\n- Reuse computations\n\n### Early Stopping\n\nCho iterative algorithms (gradient descent, boosting).\n\n**Nguyên lý:**\n- Monitor validation performance\n- Stop khi performance degrades\n- Prevents overfitting\n\n**Thuật toán:**\n1. Set patience (số epochs không cải thiện)\n2. Track best validation score\n3. Each epoch:\n   - Evaluate validation\n   - If improved: Reset counter, save model\n   - If not: Increment counter\n4. If counter > patience: Stop\n\n**Ưu điểm:**\n- Automatic regularization\n- Save training time\n- Prevent overfitting\n\n**Tham số:**\n- **patience:** Số epochs chờ (5-20)\n- **min_delta:** Minimum improvement (0.001-0.01)\n- **restore_best_weights:** Restore model tốt nhất\n\n**Áp dụng:**\n- Neural Networks (most common)\n- Gradient Boosting\n- Iterative algorithms\n\n### Chiến Lược Regularization\n\n**1. L1 (Lasso):**\n- Feature selection\n- Sparse solutions\n- $\\lambda||w||_1$\n\n**2. L2 (Ridge):**\n- Shrinks coefficients\n- Handles multicollinearity\n- $\\lambda||w||_2^2$\n\n**3. Elastic Net:**\n- Combines L1 và L2\n- $\\lambda_1||w||_1 + \\lambda_2||w||_2^2$\n\n**4. Dropout (Neural Networks):**\n- Randomly drop units during training\n- Rate: 0.2-0.5\n- Forces redundancy\n- Reduces co-adaptation\n\n**5. Data Augmentation:**\n- Artificially expand training set\n- Transformations:\n  - Images: Rotation, flip, crop, brightness\n  - Text: Synonym replacement, back-translation\n  - Audio: Time stretch, pitch shift, noise\n\n**Ưu điểm:**\n- More data without collecting\n- Improve generalization\n- Reduce overfitting\n\n### AutoML\n\nAutomated machine learning systems.\n\n**Tools:**\n- **Auto-sklearn:** Automated sklearn\n- **H2O AutoML:** Enterprise-grade\n- **Google AutoML:** Cloud-based\n- **TPOT:** Genetic programming\n- **AutoKeras:** Automated deep learning\n\n**Tự động hóa:**\n1. **Feature preprocessing:**\n   - Scaling, encoding, imputation\n   - Feature engineering\n\n2. **Algorithm selection:**\n   - Try multiple algorithms\n   - Ensemble automatically\n\n3. **Hyperparameter tuning:**\n   - Bayesian optimization\n   - Meta-learning\n\n4. **Model ensembling:**\n   - Combine best models\n   - Stacking, voting\n\n**Ưu điểm:**\n- Save time\n- Good baseline\n- Accessible to non-experts\n- Try many approaches\n\n**Nhược điểm:**\n- Black box\n- Computational expensive\n- May not find best solution\n- Limited customization\n- Overkill cho simple problems\n\n**Khi nào dùng:**\n- Starting point\n- Baseline comparison\n- Limited ML expertise\n- Have computational resources\n\n**Best practices:**\n- Set time/resource limits\n- Understand results\n- Use as starting point, tune further\n- Validate on hold-out set\n\n### Best Practices\n\n**1. Start Simple:**\n- Begin với simple model (Linear, Logistic)\n- Establish baseline\n- Increase complexity nếu cần\n\n**2. Establish Baseline:**\n- Random prediction\n- Mean/Mode prediction\n- Simple rule-based\n- Must beat baseline\n\n**3. Feature Importance:**\n- Understand which features matter\n- Remove useless features\n- Focus effort on important features\n\n**4. Iterate:**\n- Continuous improvement cycle\n- Experiment → Analyze → Refine\n- Keep track of experiments\n\n**5. Monitor Multiple Metrics:**\n- Không chỉ một metric\n\n**Các khái niệm quan trọng:**\n- Model ensembling là quy trình kết hợp nhiều mô hình học máy riêng lẻ để tạo ra một mô hình mạnh mẽ hơn. Các kỹ thuật phổ biến bao gồm stacking và voting. Trong AutoML, quy trình này được tự động hóa để kết hợp các mô hình tốt nhất đã được huấn luyện, thường dẫn đến hiệu suất dự đoán vượt trội so với bất kỳ mô hình đơn lẻ nào.\n\n**Mối quan hệ:**\n- AutoML tự động hóa quy trình Model ensembling bằng cách kết hợp các mô hình tốt nhất đã được huấn luyện để tạo ra một mô hình mạnh mẽ hơn với hiệu suất dự đoán vượt trội.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Lựa Chọn Đặc Trưng & Tối Ưu Hóa Mô Hình\n```\n**Dấu hiệu:**\n- Large gap giữa curves\n- Training error tiếp tục giảm\n- Validation error không cải thiện\n\n**Giải pháp:**\n- Get more training data\n- Reduce model complexity\n- Increase regularization\n- Feature selection\n- Dropout, early stopping\n\n**3. Good Fit:**\n```\nTraining error: Thấp\nValidation error: Thấp\nGap: Nhỏ\nBoth converge\n```\n**Dấu hiệu:**\n- Small gap\n- Both errors low\n- Converged performance\n\n**4. More Data Helps:**\n```\nValidation error giảm khi tăng data\nGap đang đóng lại\nChưa plateau\n```\n**Hành động:** Get more data!\n\n**5. More Data Doesn't Help:**\n```\nBoth curves plateau\nAdding data không cải thiện\n```\n**Hành động:** Improve features hoặc model\n\n### Bias-Variance Tradeoff (Sự Đánh Đổi Bias-Variance)\n\n**Công thức:**\n$$Expected\\ Error = Bias^2 + Variance + Irreducible\\ Error$$\n\n**Bias (Thiên Lệch):**\n- Error từ giả định đơn giản hóa\n- Underfitting\n- Model không capture được patterns\n- High bias → Systematic errors\n\n**Variance (Phương Sai):**\n- Error từ sensitivity to training data\n- Overfitting\n- Model learns noise\n- High variance → Different results với different data\n\n**Irreducible Error:**\n- Noise trong data\n- Không thể giảm\n- Comes from data collection\n\n**Tradeoff:**\n- Decrease bias → Increase variance\n- Decrease variance → Increase bias\n- Cần balance\n\n**Strategies:**\n\n**Giảm High Bias:**\n1. Increase model complexity\n2. Add more features/polynomial features\n3. Decrease regularization\n4. Train longer\n5. Use ensemble methods\n\n**Giảm High Variance:**\n1. Get more training data\n2. Reduce model complexity\n3. Increase regularization (L1, L2, dropout)\n4. Feature selection\n5. Early stopping\n6. Ensemble methods (bagging)\n\n**Sweet Spot:**\n- Minimize total error\n- Balance bias và variance\n- Depends on problem và data\n\n**Visualize:**\n```\nTotal Error\n    |     \\\n    |      \\___Bias²\n    |___________\\\n    |            \\___\n    |Variance_____\\___Total\n    |________________\\___\n    |___________________\\___\n    +----------------------->\n    Simple          Complex\n            Model Complexity\n```\n\n### Phương Pháp Ensemble\n\nKết hợp nhiều models để cải thiện hiệu suất.\n\n**\"Wisdom of crowds\"**\n\n**Tại sao hoạt động:**\n- Errors của individual models cancel out\n- Diverse models capture different patterns\n- Reduce variance\n- More robust\n\n**1. Bagging (Bootstrap Aggregating):**\n\n**Nguyên lý:**\n- Train multiple models trên bootstrap samples\n- Average predictions (regression) hoặc vote (classification)\n\n**Bootstrap Sampling:**\n- Sample with replacement\n- Same size as original\n- ~63% unique samples mỗi bootstrap\n\n**Thuật toán:**\n1. For i = 1 to M:\n   - Create bootstrap sample $D_i$\n   - Train model $M_i$ on $D_i$\n2. Combine:\n   - Regression: $\\hat{y} = \frac{1}{M}\\sum_{i=1}^{M}M_i(x)$\n   - Classification: Majority vote\n\n**Ưu điểm:**\n- Reduce variance\n- Parallel training\n- Works với high-variance models\n\n**Nhược điểm:**\n- Không giảm bias\n- Có thể chậm (many models)\n\n**Ví dụ:** Random Forest\n\n**2. Boosting:**\n\n**Nguyên lý:**\n- Sequential training\n- Each model corrects errors của previous models\n- Weighted combination\n\n**Thuật toán (general):**\n1. Initialize equal weights\n2. For i = 1 to M:\n   - Train model $M_i$ on weighted data\n   - Tính error\n   - Update weights (increase for misclassified)\n\n**Các khái niệm quan trọng:**\n- Ensemble methods là một kỹ thuật học máy kết hợp nhiều mô hình học yếu (weak learners) để tạo ra một mô hình mạnh hơn và ổn định hơn. Các phương pháp ensemble như Random Forest và Gradient Boosting được sử dụng để giải quyết các vấn đề của Cây Quyết định như overfitting và tính không ổn định. Chúng giúp giảm variance và cải thiện khả năng generalize của mô hình.\n- Ensemble methods là một kỹ thuật trong học máy kết hợp nhiều mô hình học máy (individual models) để tạo ra một mô hình dự đoán mạnh mẽ hơn. Các phương pháp này hoạt động dựa trên nguyên lý \"Wisdom of crowds\", giúp giảm variance, cải thiện độ mạnh mẽ và thường đạt hiệu suất tốt hơn so với một mô hình đơn lẻ. Các ví dụ bao gồm Bagging và Boosting.\n\n**Mối quan hệ:**\n- Ensemble methods, đặc biệt là Bagging, giúp giảm Variance bằng cách kết hợp nhiều mô hình đa dạng, làm cho lỗi của các mô hình riêng lẻ triệt tiêu lẫn nhau.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n\n### Nhược Điểm\n\n**1. Dễ Overfitting:**\n- Cây sâu học cả noise\n- Mô hình phức tạp không generalize tốt\n- Cần pruning hoặc ensemble\n\n**2. Không Ổn Định:**\n- Thay đổi nhỏ trong dữ liệu → cây hoàn toàn khác\n- High variance\n- Giải pháp: Ensemble methods (Random Forest)\n\n**3. Thiên Vị Về Đặc Trưng Có Nhiều Mức:**\n- Đặc trưng với nhiều giá trị unique được ưu tiên\n- Information Gain thiên vị\n- Giải pháp: Gain Ratio (C4.5)\n\n**4. Không Tối Ưu Cho Extrapolation:**\n- Hồi quy chỉ dự đoán trong phạm vi training data\n- Không thể dự đoán ngoài min/max đã thấy\n- Dự đoán là hằng số ở nút lá\n\n**5. Tạo Cây Thiên Vị Với Imbalanced Data:**\n- Ưu tiên lớp đa số\n- Cần class_weight hoặc resampling\n\n**6. Greedy Algorithm:**\n- Chọn phân chia tốt nhất tại thời điểm hiện tại\n- Không đảm bảo cây tối ưu toàn cục\n- Có thể bỏ lỡ cây tốt hơn\n\n**7. Khó Bắt Mối Quan Hệ Tuyến Tính:**\n- Cần nhiều phân chia để xấp xỉ đường thẳng\n- Linear model đơn giản hơn cho quan hệ tuyến tính\n\n### Phương Pháp Ensemble Với Cây\n\n**1. Random Forest (Rừng Ngẫu Nhiên):**\n\n**Nguyên lý:**\n- Xây dựng nhiều cây quyết định\n- Mỗi cây trên bootstrap sample khác nhau\n- Random subset đặc trưng tại mỗi split\n- Kết hợp dự đoán: Voting (classification) hoặc averaging (regression)\n\n**Tham số chính:**\n- `n_estimators`: Số cây (50-500)\n- `max_features`: Số đặc trưng xem xét (sqrt(n) cho classification, n/3 cho regression)\n- `max_depth`: Độ sâu mỗi cây\n- `min_samples_split`, `min_samples_leaf`\n\n**Ưu điểm:**\n- Giảm variance, ít overfitting\n- Ổn định hơn cây đơn\n- Feature importance đáng tin cậy hơn\n- Xử lý tốt high-dimensional data\n- Out-of-bag error estimation\n\n**2. Gradient Boosting:**\n\n**Nguyên lý:**\n- Xây dựng cây tuần tự\n- Mỗi cây học sửa lỗi của cây trước\n- Mỗi cây nhỏ (weak learner)\n- Kết hợp có trọng số\n\n**Công thức:**\n$$F_m(x) = F_{m-1}(x) + \nu \\cdot h_m(x)$$\n\nTrong đó:\n- $F_m$ là mô hình tại iteration $m$\n- $h_m$ là cây mới\n- $\nu$ là learning rate\n\n**Implementations phổ biến:**\n- **XGBoost:** Nhanh, regularization tốt, xử lý missing values\n- **LightGBM:** Rất nhanh, hiệu quả bộ nhớ, leaf-wise growth\n- **CatBoost:** Tốt cho categorical features, ít overfitting\n\n**Ưu điểm:**\n- Hiệu suất cao nhất trong nhiều competition\n- Có thể đạt accuracy rất cao\n- Xử lý tốt heterogeneous features\n\n**Nhược điểm:**\n\n**Các khái niệm quan trọng:**\n- Ensemble methods là một kỹ thuật học máy kết hợp nhiều mô hình học yếu (weak learners) để tạo ra một mô hình mạnh hơn và ổn định hơn. Các phương pháp ensemble như Random Forest và Gradient Boosting được sử dụng để giải quyết các vấn đề của Cây Quyết định như overfitting và tính không ổn định. Chúng giúp giảm variance và cải thiện khả năng generalize của mô hình.\n- Ensemble methods là một kỹ thuật trong học máy kết hợp nhiều mô hình học máy (individual models) để tạo ra một mô hình dự đoán mạnh mẽ hơn. Các phương pháp này hoạt động dựa trên nguyên lý \"Wisdom of crowds\", giúp giảm variance, cải thiện độ mạnh mẽ và thường đạt hiệu suất tốt hơn so với một mô hình đơn lẻ. Các ví dụ bao gồm Bagging và Boosting.\n\n**Mối quan hệ:**\n- Ensemble methods, đặc biệt là Bagging, giúp giảm Variance bằng cách kết hợp nhiều mô hình đa dạng, làm cho lỗi của các mô hình riêng lẻ triệt tiêu lẫn nhau."
        },
        "output_without_context": {
            "question": "Kỹ thuật nào được sử dụng để tập hợp các mô hình phân loại trong học máy, giúp tối ưu hóa hiệu suất mô hình?",
            "answer": "Stacking"
        }
    }
]