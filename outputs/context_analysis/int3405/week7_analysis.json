[
    {
        "topic_description": "Chủ đề này khám phá khái niệm học sâu, nằm trong lĩnh vực học máy, với sự tập trung vào cách mà các thuật toán học sâu học các biểu diễn dữ liệu. Học sinh sẽ được yêu cầu định nghĩa học sâu, nhận diện ứng dụng cụ thể như AlphaGo và ChatGPT, cũng như mô tả cách mà học sâu khác biệt so với học máy truyền thống.",
        "output_with_context": {
            "question": "Học sâu (Deep Learning) là một nhánh của học máy (Machine Learning) sử dụng gì để học các biểu diễn dữ liệu?",
            "answer": "Mạng nơ-ron nhân tạo với nhiều lớp ẩn.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n- Matrix factorization (NMF, SVD)\n\n**5. Topic Modeling:**\n- Document clustering\n- Automatic tagging\n- Content organization\n- Trend detection\n\n**6. Gene Expression Analysis:**\n- Group similar genes\n- Identify cancer subtypes\n- Drug discovery\n- Understanding diseases\n\n**7. Social Network Analysis:**\n- Community detection\n- Influencer identification\n- Link prediction\n- Recommendation\n\n**8. Data Preprocessing:**\n- Feature extraction (PCA, ICA)\n- Noise reduction (autoencoders)\n- Data compression\n- Dimensionality reduction\n\n**9. Market Basket Analysis:**\n- Product recommendations\n- Store layout\n- Promotions\n- Cross-selling\n\n**10. Image Segmentation:**\n- Medical imaging\n- Object detection preparation\n- Video processing\n- Computer vision preprocessing\n\n---\n\n## Học Sâu (Deep Learning)\n\n### Giới Thiệu về Học Sâu\n\nHọc sâu (Deep Learning) là một nhánh con của học máy sử dụng mạng nơ-ron nhân tạo với nhiều lớp ẩn để học các biểu diễn phân cấp của dữ liệu. Khác với các phương pháp học máy truyền thống, học sâu có khả năng tự động trích xuất đặc trưng từ dữ liệu thô mà không cần kỹ thuật đặc trưng thủ công.\n\n**Đặc điểm chính:**\n- **Học biểu diễn phân cấp:** Các lớp đầu học các đặc trưng cấp thấp (cạnh, góc), các lớp sau học đặc trưng cấp cao hơn (hình dạng, đối tượng)\n- **Khả năng xử lý dữ liệu lớn:** Hiệu suất tăng theo lượng dữ liệu\n- **End-to-end learning:** Học trực tiếp từ đầu vào thô đến đầu ra mong muốn\n- **Tự động trích xuất đặc trưng:** Không cần thiết kế đặc trưng thủ công\n\n**Ứng dụng đã cách mạng hóa:**\n- Thị giác máy tính (nhận dạng ảnh, phát hiện đối tượng)\n- Xử lý ngôn ngữ tự nhiên (dịch máy, chatbot, sinh văn bản)\n- Nhận dạng giọng nói (trợ lý ảo, chuyển đổi giọng nói thành văn bản)\n- Y tế (chẩn đoán hình ảnh, phát triển thuốc)\n- Tự động hóa (xe tự lái, robot)\n\n### Mạng Nơ-ron Nhân Tạo (Artificial Neural Networks - ANN)\n\nMạng nơ-ron nhân tạo được lấy cảm hứng từ cách thức hoạt động của não người, trong đó các nơ-ron sinh học truyền tín hiệu cho nhau thông qua các synapse.\n\n### Perceptron - Đơn Vị Cơ Bản\n\nPerceptron là đơn vị mạng nơ-ron đơn giản nhất, được phát minh bởi Frank Rosenblatt năm 1958.\n\n**Công thức:**\n$$y = \\sigma(w^Tx + b)$$\n\nTrong đó:\n- $x = [x_1, x_2, ..., x_n]^T$: Vector đầu vào (các đặc trưng)\n- $w = [w_1, w_2, ..., w_n]^T$: Vector trọng số (weights)\n- $b$: Hệ số điều chỉnh (bias) - cho phép dịch chuyển hàm quyết định\n- $\\sigma$: Hàm kích hoạt (activation function)\n- $y$: Đầu ra dự đoán\n\n\n**Các khái niệm quan trọng:**\n- Học Sâu (Deep Learning) là một nhánh con của học máy sử dụng mạng nơ-ron nhân tạo với nhiều lớp ẩn để học các biểu diễn phân cấp của dữ liệu. Nó có khả năng tự động trích xuất đặc trưng và xử lý dữ liệu lớn, cách mạng hóa các ứng dụng như thị giác máy tính và xử lý ngôn ngữ tự nhiên.\n- Học Không Giám Sát là một nhánh của Học Máy, nơi các mô hình hoặc thuật toán học từ dữ liệu không được gán nhãn. Mục tiêu chính là tìm kiếm các cấu trúc, mẫu hoặc nhóm ẩn trong dữ liệu. Các kỹ thuật phổ biến bao gồm phân cụm, giảm chiều dữ liệu và phân tích liên kết.\n- Học Máy là một lĩnh vực của trí tuệ nhân tạo cho phép hệ thống học từ dữ liệu, xác định các mẫu và đưa ra quyết định với sự can thiệp tối thiểu của con người, mà không cần được lập trình rõ ràng. Nó bao gồm nhiều phương pháp và thuật toán để xây dựng các mô hình dự đoán hoặc phân loại, với các nhánh như Học Không Giám Sát và Học Sâu.\n\n**Mối quan hệ:**\n- Học Sâu sử dụng mạng nơ-ron nhân tạo với nhiều lớp ẩn để học biểu diễn dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n- Kết hợp tất cả features để ra quyết định cuối cùng\n- Classification head\n\n**Nhược điểm:**\n- **Nhiều parameters:** Có thể chiếm 90% tổng số parameters\n- Dễ overfit\n- Xu hướng thay thế bằng Global Average Pooling + 1 FC nhỏ\n\n**Kiến Trúc Điển Hình:**\n\n**Pattern chung:**\n```\nInput → [Conv → ReLU → Pool] × N → [FC] × M → Output\n```\n\n**Ví dụ cụ thể:**\n```\nInput (224×224×3)\n↓\nConv 64 filters 3×3, ReLU (224×224×64)\n↓\nMaxPool 2×2 (112×112×64)\n↓\nConv 128 filters 3×3, ReLU (112×112×128)\n↓\nMaxPool 2×2 (56×56×128)\n↓\nConv 256 filters 3×3, ReLU (56×56×256)\n↓\nMaxPool 2×2 (28×28×256)\n↓\nFlatten (200,704 dimensions)\n↓\nFC 1024, ReLU\n↓\nDropout 0.5\n↓\nFC 10 (num_classes)\n↓\nSoftmax\n```\n\n**Các Kiến Trúc CNN Kinh Điển:**\n\n**LeNet-5 (1998 - Yann LeCun):**\n- Một trong những CNN đầu tiên\n- Phân loại chữ số viết tay (MNIST)\n- Kiến trúc: Conv → Pool → Conv → Pool → FC → FC\n- Chỉ ~60K parameters\n\n**AlexNet (2012 - Krizhevsky, Sutskever, Hinton):**\n- **Breakthrough moment** trong Deep Learning\n- Thắng ImageNet 2012 với top-5 error 15.3% (giảm 10% so với runner-up)\n- 8 layers, ~60M parameters\n\n**Đóng góp quan trọng:**\n- Sử dụng **ReLU** thay vì tanh/sigmoid\n- **Dropout** regularization\n- **Data augmentation** mạnh\n- **GPU training** (2 GPUs)\n- Local Response Normalization (LRN)\n\n**VGGNet (2014 - Visual Geometry Group, Oxford):**\n- Rất sâu: VGG-16 (16 layers), VGG-19 (19 layers)\n- **Đơn giản và đồng nhất:** Chỉ dùng conv 3×3, pool 2×2\n- ~138M parameters (rất lớn!)\n\n**Kiến trúc VGG-16:**\n```\nInput (224×224×3)\n↓\n[Conv 3×3, 64] × 2 → Pool\n↓\n[Conv 3×3, 128] × 2 → Pool\n↓\n[Conv 3×3, 256] × 3 → Pool\n↓\n[Conv 3×3, 512] × 3 → Pool\n↓\n[Conv 3×3, 512] × 3 → Pool\n↓\nFC 4096 → FC 4096 → FC 1000\n```\n\n**Insight:**\n- Nhiều conv 3×3 stacked = receptive field lớn hơn nhưng ít params hơn\n- 2 conv 3×3 = receptive field 5×5\n- 3 conv 3×3 = receptive field 7×7\n\n**GoogLeNet/Inception (2014 - Google):**\n- Thắng ImageNet 2014\n- 22 layers nhưng chỉ 7M parameters (ít hơn AlexNet!)\n- **Inception module:** Ý tưởng chính\n\n**Inception Module:**\n- Áp dụng **đồng thời** nhiều kích thước filter (1×1, 3×3, 5×5) và pooling\n- Concatenate outputs\n- Network tự học combination nào tốt\n\n```\nInput\n├─ 1×1 conv\n├─ 1×1 conv → 3×3 conv\n├─ 1×1 conv → 5×5 conv\n\n**Các khái niệm quan trọng:**\n- Deep Learning là một nhánh của Machine Learning sử dụng mạng nơ-ron sâu (deep neural networks) với nhiều lớp để học các biểu diễn dữ liệu phức tạp. Nó có khả năng tự động trích xuất các đặc trưng từ dữ liệu thô, từ các đặc trưng cấp thấp như kết cấu và mẫu đến các đặc trưng cấp cao hơn như các phần của vật thể và vật thể hoàn chỉnh. Deep Learning đã đạt được thành công lớn trong nhiều lĩnh vực như xử lý ảnh (thị giác máy tính, nhận dạng hình ảnh), xử lý ngôn ngữ tự nhiên và nhận dạng giọng nói, với các ứng dụng bao gồm hệ thống gia sư thông minh và đề xuất nội dung. Các kiến trúc hiện đại của Deep Learning có thể được huấn luyện qua nhiều lần lặp mà không lo vấn đề gradient vanishing.\n- Deep Learning là một nhánh của Machine Learning sử dụng mạng nơ-ron sâu để học các biểu diễn dữ liệu. Các mô hình Deep Learning thường kết hợp tất cả các features để đưa ra quyết định cuối cùng, thường có một classification head ở cuối. Chúng có nhược điểm là có nhiều parameters, dễ overfit, và xu hướng được thay thế bằng Global Average Pooling + 1 FC nhỏ.\n- Deep Learning là một tập hợp các kỹ thuật sử dụng mạng nơ-ron sâu (Deep Neural Networks) làm Function Approximators trong Reinforcement Learning. Các kiến trúc phổ biến bao gồm DNN, CNN và RNN, cho phép xử lý dữ liệu phức tạp như hình ảnh hoặc chuỗi thời gian.\n\n**Mối quan hệ:**\n- Activation Functions cải thiện khả năng học của Deep Learning bằng cách thêm tính phi tuyến, cho phép mô hình học các quan hệ phức tạp trong dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n- Lớp output: 10 nơ-ron (phân loại 10 chữ số) → $W^{[3]}$: 10×2\n\n### Hàm Kích Hoạt (Activation Functions)\n\nHàm kích hoạt thêm tính phi tuyến vào mạng, cho phép học các quan hệ phức tạp. Không có hàm kích hoạt, mạng nhiều lớp chỉ tương đương một phép biến đổi tuyến tính.\n\n**1. Sigmoid:**\n$$\\sigma(z) = \frac{1}{1 + e^{-z}}$$\n\n**Đặc điểm:**\n- Đầu ra: khoảng (0, 1)\n- Hình dạng chữ S, trơn và khả vi\n- Có thể hiểu như xác suất\n\n**Ưu điểm:**\n- Đầu ra bị chặn, dễ diễn giải\n- Phù hợp cho lớp output trong phân loại nhị phân\n\n**Nhược điểm:**\n- **Vanishing gradient:** Gradient gần như bằng 0 khi $|z|$ lớn\n- Output không tập trung quanh 0 (not zero-centered)\n- Tính toán hàm exp tốn kém\n- Ít được dùng trong lớp ẩn của mạng sâu\n\n**2. Tanh (Hyperbolic Tangent):**\n$$\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} = \frac{2}{1+e^{-2z}} - 1$$\n\n**Đặc điểm:**\n- Đầu ra: khoảng (-1, 1)\n- Là phiên bản dịch chuyển và co giãn của sigmoid\n\n**Ưu điểm:**\n- Zero-centered (đầu ra tập trung quanh 0)\n- Gradient mạnh hơn sigmoid\n- Thường hoạt động tốt hơn sigmoid trong lớp ẩn\n\n**Nhược điểm:**\n- Vẫn bị vanishing gradient\n- Tính toán hàm exp tốn kém\n\n**3. ReLU (Rectified Linear Unit):**\n$$ReLU(z) = \\max(0, z) = \begin{cases} z & \text{nếu } z > 0 \\ 0 & \text{nếu } z \\leq 0 \\end{cases}$$\n\n**Đặc điểm:**\n- Cực kỳ đơn giản và hiệu quả\n- Là hàm kích hoạt phổ biến nhất cho lớp ẩn\n\n**Ưu điểm:**\n- **Tính toán nhanh:** Chỉ cần so sánh với 0\n- **Không bị vanishing gradient** khi $z > 0$\n- **Sparsity:** Một số nơ-ron có activation = 0, tạo biểu diễn thưa\n- **Tăng tốc hội tụ:** Nhanh hơn sigmoid/tanh 6 lần\n\n**Nhược điểm:**\n- **Dying ReLU problem:** Nếu $z < 0$ trong quá trình training, gradient = 0, nơ-ron \"chết\" và không bao giờ được cập nhật\n- Output không zero-centered\n- Unbounded output (có thể dẫn đến giá trị quá lớn)\n\n**4. Leaky ReLU:**\n$$LeakyReLU(z) = \\max(\\alpha z, z) = \begin{cases} z & \text{nếu } z > 0 \\ \\alpha z & \text{nếu } z \\leq 0 \\end{cases}$$\n\nVới $\\alpha$ thường là 0.01 hoặc 0.02\n\n**Ưu điểm:**\n- Khắc phục dying ReLU: vẫn có gradient nhỏ khi $z < 0$\n- Giữ được ưu điểm tính toán nhanh của ReLU\n\n\n**Các khái niệm quan trọng:**\n- Deep Learning là một nhánh của Machine Learning sử dụng mạng nơ-ron sâu (deep neural networks) với nhiều lớp để học các biểu diễn dữ liệu phức tạp. Nó có khả năng tự động trích xuất các đặc trưng từ dữ liệu thô, từ các đặc trưng cấp thấp như kết cấu và mẫu đến các đặc trưng cấp cao hơn như các phần của vật thể và vật thể hoàn chỉnh. Deep Learning đã đạt được thành công lớn trong nhiều lĩnh vực như xử lý ảnh (thị giác máy tính, nhận dạng hình ảnh), xử lý ngôn ngữ tự nhiên và nhận dạng giọng nói, với các ứng dụng bao gồm hệ thống gia sư thông minh và đề xuất nội dung. Các kiến trúc hiện đại của Deep Learning có thể được huấn luyện qua nhiều lần lặp mà không lo vấn đề gradient vanishing.\n- Deep Learning là một nhánh của Machine Learning sử dụng mạng nơ-ron sâu để học các biểu diễn dữ liệu. Các mô hình Deep Learning thường kết hợp tất cả các features để đưa ra quyết định cuối cùng, thường có một classification head ở cuối. Chúng có nhược điểm là có nhiều parameters, dễ overfit, và xu hướng được thay thế bằng Global Average Pooling + 1 FC nhỏ.\n- Deep Learning là một tập hợp các kỹ thuật sử dụng mạng nơ-ron sâu (Deep Neural Networks) làm Function Approximators trong Reinforcement Learning. Các kiến trúc phổ biến bao gồm DNN, CNN và RNN, cho phép xử lý dữ liệu phức tạp như hình ảnh hoặc chuỗi thời gian.\n\n**Mối quan hệ:**\n- Activation Functions cải thiện khả năng học của Deep Learning bằng cách thêm tính phi tuyến, cho phép mô hình học các quan hệ phức tạp trong dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n- **Discontinued** (2017)\n- Legacy influence\n\n**So Sánh:**\n\n| Feature | TensorFlow/Keras | PyTorch | JAX |\n|---------|-----------------|---------|-----|\n| Ease of learning | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐ |\n| Production | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| Research | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |\n| Performance | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |\n| Community | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ |\n| Deployment | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |\n| Debugging | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ |\n\n**Recommendation:**\n- **Learning:** PyTorch hoặc Keras\n- **Production:** TensorFlow/Keras\n- **Research:** PyTorch\n- **High-performance computing:** JAX\n- Ultimately: **Pick one và master it!** Concepts transfer dễ dàng\n\n### Ứng Dụng của Học Sâu (Applications of Deep Learning)\n\n**Computer Vision (Thị Giác Máy Tính):**\n\n**1. Image Classification:**\n- Phân loại ảnh vào categories\n- **Applications:** Medical diagnosis, quality control, content moderation\n- **Architectures:** ResNet, EfficientNet, ViT\n- **Datasets:** ImageNet, CIFAR, Places\n\n**2. Object Detection:**\n- Phát hiện và localize objects trong ảnh\n- **Applications:** Autonomous vehicles, surveillance, retail analytics\n- **Methods:**\n  - **Two-stage:** R-CNN, Fast R-CNN, Faster R-CNN (accurate, chậm)\n  - **One-stage:** YOLO, SSD, RetinaNet (fast, real-time)\n- **Advanced:** EfficientDet, DETR (transformer-based)\n\n**3. Semantic Segmentation:**\n- Phân loại mỗi pixel (pixel-wise classification)\n- **Applications:** Medical imaging, autonomous driving, satellite imagery\n- **Architectures:** FCN, U-Net, DeepLab, SegFormer\n\n**4. Instance Segmentation:**\n- Segment mỗi object instance riêng biệt\n- **Applications:** Cell counting, object manipulation, scene understanding\n- **Methods:** Mask R-CNN, YOLACT\n\n**5. Face Recognition:**\n- Identify/verify người từ faces\n- **Applications:** Security, authentication, photo organization\n- **Methods:** FaceNet, DeepFace, ArcFace\n\n**6. Medical Image Analysis:**\n- **X-ray, CT, MRI analysis:** Disease detection, tumor segmentation\n- **Pathology:** Cancer cell detection\n- **Retinal imaging:** Diabetic retinopathy\n- **Impact:** Earlier detection, assist doctors, reduce workload\n\n**7. Image Generation:**\n- GANs, Diffusion models\n- Art, design, data augmentation\n\n**8. Pose Estimation:**\n- Detect human pose (joints, keypoints)\n- **Applications:** Sports analytics, AR, human-computer interaction\n\n**Natural Language Processing:**\n\n**1. Machine Translation:**\n- Translate text giữa languages\n- **Methods:** Seq2Seq, Transformer, mT5\n- **Applications:** Google Translate, multilingual communication\n- **Challenges:** Idioms, context, rare languages\n\n**2. Text Generation:**\n- Generate coherent text\n- **Models:** GPT-2, GPT-3, GPT-4\n- **Applications:**\n  - Content creation, storytelling\n  - Code generation (Copilot, CodeGen)\n  - Dialogue systems (ChatGPT)\n\n**3. Sentiment Analysis:**\n- Classify sentiment (positive, negative, neutral)\n- **Applications:** Brand monitoring, customer feedback, market research\n- **Methods:** BERT, RoBERTa fine-tuned\n\n**4. Question Answering:**\n- Answer questions từ context\n- **Types:**\n  - Extractive (select span từ text)\n  - Abstractive (generate answer)\n- **Applications:** Customer support, information retrieval\n\n**Các khái niệm quan trọng:**\n- Deep Learning là một nhánh của Machine Learning sử dụng mạng nơ-ron sâu (deep neural networks) với nhiều lớp để học các biểu diễn dữ liệu phức tạp. Nó có khả năng tự động trích xuất các đặc trưng từ dữ liệu thô, từ các đặc trưng cấp thấp như kết cấu và mẫu đến các đặc trưng cấp cao hơn như các phần của vật thể và vật thể hoàn chỉnh. Deep Learning đã đạt được thành công lớn trong nhiều lĩnh vực như xử lý ảnh (thị giác máy tính, nhận dạng hình ảnh), xử lý ngôn ngữ tự nhiên và nhận dạng giọng nói, với các ứng dụng bao gồm hệ thống gia sư thông minh và đề xuất nội dung. Các kiến trúc hiện đại của Deep Learning có thể được huấn luyện qua nhiều lần lặp mà không lo vấn đề gradient vanishing.\n\n**Mối quan hệ:**\n- Activation Functions cải thiện khả năng học của Deep Learning bằng cách thêm tính phi tuyến, cho phép mô hình học các quan hệ phức tạp trong dữ liệu."
        },
        "output_without_context": {
            "question": "Học sâu là gì trong lĩnh vực học máy?",
            "answer": "Là một nhánh của học máy tập trung vào việc học các biểu diễn dữ liệu thông qua các mạng nơ-ron sâu."
        }
    },
    {
        "topic_description": "Chủ đề này tập trung vào các khía cạnh cơ bản của mạng nơ-ron nhân tạo (ANN), bao gồm cấu trúc của nó với các lớp đầu vào, lớp ẩn, và lớp đầu ra. Học sinh sẽ cần nhớ công thức tính toán trọng số và ứng dụng của mạng trong các bài toán phân loại. Thảo luận về ví dụ thực tế sẽ làm rõ ứng dụng của ANN trong các lĩnh vực khác nhau.",
        "output_with_context": {
            "question": "Công thức nào được sử dụng để tính toán đầu ra của một perceptron trong mạng nơ-ron nhân tạo?",
            "answer": "y = σ(w^Tx + b)",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n- Matrix factorization (NMF, SVD)\n\n**5. Topic Modeling:**\n- Document clustering\n- Automatic tagging\n- Content organization\n- Trend detection\n\n**6. Gene Expression Analysis:**\n- Group similar genes\n- Identify cancer subtypes\n- Drug discovery\n- Understanding diseases\n\n**7. Social Network Analysis:**\n- Community detection\n- Influencer identification\n- Link prediction\n- Recommendation\n\n**8. Data Preprocessing:**\n- Feature extraction (PCA, ICA)\n- Noise reduction (autoencoders)\n- Data compression\n- Dimensionality reduction\n\n**9. Market Basket Analysis:**\n- Product recommendations\n- Store layout\n- Promotions\n- Cross-selling\n\n**10. Image Segmentation:**\n- Medical imaging\n- Object detection preparation\n- Video processing\n- Computer vision preprocessing\n\n---\n\n## Học Sâu (Deep Learning)\n\n### Giới Thiệu về Học Sâu\n\nHọc sâu (Deep Learning) là một nhánh con của học máy sử dụng mạng nơ-ron nhân tạo với nhiều lớp ẩn để học các biểu diễn phân cấp của dữ liệu. Khác với các phương pháp học máy truyền thống, học sâu có khả năng tự động trích xuất đặc trưng từ dữ liệu thô mà không cần kỹ thuật đặc trưng thủ công.\n\n**Đặc điểm chính:**\n- **Học biểu diễn phân cấp:** Các lớp đầu học các đặc trưng cấp thấp (cạnh, góc), các lớp sau học đặc trưng cấp cao hơn (hình dạng, đối tượng)\n- **Khả năng xử lý dữ liệu lớn:** Hiệu suất tăng theo lượng dữ liệu\n- **End-to-end learning:** Học trực tiếp từ đầu vào thô đến đầu ra mong muốn\n- **Tự động trích xuất đặc trưng:** Không cần thiết kế đặc trưng thủ công\n\n**Ứng dụng đã cách mạng hóa:**\n- Thị giác máy tính (nhận dạng ảnh, phát hiện đối tượng)\n- Xử lý ngôn ngữ tự nhiên (dịch máy, chatbot, sinh văn bản)\n- Nhận dạng giọng nói (trợ lý ảo, chuyển đổi giọng nói thành văn bản)\n- Y tế (chẩn đoán hình ảnh, phát triển thuốc)\n- Tự động hóa (xe tự lái, robot)\n\n### Mạng Nơ-ron Nhân Tạo (Artificial Neural Networks - ANN)\n\nMạng nơ-ron nhân tạo được lấy cảm hứng từ cách thức hoạt động của não người, trong đó các nơ-ron sinh học truyền tín hiệu cho nhau thông qua các synapse.\n\n### Perceptron - Đơn Vị Cơ Bản\n\nPerceptron là đơn vị mạng nơ-ron đơn giản nhất, được phát minh bởi Frank Rosenblatt năm 1958.\n\n**Công thức:**\n$$y = \\sigma(w^Tx + b)$$\n\nTrong đó:\n- $x = [x_1, x_2, ..., x_n]^T$: Vector đầu vào (các đặc trưng)\n- $w = [w_1, w_2, ..., w_n]^T$: Vector trọng số (weights)\n- $b$: Hệ số điều chỉnh (bias) - cho phép dịch chuyển hàm quyết định\n- $\\sigma$: Hàm kích hoạt (activation function)\n- $y$: Đầu ra dự đoán\n\n\n**Các khái niệm quan trọng:**\n- Mạng nơ-ron nhân tạo (Artificial Neural Networks - ANN) là một mô hình tính toán lấy cảm hứng từ cấu trúc và chức năng của não bộ, bao gồm nhiều nơ-ron nhân tạo được kết nối với nhau thành các lớp để học các mẫu phức tạp từ dữ liệu.\n\n**Mối quan hệ:**\n- Mạng nơ-ron nhân tạo chứa Perceptron như đơn vị cơ bản của nó.\n- Học Sâu sử dụng mạng nơ-ron nhân tạo với nhiều lớp ẩn để học biểu diễn dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n**Cách hoạt động:**\n1. Nhận đầu vào từ các đặc trưng\n2. Tính tổng có trọng số: $z = w^Tx + b = \\sum_{i=1}^{n}w_i x_i + b$\n3. Áp dụng hàm kích hoạt để tạo đầu ra\n\n**Hạn chế quan trọng:** \n- Chỉ có thể học các mẫu phân tách tuyến tính (linearly separable)\n- Không thể giải quyết bài toán XOR\n- Không thể mô hình hóa các quan hệ phi tuyến phức tạp\n\n**Ví dụ:** Một perceptron có thể phân loại điểm nằm phía trên hay dưới một đường thẳng, nhưng không thể phân loại các điểm trong bài toán XOR (cần đường cong để phân tách).\n\n### Perceptron Đa Lớp (Multi-Layer Perceptron - MLP)\n\nMLP khắc phục hạn chế của perceptron đơn bằng cách xếp chồng nhiều lớp, cho phép học các hàm phi tuyến phức tạp.\n\n**Kiến trúc:**\n\n**1. Lớp đầu vào (Input Layer):**\n- Nhận dữ liệu thô\n- Số nơ-ron = số đặc trưng đầu vào\n- Không có phép biến đổi, chỉ truyền dữ liệu\n\n**2. Lớp ẩn (Hidden Layers):**\n- Thực hiện các phép biến đổi phi tuyến\n- Số lượng có thể từ 1 đến hàng trăm lớp\n- Mỗi lớp học biểu diễn trừu tượng hơn\n- Số nơ-ron trong mỗi lớp là hyperparameter\n\n**3. Lớp đầu ra (Output Layer):**\n- Tạo dự đoán cuối cùng\n- Số nơ-ron phụ thuộc vào bài toán:\n  - Hồi quy: 1 nơ-ron\n  - Phân loại nhị phân: 1 nơ-ron (với sigmoid) hoặc 2 (với softmax)\n  - Phân loại đa lớp: K nơ-ron (K = số lớp)\n\n**Lan truyền xuôi (Forward Propagation):**\n\nQuá trình tính toán từ đầu vào đến đầu ra qua các lớp:\n\nVới lớp $l$:\n$$z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$$\n$$a^{[l]} = \\sigma(z^{[l]})$$\n\nTrong đó:\n- $W^{[l]}$: Ma trận trọng số của lớp $l$ (kích thước $n^{[l]} \times n^{[l-1]}$)\n- $b^{[l]}$: Vector bias của lớp $l$ (kích thước $n^{[l]} \times 1$)\n- $a^{[l-1]}$: Activation của lớp trước (đầu vào cho lớp $l$)\n- $z^{[l]}$: Pre-activation (trước khi áp dụng hàm kích hoạt)\n- $a^{[l]}$: Activation (sau khi áp dụng hàm kích hoạt)\n- $\\sigma$: Hàm kích hoạt\n\n**Ví dụ minh họa:**\n- Lớp 1: 3 nơ-ron, nhận input 784 chiều (ảnh 28×28) → $W^{[1]}$: 3×784\n- Lớp 2: 2 nơ-ron, nhận từ lớp 1 → $W^{[2]}$: 2×3\n\n**Các khái niệm quan trọng:**\n- Lớp đầu ra (Output Layer) là lớp cuối cùng trong kiến trúc mạng nơ-ron, bao gồm cả MLP, chịu trách nhiệm tạo ra dự đoán cuối cùng của mô hình. Số lượng nơ-ron trong lớp này phụ thuộc vào loại bài toán: 1 nơ-ron cho hồi quy, 1 nơ-ron (với hàm kích hoạt sigmoid) hoặc 2 nơ-ron (với hàm kích hoạt softmax) cho phân loại nhị phân, và K nơ-ron (trong đó K là số lượng lớp) cho phân loại đa lớp. Ví dụ, 10 nơ-ron sẽ được sử dụng cho bài toán phân loại 10 chữ số.\n\n**Mối quan hệ:**\n- Multi-Layer Perceptron (MLP) chứa Lớp đầu ra.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n  - Exponential decay: Giảm dần liên tục\n  - Cosine annealing: Smooth decrease\n  - ReduceLROnPlateau: Giảm khi validation loss plateau\n\n**Batch Size:**\n- **Larger batches (128-512):**\n  - Pros: Faster training (parallelization), stable gradients\n  - Cons: Cần nhiều memory, có thể generalize kém hơn\n- **Smaller batches (32-64):**\n  - Pros: Regularization effect, better generalization, ít memory\n  - Cons: Noisy gradients, train chậm hơn\n- **Rule of thumb:** Bắt đầu 32-64, tăng nếu có memory\n\n**Number of Epochs:**\n- Start với nhiều epochs, dùng early stopping\n- Monitor validation loss\n\n**Network Architecture:**\n- Number of layers: Start shallow, thêm depth nếu underfitting\n- Number of neurons: Enough capacity nhưng không quá\n- Dropout rate: 0.2-0.5\n\n**Regularization Strength:**\n- Weight decay (L2): 1e-4 hoặc 1e-5\n- Dropout: 0.5 for FC, 0.2-0.3 for others\n\n**Hyperparameter Tuning Strategies:**\n- **Manual tuning:** Hiểu behavior, instructive\n- **Grid search:** Exhaustive nhưng expensive\n- **Random search:** Often better than grid\n- **Bayesian optimization:** Intelligent search (Optuna, Hyperopt)\n- **Learning rate first!** Tune LR trước, sau đó others\n\n**4. Tips Trong Training:**\n\n**Monitor Metrics:**\n- **Training loss:** Phải giảm\n- **Validation loss:** Quan trọng nhất, measure generalization\n- **Train/val gap:** Lớn → overfitting\n- **Accuracy, F1, etc.:** Task-specific metrics\n\n**Visualization:**\n- Plot loss curves (train vs validation)\n- Learning rate vs loss\n- Gradient norms\n- Activation distributions\n- Attention weights (interpretability)\n\n**Learning Rate Scheduling:**\n- Essential cho converge tốt\n- Warmup (increase gradually) cho transformers\n- Decay về cuối training\n\n**Gradient Clipping:**\n- **Critical for RNNs** (prevent exploding gradients)\n- Useful cho transformers\n- Typical value: 1.0 hoặc 5.0\n\n**Checkpoint Best Models:**\n- Save model với best validation metric\n- Checkpoint mỗi N epochs hoặc khi improve\n- Resume training nếu crash\n\n**Early Stopping:**\n- Stop nếu val loss không improve sau N epochs (patience=10-20)\n- Saves time, prevents overfitting\n\n**Mixed Precision Training:**\n- FP16 thay vì FP32\n- **2×** faster, ít memory hơn\n- Nvidia GPUs (Tensor Cores)\n\n**5. Debugging Deep Learning Models:**\n\n**Start Small:**\n- **Overfit một batch nhỏ:** Nếu không overfit được → bug trong model/training\n- Nếu overfit được → model có capacity, issue là generalization\n\n**Check Data:**\n- Visualize samples: Correct labels? Reasonable augmentation?\n- Check data pipeline: No bugs?\n- Shuffle properly?\n\n**Check Gradients:**\n- Vanishing gradients: Gradients → 0, không học được\n  - Solutions: Change activation (ReLU), batch norm, residual connections\n- Exploding gradients: Gradients → ∞\n  - Solutions: Gradient clipping, lower learning rate\n- Use gradient visualization tools\n\n**Sanity Checks:**\n- Disable regularization (dropout, weight decay): Should overfit\n- Train trên random labels: Should fit (báo model có capacity)\n- Check loss: Không phải NaN, không explode\n\n**Common Issues:**\n\n| Symptom | Possible Cause | Solution |\n|---------|---------------|----------|\n| Loss is NaN | Learning rate too high, numerical instability | Lower LR, gradient clipping, check data |\n| Loss không giảm | Learning rate too low, bad initialization | Increase LR, check data/labels |\n| Train loss giảm, val loss không giảm | Overfitting | Regularization, data augmentation, smaller model |\n| Both losses cao | Underfitting | Bigger model, more layers, train longer |\n| Loss oscillates | Batch size too small, LR too high | Increase batch size, lower LR |\n\n**Use Tools:**\n\n**Các khái niệm quan trọng:**\n- Number of neurons là số lượng neuron trong mỗi lớp của mạng neural network. Cần đảm bảo đủ số neuron để mô hình có đủ \"capacity\" (khả năng học) nhưng không quá nhiều để tránh overfitting và tăng chi phí tính toán.\n\n**Mối quan hệ:**\n- Tăng Number of neurons là một giải pháp cho tình trạng Both losses cao (underfitting) bằng cách tăng capacity của mô hình.\n- Number of neurons không quá nhiều có thể ngăn chặn Overfitting bằng cách giới hạn capacity của mô hình, buộc nó phải học các đặc trưng tổng quát hơn.\n- Number of neurons đủ lớn có thể ngăn chặn Underfitting bằng cách cung cấp đủ capacity cho mô hình để học các đặc trưng phức tạp."
        },
        "output_without_context": {
            "question": "Mạng nơ-ron nhân tạo (ANN) bao gồm các lớp nào trong cấu trúc của nó?",
            "answer": "Lớp đầu vào, lớp ẩn và lớp đầu ra."
        }
    },
    {
        "topic_description": "Chủ đề này tập trung vào việc khám phá các phương pháp phân loại trong học máy, bao gồm Hồi quy Logistic và Bộ phân loại Naïve Bayes được đề cập trong các bài giảng trước. Học sinh sẽ được yêu cầu so sánh những mô hình này và thảo luận về ưu và nhược điểm của từng mô hình trong việc giải quyết các bài toán phân loại thực tế.",
        "output_with_context": {
            "question": "So sánh Hồi quy Logistic và Bộ phân loại Naïve Bayes, mô hình nào có thể cung cấp xác suất cho từng lớp trong bài toán phân loại đa lớp?",
            "answer": "Hồi quy Logistic.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n   - Merge chúng thành 1 cluster\n3. Until: Chỉ còn 1 cluster\n\n**Steps chi tiết:**\n- Initialize: N clusters\n- Iteration 1: N-1 clusters\n- Iteration 2: N-2 clusters\n- ...\n- Final: 1 cluster\n\n**2. Divisive (Top-Down - Phân Chia):**\n\n**Thuật toán:**\n1. Start: Tất cả điểm trong 1 cluster\n2. Repeat:\n   - Chọn cluster để split\n   - Chia thành 2 sub-clusters\n3. Until: Mỗi điểm là 1 cluster\n\n**Ít phổ biến:** Computationally expensive hơn\n\n**Linkage Methods (Cách Đo Khoảng Cách Giữa Clusters):**\n\n**1. Single Linkage (Minimum):**\n$$d(C_i, C_j) = \\min_{x \\in C_i, y \\in C_j}d(x,y)$$\n- Khoảng cách giữa 2 điểm gần nhất\n- Tạo long, chain-like clusters\n- Sensitive to noise và outliers\n\n**2. Complete Linkage (Maximum):**\n$$d(C_i, C_j) = \\max_{x \\in C_i, y \\in C_j}d(x,y)$$\n- Khoảng cách giữa 2 điểm xa nhất\n- Tạo compact, spherical clusters\n- Ít sensitive to outliers\n\n**3. Average Linkage:**\n$$d(C_i, C_j) = \frac{1}{|C_i||C_j|}\\sum_{x \\in C_i}\\sum_{y \\in C_j}d(x,y)$$\n- Trung bình tất cả pairwise distances\n- Balance giữa single và complete\n- Phổ biến choice\n\n**4. Ward's Method:**\n- Minimize within-cluster variance sau khi merge\n- Maximize between-cluster variance\n- Tạo balanced, compact clusters\n- Thường cho kết quả tốt nhất\n- Phổ biến nhất trong thực tế\n\n**Dendrogram (Biểu Đồ Cây):**\n\nTree diagram showing cluster hierarchy.\n\n**Đọc Dendrogram:**\n- Vertical axis: Distance/dissimilarity\n- Horizontal axis: Samples\n- Height của merge: Distance giữa clusters\n- Càng cao merge càng dissimilar\n\n**Cutting Dendrogram:**\n- Vẽ horizontal line\n- Number of intersections = Number of clusters\n- Height của cut = dissimilarity threshold\n\n**Ưu Điểm:**\n- Không cần specify K trước\n- Dendrogram provides insights\n- Flexible - có thể chọn K sau\n- Deterministic (no randomness)\n\n**Nhược Điểm:**\n- Computationally expensive: O(N²log N) or O(N³)\n- Không scale với large datasets\n- Một khi merge không thể undo\n- Memory intensive\n\n**Khi Nào Dùng:**\n- Small-medium datasets (< 10,000)\n- Cần understand hierarchy\n- Không biết K optimal\n- Exploratory analysis\n\n### DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n\nNhóm các điểm có mật độ cao, robust to outliers và arbitrary shapes.\n\n**Tham Số:**\n\n**1. ε (epsilon):**\n- Maximum distance giữa 2 điểm để được coi là neighbors\n- Định nghĩa neighborhood radius\n- Quá nhỏ: Nhiều noise points\n- Quá lớn: Merge nhiều clusters\n\n**2. MinPts (Minimum Points):**\n- Minimum số điểm trong ε-neighborhood để là core point\n- Thường: 4, 5, hoặc 2×dim\n- Larger MinPts: Ít core points, stricter\n\n**Các Loại Điểm:**\n\n**1. Core Point:**\n- Có ≥ MinPts điểm khác trong ε-neighborhood (bao gồm cả chính nó)\n- Trung tâm của clusters\n- Can form clusters\n\n**2. Border Point:**\n- Nằm trong ε-neighborhood của core point\n- Có < MinPts neighbors\n- Thuộc cluster nhưng không core\n- Ở biên của cluster\n\n\n**Các khái niệm quan trọng:**\n- Học Máy là một lĩnh vực của trí tuệ nhân tạo cho phép hệ thống học từ dữ liệu, xác định các mẫu và đưa ra quyết định với sự can thiệp tối thiểu của con người, mà không cần được lập trình rõ ràng. Nó bao gồm nhiều phương pháp và thuật toán để xây dựng các mô hình dự đoán hoặc phân loại, với các nhánh như Học Không Giám Sát và Học Sâu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Phân Loại (Classification)\n- Ưu điểm: Mỗi mô hình đơn giản hơn, cân bằng hơn\n- Nhược điểm: Nhiều mô hình (phức tạp khi K lớn)\n\n**Ví dụ:** 3 lớp (A, B, C)\n- Mô hình 1: A vs B\n- Mô hình 2: A vs C\n- Mô hình 3: B vs C\n\n**3. Softmax Regression (Multinomial Logistic Regression):**\n\nMở rộng trực tiếp của logistic regression cho đa lớp.\n\n**Công thức:**\n$$P(y=k|x) = \frac{e^{z_k}}{\\sum_{j=1}^{K}e^{z_j}}$$\n\nTrong đó: $z_k = \beta_k^Tx$ với $\beta_k$ là vector hệ số cho lớp $k$\n\n**Đặc điểm:**\n- Tổng các xác suất = 1: $\\sum_{k=1}^{K}P(y=k|x) = 1$\n- Output là phân phối xác suất trên tất cả lớp\n- Huấn luyện đồng thời tất cả lớp\n\n**Hàm chi phí (Categorical Cross-Entropy):**\n$$J(\beta) = -\frac{1}{m}\\sum_{i=1}^{m}\\sum_{k=1}^{K}y_k^{(i)}\\log(P(y=k|x^{(i)}))$$\n\nTrong đó $y_k^{(i)}$ là one-hot encoding của nhãn.\n\n**Lựa chọn giữa OvR, OvO, và Softmax:**\n- **Softmax:** Tốt nhất khi cần xác suất, K không quá lớn\n- **OvR:** Đơn giản, hiệu quả với K lớn\n- **OvO:** Tốt với SVM, K nhỏ/trung bình\n\n### Naive Bayes Classifier (Bộ Phân Loại Naive Bayes)\n\nDựa trên định lý Bayes với giả định \"ngây thơ\" (naive) về tính độc lập đặc trưng.\n\n**Định Lý Bayes:**\n$$P(C_k|x) = \frac{P(x|C_k)P(C_k)}{P(x)}$$\n\nTrong đó:\n- $P(C_k|x)$: Xác suất hậu nghiệm (posterior) - xác suất lớp $C_k$ cho trước $x$\n- $P(x|C_k)$: Likelihood - xác suất của $x$ trong lớp $C_k$\n- $P(C_k)$: Xác suất tiên nghiệm (prior) của lớp $C_k$\n- $P(x)$: Evidence - xác suất của $x$\n\n**Giả Định Naive (Độc Lập Điều Kiện):**\n$$P(x_1, x_2, ..., x_n|C_k) = \\prod_{i=1}^{n}P(x_i|C_k)$$\n\nCác đặc trưng độc lập với nhau khi biết lớp.\n\n**Công Thức Đầy Đủ:**\n$$P(C_k|x_1,...,x_n) = \frac{P(C_k)\\prod_{i=1}^{n}P(x_i|C_k)}{P(x_1,...,x_n)}$$\n\n**Quyết Định:**\n$$\\hat{y} = \\arg\\max_{k} P(C_k)\\prod_{i=1}^{n}P(x_i|C_k)$$\n\nKhông cần tính $P(x)$ vì nó giống nhau cho tất cả lớp.\n\n**Các Biến Thể:**\n\n**1. Gaussian Naive Bayes:**\n- Cho đặc trưng liên tục\n- Giả định phân phối Gaussian (chuẩn)\n\n**Các khái niệm quan trọng:**\n- Phân loại là một tác vụ trong học máy nhằm gán một nhãn lớp cụ thể cho các mẫu dữ liệu đầu vào dựa trên các đặc trưng của chúng. Mục tiêu là xây dựng một mô hình, ví dụ như Cây Quyết Định, có khả năng dự đoán chính xác nhãn lớp của các mẫu mới, với kết quả dự đoán ở nút lá là một nhãn lớp cụ thể.\n- Naive Bayes Classifier là một bộ phân loại dựa trên Định lý Bayes với giả định \"ngây thơ\" (naive) về tính độc lập có điều kiện của các đặc trưng. Mô hình này tính toán xác suất hậu nghiệm của một lớp cho trước các đặc trưng đầu vào và chọn lớp có xác suất cao nhất. Naive Bayes đơn giản, hiệu quả và thường hoạt động tốt ngay cả với lượng dữ liệu nhỏ.\n\n**Mối quan hệ:**\n- Softmax Regression là một mô hình được thiết kế để giải quyết các bài toán Phân loại đa lớp, cung cấp xác suất cho mỗi lớp.\n- Naive Bayes Classifier là một mô hình được sử dụng để giải quyết các bài toán Phân loại, đặc biệt hiệu quả với giả định độc lập đặc trưng.\n- Cây Quyết Định là một thuật toán học có giám sát có thể thực hiện tác vụ Phân loại, gán nhãn lớp cho dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n\n### Giới Thiệu Về Cây Quyết Định\n\nCây quyết định là thuật toán học có giám sát đa năng có thể thực hiện cả tác vụ phân loại và hồi quy. Chúng học các quy tắc quyết định từ các đặc trưng để dự đoán giá trị mục tiêu thông qua cấu trúc dạng cây.\n\n**Ứng dụng thực tế:**\n- Chẩn đoán y tế (chuỗi quyết định dựa trên triệu chứng)\n- Đánh giá rủi ro tín dụng\n- Dự đoán churn khách hàng\n- Phát hiện gian lận\n- Hệ thống chuyên gia\n- Phân loại email spam\n\n**Tại sao gọi là \"cây\":**\n- Cấu trúc phân cấp giống cây ngược\n- Gốc ở trên, lá ở dưới\n- Quyết định được đưa ra tại mỗi nút nội bộ\n- Kết quả cuối cùng ở nút lá\n\n### Cấu Trúc Cây\n\n**1. Nút Gốc (Root Node):**\n- Nút trên cùng đại diện cho toàn bộ tập dữ liệu\n- Chứa tất cả mẫu training\n- Điểm bắt đầu của quá trình quyết định\n- Có phân chia đầu tiên dựa trên đặc trưng quan trọng nhất\n\n**2. Nút Nội Bộ (Internal Nodes):**\n- Các nút quyết định dựa trên kiểm tra đặc trưng\n- Mỗi nút thực hiện một câu hỏi yes/no về đặc trưng\n- Ví dụ: \"Tuổi > 30?\", \"Thu nhập < 50,000?\"\n- Chia dữ liệu thành các tập con\n\n**3. Nhánh (Branches):**\n- Kết quả của các quyết định\n- Kết nối nút cha với nút con\n- Đại diện cho giá trị hoặc phạm vi giá trị của đặc trưng\n\n**4. Nút Lá (Leaf Nodes):**\n- Nút cuối cùng không có nhánh con\n- Chứa dự đoán cuối cùng\n- Phân loại: Nhãn lớp\n- Hồi quy: Giá trị số\n\n**Ví dụ minh họa - Quyết định mua nhà:**\n```\n                 [Thu nhập > 50K?]\n                /                 \\\n            YES                    NO\n           /                         \\\n   [Tuổi > 30?]                [Không mua]\n    /        \\\n  YES        NO\n  /            \\\n[Mua]      [Thuê]\n```\n\n### Xây Dựng Cây Quyết Định\n\n**Tiêu Chí Phân Chia (Splitting Criteria):**\n\nMục tiêu: Tìm phân chia tốt nhất làm tăng \"độ thuần khiết\" (purity) của các tập con.\n\n**Cho Phân Loại:**\n\n**1. Gini Impurity (Chỉ Số Gini):**\n$$Gini(t) = 1 - \\sum_{i=1}^{C}p_i^2$$\n\nTrong đó:\n- $p_i$ là tỷ lệ mẫu thuộc lớp $i$ tại nút $t$\n- $C$ là số lớp\n- Gini = 0: Nút hoàn toàn thuần khiết (tất cả mẫu cùng lớp)\n\n**Các khái niệm quan trọng:**\n- Phân loại là một tác vụ trong học máy nhằm gán một nhãn lớp cụ thể cho các mẫu dữ liệu đầu vào dựa trên các đặc trưng của chúng. Mục tiêu là xây dựng một mô hình, ví dụ như Cây Quyết Định, có khả năng dự đoán chính xác nhãn lớp của các mẫu mới, với kết quả dự đoán ở nút lá là một nhãn lớp cụ thể.\n\n**Mối quan hệ:**\n- Naive Bayes Classifier là một mô hình được sử dụng để giải quyết các bài toán Phân loại, đặc biệt hiệu quả với giả định độc lập đặc trưng.\n- Cây Quyết Định là một thuật toán học có giám sát có thể thực hiện tác vụ Phân loại, gán nhãn lớp cho dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n**Underfitting (High Bias):**\n- Training error cao\n- Validation error cao\n- Mô hình quá đơn giản\n- Giải pháp: Thêm đặc trưng, tăng độ phức tạp, giảm regularization\n\n**Overfitting (High Variance):**\n- Training error thấp\n- Validation error cao (chênh lệch lớn)\n- Mô hình quá phức tạp\n- Giải pháp: Thêm dữ liệu, regularization, giảm đặc trưng, early stopping\n\n**Good fit:**\n- Training error thấp\n- Validation error thấp\n- Chênh lệch nhỏ giữa hai errors\n\n\n---\n\n## Phân Loại (Classification)\n\n### Giới Thiệu Về Phân Loại\n\nPhân loại là một tác vụ học có giám sát trong đó mục tiêu là dự đoán nhãn lớp rời rạc. Khác với hồi quy dự đoán giá trị liên tục, phân loại gán các đầu vào vào các danh mục được định nghĩa trước.\n\n**Ứng dụng thực tế:**\n- Phát hiện thư rác (spam/không spam)\n- Chẩn đoán bệnh (bệnh/không bệnh)\n- Nhận dạng chữ viết tay\n- Phân tích cảm xúc (tích cực/tiêu cực/trung lập)\n- Phát hiện gian lận thẻ tín dụng\n- Nhận dạng khuôn mặt\n- Phân loại văn bản, hình ảnh\n\n### Các Loại Bài Toán Phân Loại\n\n**1. Phân Loại Nhị Phân (Binary Classification):**\n- Hai lớp duy nhất\n- Ví dụ: Email spam/không spam, Bệnh/khỏe mạnh\n- Mã hóa nhãn: 0 và 1, hoặc -1 và +1\n\n**2. Phân Loại Đa Lớp (Multiclass Classification):**\n- Nhiều hơn hai lớp\n- Mỗi mẫu thuộc đúng một lớp\n- Ví dụ: Nhận dạng chữ số (0-9), Phân loại loại hoa\n- Mã hóa nhãn: One-hot encoding\n\n**3. Phân Loại Đa Nhãn (Multilabel Classification):**\n- Mỗi mẫu có thể thuộc nhiều lớp\n- Ví dụ: Gắn thẻ bài viết (công nghệ, kinh tế, chính trị), Phân loại thể loại phim\n\n### Hồi Quy Logistic (Logistic Regression)\n\nMặc dù có tên là \"regression\", hồi quy logistic là thuật toán phân loại mô hình hóa xác suất của kết quả nhị phân.\n\n**Hàm Sigmoid (Logistic Function):**\n$$\\sigma(z) = \frac{1}{1 + e^{-z}}$$\n\nTrong đó: $z = \beta_0 + \beta_1x_1 + ... + \beta_nx_n = \beta^Tx$\n\n**Đặc điểm hàm Sigmoid:**\n- Miền giá trị: $(0, 1)$ - phù hợp để biểu diễn xác suất\n- $\\sigma(0) = 0.5$\n- $\\sigma(z) \to 1$ khi $z \to \\infty$\n- $\\sigma(z) \to 0$ khi $z \to -\\infty$\n- Đạo hàm: $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$\n\n**Diễn Giải:**\n\n**Các khái niệm quan trọng:**\n- Phân loại là một tác vụ học có giám sát trong đó mục tiêu là dự đoán nhãn lớp rời rạc. Khác với hồi quy dự đoán giá trị liên tục, phân loại gán các đầu vào vào các danh mục được định nghĩa trước. Các ứng dụng bao gồm phát hiện thư rác, chẩn đoán bệnh, nhận dạng chữ viết tay, phân tích cảm xúc, phát hiện gian lận thẻ tín dụng, nhận dạng khuôn mặt và phân loại văn bản, hình ảnh.\n\n**Mối quan hệ:**\n- Phân loại chứa bài toán Phân loại Nhị phân, nơi mục tiêu là dự đoán một trong hai lớp.\n- Phân loại chứa bài toán Phân loại Đa Lớp, nơi mục tiêu là dự đoán một trong nhiều lớp.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Phân Loại (Classification)\n$$P(x_i|C_k) = \frac{1}{\\sqrt{2\\pi\\sigma_k^2}}\\exp\\left(-\frac{(x_i-\\mu_k)^2}{2\\sigma_k^2}\right)$$\n- Ước lượng $\\mu_k$ (mean) và $\\sigma_k^2$ (variance) từ dữ liệu\n- Ứng dụng: Phân loại văn bản, nhận dạng mẫu\n\n**2. Multinomial Naive Bayes:**\n- Cho đếm rời rạc (word counts, frequencies)\n- Phân phối đa thức\n$$P(x_i|C_k) = \frac{N_{ki} + \\alpha}{N_k + \\alpha n}$$\n  - $N_{ki}$: Số lần đặc trưng $i$ xuất hiện trong lớp $k$\n  - $N_k$: Tổng số đếm trong lớp $k$\n  - $\\alpha$: Laplace smoothing (thường = 1)\n- Ứng dụng: Phân loại văn bản, phân tích cảm xúc, lọc spam\n\n**3. Bernoulli Naive Bayes:**\n- Cho đặc trưng nhị phân (có/không)\n- Phân phối Bernoulli\n$$P(x_i|C_k) = P(i|C_k)x_i + (1-P(i|C_k))(1-x_i)$$\n- Tính cả việc đặc trưng xuất hiện và không xuất hiện\n- Ứng dụng: Phân loại văn bản với binary features\n\n**Ưu Điểm:**\n- Nhanh, hiệu quả\n- Hoạt động tốt với dữ liệu nhỏ\n- Dễ triển khai và diễn giải\n- Hoạt động tốt với nhiều đặc trưng\n- Không nhạy cảm với đặc trưng không liên quan\n\n**Nhược Điểm:**\n- Giả định độc lập hiếm khi đúng trong thực tế\n- \"Zero frequency problem\" cần smoothing\n- Ước lượng xác suất có thể không chính xác\n- Không tốt khi đặc trưng tương quan\n\n**Laplace Smoothing:**\nXử lý vấn đề xác suất = 0:\n$$P(x_i|C_k) = \frac{count(x_i, C_k) + \\alpha}{count(C_k) + \\alpha \times |V|}$$\n\n### k-Nearest Neighbors (k-NN) - K Láng Giềng Gần Nhất\n\nPhương pháp non-parametric phân loại dựa trên đa số vote của k láng giềng gần nhất.\n\n**Thuật Toán:**\n1. Tính khoảng cách từ điểm cần phân loại đến tất cả điểm huấn luyện\n2. Chọn k điểm gần nhất\n3. Vote: Lớp xuất hiện nhiều nhất trong k láng giềng\n4. Gán nhãn lớp đó cho điểm mới\n\n**Các Độ Đo Khoảng Cách:**\n\n**1. Euclidean Distance (Khoảng cách Euclid):**\n$$d(x,y) = \\sqrt{\\sum_{i=1}^{n}(x_i-y_i)^2}$$\n- Phổ biến nhất\n- Khoảng cách đường thẳng\n- Nhạy cảm với scale của đặc trưng\n\n**2. Manhattan Distance (Khoảng cách Manhattan):**\n$$d(x,y) = \\sum_{i=1}^{n}|x_i-y_i|$$\n- Khoảng cách theo lưới đô thị\n- Ít nhạy cảm với outliers\n- Tốt cho dữ liệu high-dimensional\n\n\n**Các khái niệm quan trọng:**\n- Bernoulli Naive Bayes là một mô hình phân loại dựa trên định lý Bayes, được thiết kế cho các đặc trưng nhị phân (binary features), tức là các đặc trưng chỉ có thể có hai giá trị (ví dụ: có hoặc không xuất hiện). Nó sử dụng phân phối Bernoulli để mô hình hóa xác suất của các đặc trưng.\n\n**Mối quan hệ:**\n- Bernoulli Naive Bayes được ứng dụng trong phân loại văn bản khi các đặc trưng được biểu diễn dưới dạng nhị phân (ví dụ: từ có xuất hiện hay không)."
        },
        "output_without_context": {
            "question": "So sánh Hồi quy Logistic và Bộ phân loại Naïve Bayes, mô hình nào thường được ưa chuộng hơn trong các bài toán phân loại với dữ liệu không độc lập?",
            "answer": "Bộ phân loại Naïve Bayes"
        }
    },
    {
        "topic_description": "Chủ đề này kiểm tra sự hiểu biết của sinh viên về Gradient Descent, một thuật toán tối ưu hóa thiết yếu trong học máy. Học sinh sẽ được yêu cầu giải thích cách mà thuật toán hoạt động, động lực phía sau tối ưu hóa hàm lỗi, và ưu nhược điểm của nó so với Phương trình chuẩn được nêu tại tuần 1.",
        "output_with_context": {
            "question": "Trong thuật toán Gradient Descent, công thức cập nhật trọng số được biểu diễn như thế nào?",
            "answer": "w := w - \\alpha \\frac{\\partial L}{\\partial w}",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\nBackpropagation có thể được hiểu thông qua đồ thị tính toán (computational graph), trong đó:\n- Mỗi node là một operation\n- Edges mang giá trị và gradients\n- Forward pass tính giá trị, backward pass tính gradients\n\n**Vấn đề Vanishing/Exploding Gradients:**\n- **Vanishing:** Gradient giảm dần khi lan truyền về các lớp đầu → các lớp đầu học chậm\n  - Nguyên nhân: Hàm kích hoạt có đạo hàm nhỏ (sigmoid, tanh)\n  - Giải pháp: ReLU, batch normalization, residual connections\n- **Exploding:** Gradient tăng dần → weights cập nhật quá mạnh, không ổn định\n  - Giải pháp: Gradient clipping, proper weight initialization\n\n**Lưu ý về hiệu suất:**\n- Độ phức tạp tính toán của backpropagation tương đương forward pass\n- Matrix operations có thể vectorize → tính toán hiệu quả trên GPU\n- Cần lưu trữ activations từ forward pass → tốn memory\n\n### Thuật Toán Tối Ưu (Optimization Algorithms)\n\nCác thuật toán tối ưu quyết định cách cập nhật weights để minimize loss function.\n\n**1. Gradient Descent (Hạ Gradient):**\n$$w := w - \\alpha\frac{\\partial L}{\\partial w}$$\n\n**Đặc điểm:**\n- $\\alpha$ (learning rate): Hyperparameter quan trọng nhất\n- Cập nhật dựa trên toàn bộ training set (batch gradient descent)\n\n**Ưu điểm:**\n- Đơn giản, dễ hiểu\n- Hội tụ ổn định với learning rate phù hợp\n- Đảm bảo tìm được local minimum với hàm convex\n\n**Nhược điểm:**\n- Chậm với dữ liệu lớn (phải xử lý toàn bộ dataset mỗi iteration)\n- Có thể bị kẹt ở local minima hoặc saddle points\n- Learning rate cố định không phù hợp mọi giai đoạn training\n\n**2. Stochastic Gradient Descent (SGD):**\n$$w := w - \\alpha\frac{\\partial L_i}{\\partial w}$$\n\n**Đặc điểm:**\n- Cập nhật sau **mỗi** mẫu dữ liệu (sample)\n- Gradient ước lượng từ 1 sample → noisy nhưng nhanh\n\n**Ưu điểm:**\n- Rất nhanh, có thể train trên dữ liệu lớn\n- Noise giúp thoát khỏi local minima\n- Có thể train online (dữ liệu đến liên tục)\n\n**Nhược điểm:**\n- Quá trình hội tụ không ổn định, dao động mạnh\n- Có thể không hội tụ chính xác đến minimum\n- Khó song song hóa (sequential updates)\n\n**3. Mini-batch Gradient Descent:**\n$$w := w - \\alpha\frac{1}{m}\\sum_{i=1}^{m}\frac{\\partial L_i}{\\partial w}$$\n\n**Đặc điểm:**\n- Cập nhật sau một **batch nhỏ** (thường 32, 64, 128, 256)\n- Kết hợp ưu điểm của batch GD và SGD\n- **Là phương pháp được sử dụng phổ biến nhất trong thực tế**\n\n**Ưu điểm:**\n- Tốc độ nhanh, ổn định hơn SGD\n- Có thể vectorize, tận dụng GPU hiệu quả\n- Gradient ổn định hơn SGD nhưng vẫn có noise tốt\n- Batch size là hyperparameter điều chỉnh được\n\n**Lựa chọn batch size:**\n\n**Các khái niệm quan trọng:**\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n- Gradient Descent là một thuật toán tối ưu được sử dụng để huấn luyện Generator. Generator cập nhật tham số θ_G bằng cách giảm gradient của hàm mục tiêu của nó: θ_G ← θ_G - η∇θ_G V(D,G). Cụ thể, Generator cố gắng giảm log xác suất mà dữ liệu giả của nó bị Discriminator từ chối, hoặc tương đương, tăng log xác suất mà dữ liệu giả của nó được Discriminator chấp nhận (non-saturating loss).\n- Gradient Descent là một kỹ thuật tối ưu hóa tổng quát được sử dụng để tìm cực tiểu của một hàm bằng cách di chuyển lặp đi lặp lại theo hướng ngược lại với gradient của hàm đó. Trong Value Function Approximation, công thức cập nhật tham số w là w_{t+1} = w_t - (α/2)∇_w J(w_t) = w_t + α E[(V^π(s) - V̂(s; w))∇_w V̂(s; w)].\n\n**Mối quan hệ:**\n- Gradient Descent là một thuật toán tối ưu được sử dụng để minimize loss function bằng cách di chuyển theo hướng ngược lại của gradient.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\nBackpropagation là thuật toán cốt lõi để huấn luyện mạng nơ-ron sâu, cho phép tính gradient một cách hiệu quả thông qua quy tắc chuỗi (chain rule).\n\n**Ý tưởng cơ bản:**\n- Tính toán gradient của loss function theo tất cả các tham số (weights và biases)\n- Lan truyền gradient từ output về input qua các lớp\n- Sử dụng quy tắc chuỗi để phân rã gradient phức tạp thành các phần đơn giản\n\n**Quy tắc chuỗi (Chain Rule):**\n$$\frac{\\partial L}{\\partial w^{[l]}} = \frac{\\partial L}{\\partial a^{[l]}} \\cdot \frac{\\partial a^{[l]}}{\\partial z^{[l]}} \\cdot \frac{\\partial z^{[l]}}{\\partial w^{[l]}}$$\n\nTrong đó:\n- $\frac{\\partial L}{\\partial a^{[l]}}$: Gradient của loss theo activation\n- $\frac{\\partial a^{[l]}}{\\partial z^{[l]}}$: Đạo hàm của hàm kích hoạt\n- $\frac{\\partial z^{[l]}}{\\partial w^{[l]}}$: Gradient của pre-activation theo weights\n\n**Các bước chi tiết:**\n\n**1. Forward Pass (Lan truyền xuôi):**\n- Tính toán output của mỗi lớp từ input đến output\n- Lưu trữ tất cả các giá trị $z^{[l]}$ và $a^{[l]}$ (cần cho backward pass)\n\n**2. Tính Loss:**\n- So sánh prediction với ground truth\n- Tính giá trị loss: $L = Loss(y, \\hat{y})$\n\n**3. Backward Pass (Lan truyền ngược):**\n- Bắt đầu từ lớp output, tính gradient của loss theo output\n- Với mỗi lớp từ L về 1:\n  - Tính $\frac{\\partial L}{\\partial z^{[l]}} = \frac{\\partial L}{\\partial a^{[l]}} \\odot \\sigma'(z^{[l]})$ (element-wise product)\n  - Tính $\frac{\\partial L}{\\partial W^{[l]}} = \frac{\\partial L}{\\partial z^{[l]}} \\cdot (a^{[l-1]})^T$\n  - Tính $\frac{\\partial L}{\\partial b^{[l]}} = \frac{\\partial L}{\\partial z^{[l]}}$\n  - Lan truyền về lớp trước: $\frac{\\partial L}{\\partial a^{[l-1]}} = (W^{[l]})^T \\cdot \frac{\\partial L}{\\partial z^{[l]}}$\n\n**4. Cập nhật Weights:**\n- Sử dụng gradient descent hoặc các optimizer khác\n- $W^{[l]} := W^{[l]} - \\alpha \frac{\\partial L}{\\partial W^{[l]}}$\n- $b^{[l]} := b^{[l]} - \\alpha \frac{\\partial L}{\\partial b^{[l]}}$\n\n**Ví dụ minh họa:**\nMạng 2 lớp: Input → Hidden → Output\n- Forward: $a^{[1]} = \\sigma(W^{[1]}x + b^{[1]})$, $\\hat{y} = \\sigma(W^{[2]}a^{[1]} + b^{[2]})$\n- Loss: $L = (y - \\hat{y})^2$\n- Backward:\n  - $\frac{\\partial L}{\\partial \\hat{y}} = -2(y - \\hat{y})$\n  - $\frac{\\partial L}{\\partial W^{[2]}} = \frac{\\partial L}{\\partial \\hat{y}} \\cdot \\sigma'(z^{[2]}) \\cdot a^{[1]}$\n  - Lan truyền về hidden layer tương tự\n\n**Computational Graph:**\n\n**Các khái niệm quan trọng:**\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n- Gradient Descent là một thuật toán tối ưu được sử dụng để huấn luyện Generator. Generator cập nhật tham số θ_G bằng cách giảm gradient của hàm mục tiêu của nó: θ_G ← θ_G - η∇θ_G V(D,G). Cụ thể, Generator cố gắng giảm log xác suất mà dữ liệu giả của nó bị Discriminator từ chối, hoặc tương đương, tăng log xác suất mà dữ liệu giả của nó được Discriminator chấp nhận (non-saturating loss).\n- Gradient Descent là một kỹ thuật tối ưu hóa tổng quát được sử dụng để tìm cực tiểu của một hàm bằng cách di chuyển lặp đi lặp lại theo hướng ngược lại với gradient của hàm đó. Trong Value Function Approximation, công thức cập nhật tham số w là w_{t+1} = w_t - (α/2)∇_w J(w_t) = w_t + α E[(V^π(s) - V̂(s; w))∇_w V̂(s; w)].\n\n**Mối quan hệ:**\n- Gradient Descent là một thuật toán tối ưu được sử dụng để minimize loss function bằng cách di chuyển theo hướng ngược lại của gradient.\n- Gradient Descent là một optimizer được sử dụng để cực tiểu hóa loss function bằng cách điều chỉnh tham số theo hướng gradient âm.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n- Giải pháp nếu vi phạm: Biến đổi đặc trưng (log, căn bậc hai, đa thức)\n\n**2. Tính Độc Lập (Independence):**\n- Các quan sát độc lập với nhau\n- Quan trọng với dữ liệu chuỗi thời gian\n- Vi phạm: Tự tương quan (autocorrelation)\n- Kiểm tra: Durbin-Watson test\n\n**3. Phương Sai Đồng Nhất (Homoscedasticity):**\n- Phương sai của phần dư không đổi theo giá trị dự đoán\n- Kiểm tra: Vẽ biểu đồ phần dư vs giá trị dự đoán\n- Nếu vi phạm (heteroscedasticity): Sử dụng weighted least squares hoặc biến đổi log\n\n**4. Tính Chuẩn (Normality):**\n- Phần dư tuân theo phân phối chuẩn\n- Kiểm tra: Q-Q plot, Shapiro-Wilk test\n- Quan trọng cho suy diễn thống kê (khoảng tin cậy, kiểm định giả thuyết)\n\n**5. Không Có Đa Cộng Tuyến (No Multicollinearity):**\n- Các đặc trưng không tương quan cao với nhau\n- Kiểm tra: VIF (Variance Inflation Factor)\n- VIF > 10 cho thấy đa cộng tuyến nghiêm trọng\n- Giải pháp: Loại bỏ đặc trưng tương quan cao, PCA, regularization\n\n**Công Thức VIF:**\n$$VIF_j = \frac{1}{1 - R_j^2}$$\nTrong đó $R_j^2$ là $R^2$ khi hồi quy $x_j$ với các đặc trưng còn lại.\n\n### Tối Ưu Hóa Bằng Gradient Descent\n\nGradient Descent là phương pháp lặp để tìm hệ số tối ưu, đặc biệt hữu ích với dữ liệu lớn.\n\n**Thuật Toán:**\n$$\beta_j := \beta_j - \\alpha\frac{\\partial J(\beta)}{\\partial\beta_j}$$\n\nTrong đó:\n- $\\alpha$ là tốc độ học (learning rate)\n- $\frac{\\partial J(\beta)}{\\partial\beta_j}$ là đạo hàm riêng của hàm chi phí\n\n**Đạo Hàm Riêng:**\n$$\frac{\\partial J(\beta)}{\\partial\beta_j} = \frac{1}{m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n\n**Các Loại Gradient Descent:**\n\n**1. Batch Gradient Descent:**\n- Sử dụng toàn bộ tập dữ liệu trong mỗi lần cập nhật\n- Ưu điểm: Hội tụ ổn định, tối ưu toàn cục\n- Nhược điểm: Chậm với dữ liệu lớn\n- Công thức cập nhật: $\beta := \beta - \\alpha\nabla J(\beta)$\n\n**2. Stochastic Gradient Descent (SGD):**\n- Sử dụng từng mẫu một để cập nhật\n- Ưu điểm: Nhanh, có thể thoát khỏi cực tiểu địa phương\n- Nhược điểm: Dao động nhiều, không hội tụ chính xác\n- Phù hợp: Dữ liệu rất lớn, học trực tuyến\n\n**3. Mini-batch Gradient Descent:**\n- Sử dụng các batch nhỏ (thường 32-256 mẫu)\n\n**Các khái niệm quan trọng:**\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n- Gradient Descent là một thuật toán tối ưu được sử dụng để huấn luyện Generator. Generator cập nhật tham số θ_G bằng cách giảm gradient của hàm mục tiêu của nó: θ_G ← θ_G - η∇θ_G V(D,G). Cụ thể, Generator cố gắng giảm log xác suất mà dữ liệu giả của nó bị Discriminator từ chối, hoặc tương đương, tăng log xác suất mà dữ liệu giả của nó được Discriminator chấp nhận (non-saturating loss).\n- Gradient Descent là một kỹ thuật tối ưu hóa tổng quát được sử dụng để tìm cực tiểu của một hàm bằng cách di chuyển lặp đi lặp lại theo hướng ngược lại với gradient của hàm đó. Trong Value Function Approximation, công thức cập nhật tham số w là w_{t+1} = w_t - (α/2)∇_w J(w_t) = w_t + α E[(V^π(s) - V̂(s; w))∇_w V̂(s; w)].\n\n**Mối quan hệ:**\n- Gradient Descent là một thuật toán tối ưu được sử dụng để minimize loss function bằng cách di chuyển theo hướng ngược lại của gradient."
        },
        "output_without_context": {
            "question": "Trong thuật toán Gradient Descent, biến nào được điều chỉnh để tối ưu hóa hàm lỗi?",
            "answer": "Tốc độ học (learning rate)"
        }
    },
    {
        "topic_description": "Chủ đề này sẽ mở rộng vào các khái niệm SVM từ bài giảng trước, yêu cầu học sinh thảo luận về cách thức hoạt động của Hard Margin và Soft Margin SVM. Học sinh sẽ cần nhận diện ứng dụng của SVM trong các bài toán không tuyến tính và ưu điểm của nó so với các mô hình phân loại khác mà đã học trước đó.",
        "output_with_context": {
            "question": "Trong Hard Margin SVM, điều gì xảy ra với margin khi dữ liệu có outliers?",
            "answer": "Margin sẽ bị giảm và mô hình có thể không phân loại chính xác các điểm dữ liệu.",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Máy Vector Hỗ Trợ (Support Vector Machine - SVM)\n### Hard Margin SVM\n\nDành cho dữ liệu **linearly separable** (phân tách tuyến tính hoàn toàn).\n\n**Bài toán tối ưu:**\n$$\\min_{w,b} \frac{1}{2}||w||^2$$\n\n**Ràng buộc:** $y_i(w^Tx_i + b) \\geq 1, \forall i$\n\n**Giải thích:**\n- Mục tiêu: Tối thiểu hóa $||w||^2$ (tương đương tối đa hóa margin $\frac{2}{||w||}$)\n- Ràng buộc: Tất cả điểm phải được phân loại đúng\n- $y_i \\in \\{-1, +1\\}$: Nhãn lớp\n- $y_i(w^Tx_i + b) \\geq 1$: Điểm nằm đúng phía và cách siêu phẳng ít nhất 1 đơn vị\n\n**Tại sao dùng $\frac{1}{2}||w||^2$:**\n- Đạo hàm đẹp hơn (mất $\frac{1}{2}$ khi lấy đạo hàm)\n- Bài toán convex quadratic programming\n- Dễ giải với Lagrange multipliers\n\n**Hạn chế:**\n- Yêu cầu dữ liệu phân tách tuyến tính hoàn toàn\n- Không tolerant với outliers\n- Hiếm khi áp dụng trong thực tế (dữ liệu thường có noise)\n\n### Soft Margin SVM\n\nDành cho dữ liệu **không phân tách tuyến tính hoàn toàn** (có overlap).\n\n**Giới thiệu Slack Variables $\\xi_i$:**\n- Cho phép một số điểm vi phạm margin\n- $\\xi_i$ đo lường mức độ vi phạm của điểm $i$\n- $\\xi_i = 0$: Điểm được phân loại đúng, nằm ngoài margin\n- $0 < \\xi_i < 1$: Điểm nằm trong margin nhưng phân loại đúng\n- $\\xi_i \\geq 1$: Điểm bị misclassified\n\n**Bài toán tối ưu:**\n$$\\min_{w,b,\\xi} \frac{1}{2}||w||^2 + C\\sum_{i=1}^{m}\\xi_i$$\n\n**Ràng buộc:**\n- $y_i(w^Tx_i + b) \\geq 1 - \\xi_i$\n- $\\xi_i \\geq 0, \forall i$\n\n**Tham số C (Regularization Parameter):**\n\nC điều khiển trade-off giữa margin rộng và số lượng vi phạm.\n\n**C lớn (C → ∞):**\n- Penalty cao cho vi phạm\n- Margin nhỏ hơn\n- Ít misclassifications\n- Low bias, high variance (overfitting)\n- Gần với hard margin SVM\n\n**C nhỏ:**\n- Penalty thấp cho vi phạm\n- Margin lớn hơn\n- Nhiều misclassifications hơn\n- High bias, low variance (underfitting)\n- Mô hình đơn giản hơn\n\n**Lựa chọn C:**\n- Cross-validation\n- Thường thử: 0.01, 0.1, 1, 10, 100\n- Phụ thuộc vào scale của dữ liệu\n\n**Diễn giải hàm mục tiêu:**\n- $\frac{1}{2}||w||^2$: Tối đa hóa margin\n- $C\\sum_{i=1}^{m}\\xi_i$: Tối thiểu hóa vi phạm\n- C cân bằng hai mục tiêu này\n\n### Kernel Trick (Mẹo Kernel)\n\nÁnh xạ dữ liệu sang không gian nhiều chiều hơn nơi nó trở nên phân tách tuyến tính.\n\n**Vấn đề:**\n\n**Các khái niệm quan trọng:**\n- Outliers (dữ liệu ngoại lai) là các điểm dữ liệu nằm xa bất thường so với phần lớn các điểm dữ liệu khác. Hard Margin SVM rất nhạy cảm với outliers vì chúng có thể ảnh hưởng đáng kể đến vị trí của siêu phẳng phân tách, làm giảm khả năng tổng quát hóa của mô hình. Soft Margin SVM được thiết kế để tolerant hơn với outliers.\n- Support Vector Machine (SVM) là một mô hình phân loại mạnh mẽ, đặc biệt hiệu quả với dữ liệu có chiều cao và kích thước mẫu nhỏ. SVM hoạt động bằng cách tìm một siêu phẳng tối ưu để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng và các điểm dữ liệu gần nhất (support vectors). Mô hình này không cung cấp xác suất trực tiếp mà thay vào đó là một hàm quyết định dựa trên khoảng cách. SVM gặp khó khăn trong việc xử lý các tập dữ liệu lớn và không cung cấp thông tin về tầm quan trọng của các đặc trưng một cách trực tiếp. Nó yêu cầu feature scaling và có thể được điều chỉnh cho các vấn đề mất cân bằng lớp. Các ứng dụng của SVM bao gồm phân loại văn bản, nhận dạng hình ảnh và tin sinh học.\n- Support Vector Machine (SVM) là một thuật toán học có giám sát mạnh mẽ, được sử dụng rộng rãi cho cả bài toán phân loại và hồi quy (SVR). Mục tiêu chính của SVM là tìm một siêu phẳng tối ưu trong không gian nhiều chiều để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng này và các điểm dữ liệu gần nhất (được gọi là support vectors). SVM có khả năng xử lý hiệu quả dữ liệu trong không gian chiều cao, ngay cả khi số lượng chiều lớn hơn số lượng mẫu.\n\nĐể xử lý các bài toán không phân tách tuyến tính trong không gian gốc, SVM sử dụng Kernel Trick để ánh xạ dữ liệu sang một không gian đặc trưng có chiều cao hơn, nơi dữ liệu có thể phân tách tuyến tính. Điều này cho phép SVM hoạt động như một mô hình phi tuyến trong không gian gốc thông qua các hàm kernel linh hoạt. SVM có hai dạng chính là Hard Margin SVM (khi dữ liệu phân tách hoàn toàn) và Soft Margin SVM (khi có thể chấp nhận một số lỗi phân loại để đạt được biên độ lớn hơn), đồng thời tích hợp cơ chế regularization thông qua tham số C để kiểm soát overfitting.\n\nMô hình này được tối ưu hóa thông qua bài toán đối ngẫu để tìm các Lagrange multipliers, từ đó xác định các support vectors quan trọng. Hàm mục tiêu của SVM là một bài toán tối ưu lồi, đảm bảo tìm được cực tiểu toàn cục.\n\nCác ứng dụng của SVM rất đa dạng, bao gồm phân loại văn bản, nhận dạng chữ viết tay, nhận dạng khuôn mặt, phân loại hình ảnh, phân tích sinh học, xác minh chữ ký và dự đoán chuỗi thời gian.\n- Đây là ràng buộc của Hard Margin SVM, đảm bảo rằng tất cả các điểm dữ liệu $x_i$ được phân loại đúng và nằm cách siêu phẳng $w^Tx + b = 0$ ít nhất 1 đơn vị. $y_i \\in \\{-1, +1\\}$ là nhãn lớp của điểm $x_i$. Nếu $y_i=1$, thì $w^Tx_i + b \\geq 1$; nếu $y_i=-1$, thì $w^Tx_i + b \\leq -1$.\n\n**Mối quan hệ:**\n- Support Vector Machine giải quyết non-linear relationships thông qua việc sử dụng kernel functions.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Máy Vector Hỗ Trợ (Support Vector Machine - SVM)\n- Kiểm soát trade-off giữa margin và errors\n- Range: 0.01 đến 1000\n- Grid search: [0.01, 0.1, 1, 10, 100]\n\n**2. Kernel type:**\n- Lựa chọn hàm kernel\n- Try: 'linear', 'rbf', 'poly'\n- Default: 'rbf'\n\n**3. Gamma (γ) - cho RBF kernel:**\n- Định nghĩa bán kính ảnh hưởng\n- Range: 0.0001 đến 1\n- Grid search: [0.001, 0.01, 0.1, 1]\n- 'scale': $\frac{1}{n \times var(X)}$\n\n**4. Degree (d) - cho Polynomial kernel:**\n- Bậc của polynomial\n- Thường: 2, 3, 4\n- Tránh quá cao (overfitting, computational cost)\n\n**5. Epsilon (ε) - cho SVR:**\n- Độ rộng tube\n- Range: 0.01 đến 1\n- Phụ thuộc scale của target\n\n**Chiến lược Tuning:**\n\n**1. Coarse Grid Search:**\n- Tìm vùng tốt với grid thô\n- C: [0.1, 1, 10, 100]\n- gamma: [0.001, 0.01, 0.1, 1]\n\n**2. Fine Grid Search:**\n- Zoom vào vùng tốt\n- Grid mịn hơn\n\n**3. Randomized Search:**\n- Nhanh hơn grid search\n- Sample ngẫu nhiên từ distributions\n\n**4. Bayesian Optimization:**\n- Thông minh, adaptive\n- Ít iterations hơn\n\n**Tips:**\n- Luôn feature scaling trước\n- Cross-validation (5-fold hoặc 10-fold)\n- Monitor training time\n- Tune C và gamma cùng lúc (interdependent)\n\n### Ưu Điểm Của SVM\n\n**1. Hiệu quả trong không gian nhiều chiều:**\n- Hoạt động tốt khi $n_{features} > n_{samples}$\n- Phù hợp cho text, genomics, high-dimensional data\n\n**2. Tiết kiệm bộ nhớ:**\n- Chỉ lưu support vectors\n- Không cần lưu toàn bộ training data\n- Sparse representation\n\n**3. Linh hoạt với kernel functions:**\n- Nhiều kernel có sẵn\n- Có thể define custom kernel\n- Xử lý được non-linear relationships\n\n**4. Hoạt động tốt với margin rõ ràng:**\n- Khi các lớp separated tốt\n- Decision boundary rõ ràng\n\n**5. Robust to outliers (soft margin):**\n- Slack variables cho phép một số outliers\n- Không bị ảnh hưởng nhiều bởi outliers xa\n\n**6. Cơ sở toán học vững chắc:**\n- Convex optimization problem\n- Global optimum guaranteed\n- Không bị stuck ở local minima\n\n**7. Regularization tích hợp:**\n- Tham số C control overfitting\n- Không cần regularization bên ngoài\n\n### Nhược Điểm\n\n**1. Chi phí tính toán cao cho dữ liệu lớn:**\n- Training complexity: O($n^2$) đến O($n^3$)\n- Không scale tốt với >10,000 mẫu\n- Memory intensive\n\n**2. Nhạy cảm với feature scaling:**\n- **Bắt buộc** phải scaling/normalization\n- Đặc trưng có scale lớn sẽ dominate\n- Ảnh hưởng đến kernel calculations\n\n**3. Khó diễn giải (với kernels):**\n- Đặc biệt với RBF kernel\n- Không thấy được feature importance trực tiếp\n- Black box (so với linear models, trees)\n\n\n**Các khái niệm quan trọng:**\n- Support Vector Machine (SVM) là một thuật toán học có giám sát mạnh mẽ, được sử dụng rộng rãi cho cả bài toán phân loại và hồi quy (SVR). Mục tiêu chính của SVM là tìm một siêu phẳng tối ưu trong không gian nhiều chiều để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng này và các điểm dữ liệu gần nhất (được gọi là support vectors). SVM có khả năng xử lý hiệu quả dữ liệu trong không gian chiều cao, ngay cả khi số lượng chiều lớn hơn số lượng mẫu.\n\nĐể xử lý các bài toán không phân tách tuyến tính trong không gian gốc, SVM sử dụng Kernel Trick để ánh xạ dữ liệu sang một không gian đặc trưng có chiều cao hơn, nơi dữ liệu có thể phân tách tuyến tính. Điều này cho phép SVM hoạt động như một mô hình phi tuyến trong không gian gốc thông qua các hàm kernel linh hoạt. SVM có hai dạng chính là Hard Margin SVM (khi dữ liệu phân tách hoàn toàn) và Soft Margin SVM (khi có thể chấp nhận một số lỗi phân loại để đạt được biên độ lớn hơn), đồng thời tích hợp cơ chế regularization thông qua tham số C để kiểm soát overfitting.\n\nMô hình này được tối ưu hóa thông qua bài toán đối ngẫu để tìm các Lagrange multipliers, từ đó xác định các support vectors quan trọng. Hàm mục tiêu của SVM là một bài toán tối ưu lồi, đảm bảo tìm được cực tiểu toàn cục.\n\nCác ứng dụng của SVM rất đa dạng, bao gồm phân loại văn bản, nhận dạng chữ viết tay, nhận dạng khuôn mặt, phân loại hình ảnh, phân tích sinh học, xác minh chữ ký và dự đoán chuỗi thời gian.\n- Non-linear relationships là các mối quan hệ giữa các đặc trưng và biến mục tiêu không thể được biểu diễn bằng một đường thẳng hoặc siêu phẳng. SVM có khả năng xử lý các mối quan hệ phi tuyến tính này một cách hiệu quả thông qua việc sử dụng các hàm kernel, ánh xạ dữ liệu vào một không gian đặc trưng có chiều cao hơn nơi chúng có thể được phân tách tuyến tính.\n\n**Mối quan hệ:**\n- Support Vector Machine giải quyết non-linear relationships thông qua việc sử dụng kernel functions.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Cây Quyết Định (Decision Tree)\n- Content filtering\n\n---\n\n## Máy Vector Hỗ Trợ (Support Vector Machine - SVM)\n\n### Giới Thiệu Về SVM\n\nSupport Vector Machine (SVM) là thuật toán học có giám sát mạnh mẽ cho phân loại và hồi quy. Chúng hoạt động bằng cách tìm siêu phẳng (hyperplane) tối ưu phân tách tối đa các lớp trong không gian nhiều chiều.\n\n**Ý tưởng cốt lõi:**\n- Tìm ranh giới quyết định tốt nhất giữa các lớp\n- Tối đa hóa khoảng cách (margin) giữa các lớp\n- Chỉ dựa vào các điểm dữ liệu quan trọng nhất (support vectors)\n\n**Ứng dụng:**\n- Phân loại văn bản (spam detection, sentiment analysis)\n- Nhận dạng chữ viết tay\n- Nhận dạng khuôn mặt\n- Phân loại hình ảnh\n- Phân tích sinh học (protein classification)\n- Dự đoán chuỗi thời gian\n\n**Ưu điểm chính:**\n- Hiệu quả trong không gian nhiều chiều\n- Hoạt động tốt khi có ranh giới rõ ràng\n- Tiết kiệm bộ nhớ (chỉ lưu support vectors)\n- Linh hoạt với nhiều kernel functions\n\n### SVM Tuyến Tính (Linear SVM)\n\n**Mục tiêu:** Tìm siêu phẳng có margin tối đa giữa các lớp.\n\n**Siêu Phẳng (Hyperplane):**\n\nTrong không gian n chiều, siêu phẳng là không gian con (n-1) chiều chia không gian thành hai nửa.\n\n**Phương trình siêu phẳng:**\n$$w^Tx + b = 0$$\n\nTrong đó:\n- $w$ là vector trọng số (weights) - vector pháp tuyến của siêu phẳng\n- $x$ là vector đặc trưng\n- $b$ là bias (hệ số chặn)\n\n**Ví dụ:**\n- 2D: $w_1x_1 + w_2x_2 + b = 0$ (đường thẳng)\n- 3D: $w_1x_1 + w_2x_2 + w_3x_3 + b = 0$ (mặt phẳng)\n\n**Hàm Quyết Định:**\n$$f(x) = sign(w^Tx + b)$$\n\n- Nếu $w^Tx + b > 0$: Dự đoán lớp +1\n- Nếu $w^Tx + b < 0$: Dự đoán lớp -1\n- Nếu $w^Tx + b = 0$: Điểm nằm trên siêu phẳng\n\n**Margin (Lề):**\n\nMargin là khoảng cách từ siêu phẳng đến điểm dữ liệu gần nhất.\n\n**Công thức:**\n$$margin = \frac{2}{||w||}$$\n\n**Giải thích:**\n- Khoảng cách từ điểm $x_i$ đến siêu phẳng: $\frac{|w^Tx_i + b|}{||w||}$\n- Điểm support vector thỏa: $|w^Tx_i + b| = 1$\n- Margin = khoảng cách từ support vector này đến support vector bên kia = $\frac{2}{||w||}$\n\n**Tối đa hóa margin:**\n- Margin lớn → Generalization tốt hơn\n- Mô hình ổn định hơn với noise\n- Tăng khả năng phân loại đúng trên dữ liệu mới\n\n\n**Các khái niệm quan trọng:**\n- Support Vector Machine (SVM) là một thuật toán học có giám sát mạnh mẽ, được sử dụng rộng rãi cho cả bài toán phân loại và hồi quy (SVR). Mục tiêu chính của SVM là tìm một siêu phẳng tối ưu trong không gian nhiều chiều để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng này và các điểm dữ liệu gần nhất (được gọi là support vectors). SVM có khả năng xử lý hiệu quả dữ liệu trong không gian chiều cao, ngay cả khi số lượng chiều lớn hơn số lượng mẫu.\n\nĐể xử lý các bài toán không phân tách tuyến tính trong không gian gốc, SVM sử dụng Kernel Trick để ánh xạ dữ liệu sang một không gian đặc trưng có chiều cao hơn, nơi dữ liệu có thể phân tách tuyến tính. Điều này cho phép SVM hoạt động như một mô hình phi tuyến trong không gian gốc thông qua các hàm kernel linh hoạt. SVM có hai dạng chính là Hard Margin SVM (khi dữ liệu phân tách hoàn toàn) và Soft Margin SVM (khi có thể chấp nhận một số lỗi phân loại để đạt được biên độ lớn hơn), đồng thời tích hợp cơ chế regularization thông qua tham số C để kiểm soát overfitting.\n\nMô hình này được tối ưu hóa thông qua bài toán đối ngẫu để tìm các Lagrange multipliers, từ đó xác định các support vectors quan trọng. Hàm mục tiêu của SVM là một bài toán tối ưu lồi, đảm bảo tìm được cực tiểu toàn cục.\n\nCác ứng dụng của SVM rất đa dạng, bao gồm phân loại văn bản, nhận dạng chữ viết tay, nhận dạng khuôn mặt, phân loại hình ảnh, phân tích sinh học, xác minh chữ ký và dự đoán chuỗi thời gian.\n- Support Vector Machine (SVM) là một mô hình phân loại mạnh mẽ, đặc biệt hiệu quả với dữ liệu có chiều cao và kích thước mẫu nhỏ. SVM hoạt động bằng cách tìm một siêu phẳng tối ưu để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng và các điểm dữ liệu gần nhất (support vectors). Mô hình này không cung cấp xác suất trực tiếp mà thay vào đó là một hàm quyết định dựa trên khoảng cách. SVM gặp khó khăn trong việc xử lý các tập dữ liệu lớn và không cung cấp thông tin về tầm quan trọng của các đặc trưng một cách trực tiếp. Nó yêu cầu feature scaling và có thể được điều chỉnh cho các vấn đề mất cân bằng lớp. Các ứng dụng của SVM bao gồm phân loại văn bản, nhận dạng hình ảnh và tin sinh học.\n\n**Mối quan hệ:**\n- Support Vector Machine giải quyết non-linear relationships thông qua việc sử dụng kernel functions.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Máy Vector Hỗ Trợ (Support Vector Machine - SVM)\n- Biên giới giữa các lớp\n\n### SVM Đa Lớp (Multi-class SVM)\n\nSVM ban đầu cho binary classification. Mở rộng cho multi-class:\n\n**1. One-vs-One (OvO):**\n- Huấn luyện $\frac{K(K-1)}{2}$ bộ phân loại nhị phân\n- Mỗi cặp lớp có một SVM\n- Dự đoán: Voting - lớp thắng nhiều nhất\n\n**Ưu điểm:**\n- Mỗi SVM đơn giản hơn (chỉ 2 lớp)\n- Training nhanh cho mỗi SVM\n- Tốt cho SVM với kernel\n\n**Nhược điểm:**\n- Nhiều mô hình khi K lớn\n- Voting có thể tie\n\n**2. One-vs-Rest (OvR / One-vs-All):**\n- Huấn luyện K bộ phân loại nhị phân\n- Mỗi SVM: Một lớp vs tất cả lớp khác\n- Dự đoán: Lớp có decision function score cao nhất\n\n**Ưu điểm:**\n- Ít mô hình hơn (K so với $\frac{K(K-1)}{2}$)\n- Đơn giản\n\n**Nhược điểm:**\n- Imbalanced training sets\n- Scores không comparable trực tiếp\n\n**3. Crammer & Singer:**\n- Giải trực tiếp multi-class SVM\n- Một bài toán tối ưu duy nhất\n- Phức tạp tính toán\n\n**Sklearn default:** OvR cho hầu hết, OvO cho `SVC`\n\n### SVM cho Hồi Quy (SVR - Support Vector Regression)\n\nThay vì tối đa hóa margin, SVR tìm một \"ống\" (tube) có độ rộng $\\epsilon$ chứa hầu hết các điểm dữ liệu.\n\n**Ý tưởng:**\n- Cho phép sai số trong khoảng $\\epsilon$\n- Penalty cho điểm ngoài ống\n- Cân bằng giữa flatness và tolerance\n\n**Bài toán tối ưu:**\n$$\\min_{w,b} \frac{1}{2}||w||^2 + C\\sum_{i=1}^{m}(\\xi_i + \\xi_i^*)$$\n\n**Ràng buộc:**\n- $y_i - (w^Tx_i + b) \\leq \\epsilon + \\xi_i$\n- $(w^Tx_i + b) - y_i \\leq \\epsilon + \\xi_i^*$\n- $\\xi_i, \\xi_i^* \\geq 0$\n\n**Trong đó:**\n- $\\epsilon$ là độ rộng của ống (epsilon-insensitive tube)\n- $\\xi_i, \\xi_i^*$ là slack variables (trên và dưới)\n- Điểm trong ống: không penalty\n- Điểm ngoài ống: penalty tỷ lệ với khoảng cách\n\n**Tham số:**\n\n**1. Epsilon ($\\epsilon$):**\n- Độ rộng tube\n- $\\epsilon$ lớn: Ống rộng, ít support vectors, underfitting\n- $\\epsilon$ nhỏ: Ống hẹp, nhiều support vectors, overfitting\n- Thường: 0.01, 0.1, 0.5\n\n**2. C:**\n- Trade-off margin vs vi phạm\n- Giống như trong classification\n\n**3. Kernel:**\n- RBF, Linear, Polynomial\n- Giống như classification\n\n**Support Vectors trong SVR:**\n- Điểm nằm trên hoặc ngoài biên ống\n- Điểm trong ống không đóng góp\n\n**Ứng dụng:**\n- Time series forecasting\n- Stock price prediction\n- Weather prediction\n- Regression với outliers\n\n### Điều Chỉnh Hyperparameters\n\n**Các tham số chính:**\n\n**1. C (Regularization):**\n\n**Các khái niệm quan trọng:**\n- Support Vector Machine (SVM) là một thuật toán học có giám sát mạnh mẽ, được sử dụng rộng rãi cho cả bài toán phân loại và hồi quy (SVR). Mục tiêu chính của SVM là tìm một siêu phẳng tối ưu trong không gian nhiều chiều để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng này và các điểm dữ liệu gần nhất (được gọi là support vectors). SVM có khả năng xử lý hiệu quả dữ liệu trong không gian chiều cao, ngay cả khi số lượng chiều lớn hơn số lượng mẫu.\n\nĐể xử lý các bài toán không phân tách tuyến tính trong không gian gốc, SVM sử dụng Kernel Trick để ánh xạ dữ liệu sang một không gian đặc trưng có chiều cao hơn, nơi dữ liệu có thể phân tách tuyến tính. Điều này cho phép SVM hoạt động như một mô hình phi tuyến trong không gian gốc thông qua các hàm kernel linh hoạt. SVM có hai dạng chính là Hard Margin SVM (khi dữ liệu phân tách hoàn toàn) và Soft Margin SVM (khi có thể chấp nhận một số lỗi phân loại để đạt được biên độ lớn hơn), đồng thời tích hợp cơ chế regularization thông qua tham số C để kiểm soát overfitting.\n\nMô hình này được tối ưu hóa thông qua bài toán đối ngẫu để tìm các Lagrange multipliers, từ đó xác định các support vectors quan trọng. Hàm mục tiêu của SVM là một bài toán tối ưu lồi, đảm bảo tìm được cực tiểu toàn cục.\n\nCác ứng dụng của SVM rất đa dạng, bao gồm phân loại văn bản, nhận dạng chữ viết tay, nhận dạng khuôn mặt, phân loại hình ảnh, phân tích sinh học, xác minh chữ ký và dự đoán chuỗi thời gian.\n- Support Vector Machine (SVM) là một mô hình phân loại mạnh mẽ, đặc biệt hiệu quả với dữ liệu có chiều cao và kích thước mẫu nhỏ. SVM hoạt động bằng cách tìm một siêu phẳng tối ưu để phân tách các lớp dữ liệu, tối đa hóa khoảng cách (margin) giữa siêu phẳng và các điểm dữ liệu gần nhất (support vectors). Mô hình này không cung cấp xác suất trực tiếp mà thay vào đó là một hàm quyết định dựa trên khoảng cách. SVM gặp khó khăn trong việc xử lý các tập dữ liệu lớn và không cung cấp thông tin về tầm quan trọng của các đặc trưng một cách trực tiếp. Nó yêu cầu feature scaling và có thể được điều chỉnh cho các vấn đề mất cân bằng lớp. Các ứng dụng của SVM bao gồm phân loại văn bản, nhận dạng hình ảnh và tin sinh học.\n\n**Mối quan hệ:**\n- Support Vector Machine giải quyết non-linear relationships thông qua việc sử dụng kernel functions."
        },
        "output_without_context": {
            "question": "So sánh Hard Margin và Soft Margin trong SVM, yếu tố nào quyết định việc sử dụng Soft Margin thay vì Hard Margin trong các bài toán phân loại không tuyến tính?",
            "answer": "Soft Margin cho phép tồn tại các điểm dữ liệu nằm trong vùng biên, giúp xử lý các trường hợp không tuyến tính và dữ liệu nhiễu."
        }
    },
    {
        "topic_description": "Chủ đề này hướng tới việc phân tích các loại hàm kích hoạt khác nhau trong mạng nơ-ron, như Sigmoid, Tanh và ReLU. Học sinh sẽ cần phân biệt giữa các hàm này và thảo luận về cách mà chúng ảnh hưởng đến khả năng học của mạng nơ-ron, kết nối với các phương pháp tối ưu hóa đã thảo luận trong các tuần trước.",
        "output_with_context": {
            "question": "Hàm kích hoạt nào trong mạng nơ-ron có khả năng khắc phục vấn đề vanishing gradient và thường được sử dụng trong các lớp ẩn?",
            "answer": "ReLU",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n**Cách hoạt động:**\n1. Nhận đầu vào từ các đặc trưng\n2. Tính tổng có trọng số: $z = w^Tx + b = \\sum_{i=1}^{n}w_i x_i + b$\n3. Áp dụng hàm kích hoạt để tạo đầu ra\n\n**Hạn chế quan trọng:** \n- Chỉ có thể học các mẫu phân tách tuyến tính (linearly separable)\n- Không thể giải quyết bài toán XOR\n- Không thể mô hình hóa các quan hệ phi tuyến phức tạp\n\n**Ví dụ:** Một perceptron có thể phân loại điểm nằm phía trên hay dưới một đường thẳng, nhưng không thể phân loại các điểm trong bài toán XOR (cần đường cong để phân tách).\n\n### Perceptron Đa Lớp (Multi-Layer Perceptron - MLP)\n\nMLP khắc phục hạn chế của perceptron đơn bằng cách xếp chồng nhiều lớp, cho phép học các hàm phi tuyến phức tạp.\n\n**Kiến trúc:**\n\n**1. Lớp đầu vào (Input Layer):**\n- Nhận dữ liệu thô\n- Số nơ-ron = số đặc trưng đầu vào\n- Không có phép biến đổi, chỉ truyền dữ liệu\n\n**2. Lớp ẩn (Hidden Layers):**\n- Thực hiện các phép biến đổi phi tuyến\n- Số lượng có thể từ 1 đến hàng trăm lớp\n- Mỗi lớp học biểu diễn trừu tượng hơn\n- Số nơ-ron trong mỗi lớp là hyperparameter\n\n**3. Lớp đầu ra (Output Layer):**\n- Tạo dự đoán cuối cùng\n- Số nơ-ron phụ thuộc vào bài toán:\n  - Hồi quy: 1 nơ-ron\n  - Phân loại nhị phân: 1 nơ-ron (với sigmoid) hoặc 2 (với softmax)\n  - Phân loại đa lớp: K nơ-ron (K = số lớp)\n\n**Lan truyền xuôi (Forward Propagation):**\n\nQuá trình tính toán từ đầu vào đến đầu ra qua các lớp:\n\nVới lớp $l$:\n$$z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}$$\n$$a^{[l]} = \\sigma(z^{[l]})$$\n\nTrong đó:\n- $W^{[l]}$: Ma trận trọng số của lớp $l$ (kích thước $n^{[l]} \times n^{[l-1]}$)\n- $b^{[l]}$: Vector bias của lớp $l$ (kích thước $n^{[l]} \times 1$)\n- $a^{[l-1]}$: Activation của lớp trước (đầu vào cho lớp $l$)\n- $z^{[l]}$: Pre-activation (trước khi áp dụng hàm kích hoạt)\n- $a^{[l]}$: Activation (sau khi áp dụng hàm kích hoạt)\n- $\\sigma$: Hàm kích hoạt\n\n**Ví dụ minh họa:**\n- Lớp 1: 3 nơ-ron, nhận input 784 chiều (ảnh 28×28) → $W^{[1]}$: 3×784\n- Lớp 2: 2 nơ-ron, nhận từ lớp 1 → $W^{[2]}$: 2×3\n\n**Các khái niệm quan trọng:**\n- σ là ký hiệu chung cho hàm kích hoạt (activation function). Hàm kích hoạt được áp dụng lên pre-activation z^[l] để tạo ra activation a^[l] = σ(z^[l]), giúp mạng nơ-ron học các quan hệ phi tuyến tính phức tạp trong dữ liệu.\n\n**Mối quan hệ:**\n- Hàm kích hoạt σ cho phép mạng nơ-ron học các quan hệ phi tuyến tính.\n- Công thức a^[l] = σ(z^[l]) áp dụng hàm kích hoạt σ.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n- Lớp output: 10 nơ-ron (phân loại 10 chữ số) → $W^{[3]}$: 10×2\n\n### Hàm Kích Hoạt (Activation Functions)\n\nHàm kích hoạt thêm tính phi tuyến vào mạng, cho phép học các quan hệ phức tạp. Không có hàm kích hoạt, mạng nhiều lớp chỉ tương đương một phép biến đổi tuyến tính.\n\n**1. Sigmoid:**\n$$\\sigma(z) = \frac{1}{1 + e^{-z}}$$\n\n**Đặc điểm:**\n- Đầu ra: khoảng (0, 1)\n- Hình dạng chữ S, trơn và khả vi\n- Có thể hiểu như xác suất\n\n**Ưu điểm:**\n- Đầu ra bị chặn, dễ diễn giải\n- Phù hợp cho lớp output trong phân loại nhị phân\n\n**Nhược điểm:**\n- **Vanishing gradient:** Gradient gần như bằng 0 khi $|z|$ lớn\n- Output không tập trung quanh 0 (not zero-centered)\n- Tính toán hàm exp tốn kém\n- Ít được dùng trong lớp ẩn của mạng sâu\n\n**2. Tanh (Hyperbolic Tangent):**\n$$\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} = \frac{2}{1+e^{-2z}} - 1$$\n\n**Đặc điểm:**\n- Đầu ra: khoảng (-1, 1)\n- Là phiên bản dịch chuyển và co giãn của sigmoid\n\n**Ưu điểm:**\n- Zero-centered (đầu ra tập trung quanh 0)\n- Gradient mạnh hơn sigmoid\n- Thường hoạt động tốt hơn sigmoid trong lớp ẩn\n\n**Nhược điểm:**\n- Vẫn bị vanishing gradient\n- Tính toán hàm exp tốn kém\n\n**3. ReLU (Rectified Linear Unit):**\n$$ReLU(z) = \\max(0, z) = \begin{cases} z & \text{nếu } z > 0 \\ 0 & \text{nếu } z \\leq 0 \\end{cases}$$\n\n**Đặc điểm:**\n- Cực kỳ đơn giản và hiệu quả\n- Là hàm kích hoạt phổ biến nhất cho lớp ẩn\n\n**Ưu điểm:**\n- **Tính toán nhanh:** Chỉ cần so sánh với 0\n- **Không bị vanishing gradient** khi $z > 0$\n- **Sparsity:** Một số nơ-ron có activation = 0, tạo biểu diễn thưa\n- **Tăng tốc hội tụ:** Nhanh hơn sigmoid/tanh 6 lần\n\n**Nhược điểm:**\n- **Dying ReLU problem:** Nếu $z < 0$ trong quá trình training, gradient = 0, nơ-ron \"chết\" và không bao giờ được cập nhật\n- Output không zero-centered\n- Unbounded output (có thể dẫn đến giá trị quá lớn)\n\n**4. Leaky ReLU:**\n$$LeakyReLU(z) = \\max(\\alpha z, z) = \begin{cases} z & \text{nếu } z > 0 \\ \\alpha z & \text{nếu } z \\leq 0 \\end{cases}$$\n\nVới $\\alpha$ thường là 0.01 hoặc 0.02\n\n**Ưu điểm:**\n- Khắc phục dying ReLU: vẫn có gradient nhỏ khi $z < 0$\n- Giữ được ưu điểm tính toán nhanh của ReLU\n\n\n**Các khái niệm quan trọng:**\n- Activation Functions (Hàm Kích Hoạt) là các hàm phi tuyến được áp dụng cho đầu ra của mỗi nơ-ron trong mạng nơ-ron. Chúng thêm tính phi tuyến vào mô hình, cho phép mạng học các quan hệ phức tạp trong dữ liệu mà không thể học được chỉ với các phép biến đổi tuyến tính. Nếu không có hàm kích hoạt, một mạng nơ-ron nhiều lớp sẽ chỉ tương đương với một mô hình tuyến tính đơn giản.\n\n**Mối quan hệ:**\n- Tanh là một loại Activation Functions, được sử dụng để thêm tính phi tuyến vào mạng nơ-ron.\n- Activation Functions cải thiện khả năng học của Deep Learning bằng cách thêm tính phi tuyến, cho phép mô hình học các quan hệ phức tạp trong dữ liệu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n- Matrix factorization (NMF, SVD)\n\n**5. Topic Modeling:**\n- Document clustering\n- Automatic tagging\n- Content organization\n- Trend detection\n\n**6. Gene Expression Analysis:**\n- Group similar genes\n- Identify cancer subtypes\n- Drug discovery\n- Understanding diseases\n\n**7. Social Network Analysis:**\n- Community detection\n- Influencer identification\n- Link prediction\n- Recommendation\n\n**8. Data Preprocessing:**\n- Feature extraction (PCA, ICA)\n- Noise reduction (autoencoders)\n- Data compression\n- Dimensionality reduction\n\n**9. Market Basket Analysis:**\n- Product recommendations\n- Store layout\n- Promotions\n- Cross-selling\n\n**10. Image Segmentation:**\n- Medical imaging\n- Object detection preparation\n- Video processing\n- Computer vision preprocessing\n\n---\n\n## Học Sâu (Deep Learning)\n\n### Giới Thiệu về Học Sâu\n\nHọc sâu (Deep Learning) là một nhánh con của học máy sử dụng mạng nơ-ron nhân tạo với nhiều lớp ẩn để học các biểu diễn phân cấp của dữ liệu. Khác với các phương pháp học máy truyền thống, học sâu có khả năng tự động trích xuất đặc trưng từ dữ liệu thô mà không cần kỹ thuật đặc trưng thủ công.\n\n**Đặc điểm chính:**\n- **Học biểu diễn phân cấp:** Các lớp đầu học các đặc trưng cấp thấp (cạnh, góc), các lớp sau học đặc trưng cấp cao hơn (hình dạng, đối tượng)\n- **Khả năng xử lý dữ liệu lớn:** Hiệu suất tăng theo lượng dữ liệu\n- **End-to-end learning:** Học trực tiếp từ đầu vào thô đến đầu ra mong muốn\n- **Tự động trích xuất đặc trưng:** Không cần thiết kế đặc trưng thủ công\n\n**Ứng dụng đã cách mạng hóa:**\n- Thị giác máy tính (nhận dạng ảnh, phát hiện đối tượng)\n- Xử lý ngôn ngữ tự nhiên (dịch máy, chatbot, sinh văn bản)\n- Nhận dạng giọng nói (trợ lý ảo, chuyển đổi giọng nói thành văn bản)\n- Y tế (chẩn đoán hình ảnh, phát triển thuốc)\n- Tự động hóa (xe tự lái, robot)\n\n### Mạng Nơ-ron Nhân Tạo (Artificial Neural Networks - ANN)\n\nMạng nơ-ron nhân tạo được lấy cảm hứng từ cách thức hoạt động của não người, trong đó các nơ-ron sinh học truyền tín hiệu cho nhau thông qua các synapse.\n\n### Perceptron - Đơn Vị Cơ Bản\n\nPerceptron là đơn vị mạng nơ-ron đơn giản nhất, được phát minh bởi Frank Rosenblatt năm 1958.\n\n**Công thức:**\n$$y = \\sigma(w^Tx + b)$$\n\nTrong đó:\n- $x = [x_1, x_2, ..., x_n]^T$: Vector đầu vào (các đặc trưng)\n- $w = [w_1, w_2, ..., w_n]^T$: Vector trọng số (weights)\n- $b$: Hệ số điều chỉnh (bias) - cho phép dịch chuyển hàm quyết định\n- $\\sigma$: Hàm kích hoạt (activation function)\n- $y$: Đầu ra dự đoán\n\n\n**Các khái niệm quan trọng:**\n- $\\sigma$ (hoặc $\\sigma(z)$) là ký hiệu chung cho một hàm kích hoạt (activation function), một hàm phi tuyến tính được áp dụng cho tổng có trọng số của đầu vào (hay đầu ra tuyến tính pre-activation $z$) của một nơ-ron. Hàm kích hoạt có vai trò quyết định xem một nơ-ron có nên được \"kích hoạt\" hay không và giới thiệu tính phi tuyến tính vào mô hình, giúp mạng nơ-ron học các mối quan hệ phức tạp trong dữ liệu. Các hàm kích hoạt phổ biến bao gồm Sigmoid hoặc ReLU.\n\n**Mối quan hệ:**\n- Công thức $y = \\sigma(w^Tx + b)$ sử dụng $\\sigma$ làm hàm kích hoạt.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\nBackpropagation có thể được hiểu thông qua đồ thị tính toán (computational graph), trong đó:\n- Mỗi node là một operation\n- Edges mang giá trị và gradients\n- Forward pass tính giá trị, backward pass tính gradients\n\n**Vấn đề Vanishing/Exploding Gradients:**\n- **Vanishing:** Gradient giảm dần khi lan truyền về các lớp đầu → các lớp đầu học chậm\n  - Nguyên nhân: Hàm kích hoạt có đạo hàm nhỏ (sigmoid, tanh)\n  - Giải pháp: ReLU, batch normalization, residual connections\n- **Exploding:** Gradient tăng dần → weights cập nhật quá mạnh, không ổn định\n  - Giải pháp: Gradient clipping, proper weight initialization\n\n**Lưu ý về hiệu suất:**\n- Độ phức tạp tính toán của backpropagation tương đương forward pass\n- Matrix operations có thể vectorize → tính toán hiệu quả trên GPU\n- Cần lưu trữ activations từ forward pass → tốn memory\n\n### Thuật Toán Tối Ưu (Optimization Algorithms)\n\nCác thuật toán tối ưu quyết định cách cập nhật weights để minimize loss function.\n\n**1. Gradient Descent (Hạ Gradient):**\n$$w := w - \\alpha\frac{\\partial L}{\\partial w}$$\n\n**Đặc điểm:**\n- $\\alpha$ (learning rate): Hyperparameter quan trọng nhất\n- Cập nhật dựa trên toàn bộ training set (batch gradient descent)\n\n**Ưu điểm:**\n- Đơn giản, dễ hiểu\n- Hội tụ ổn định với learning rate phù hợp\n- Đảm bảo tìm được local minimum với hàm convex\n\n**Nhược điểm:**\n- Chậm với dữ liệu lớn (phải xử lý toàn bộ dataset mỗi iteration)\n- Có thể bị kẹt ở local minima hoặc saddle points\n- Learning rate cố định không phù hợp mọi giai đoạn training\n\n**2. Stochastic Gradient Descent (SGD):**\n$$w := w - \\alpha\frac{\\partial L_i}{\\partial w}$$\n\n**Đặc điểm:**\n- Cập nhật sau **mỗi** mẫu dữ liệu (sample)\n- Gradient ước lượng từ 1 sample → noisy nhưng nhanh\n\n**Ưu điểm:**\n- Rất nhanh, có thể train trên dữ liệu lớn\n- Noise giúp thoát khỏi local minima\n- Có thể train online (dữ liệu đến liên tục)\n\n**Nhược điểm:**\n- Quá trình hội tụ không ổn định, dao động mạnh\n- Có thể không hội tụ chính xác đến minimum\n- Khó song song hóa (sequential updates)\n\n**3. Mini-batch Gradient Descent:**\n$$w := w - \\alpha\frac{1}{m}\\sum_{i=1}^{m}\frac{\\partial L_i}{\\partial w}$$\n\n**Đặc điểm:**\n- Cập nhật sau một **batch nhỏ** (thường 32, 64, 128, 256)\n- Kết hợp ưu điểm của batch GD và SGD\n- **Là phương pháp được sử dụng phổ biến nhất trong thực tế**\n\n**Ưu điểm:**\n- Tốc độ nhanh, ổn định hơn SGD\n- Có thể vectorize, tận dụng GPU hiệu quả\n- Gradient ổn định hơn SGD nhưng vẫn có noise tốt\n- Batch size là hyperparameter điều chỉnh được\n\n**Lựa chọn batch size:**\n\n**Các khái niệm quan trọng:**\n- Sigmoid là một hàm kích hoạt có đạo hàm nhỏ, thường được sử dụng trong các lớp output cho bài toán phân loại nhị phân hoặc trong các mạng nơ-ron truyền thống. Tuy nhiên, nó là một trong những nguyên nhân gây ra vấn đề Vanishing Gradients do đạo hàm của nó có xu hướng về 0 ở các giá trị đầu vào lớn hoặc nhỏ.\n\n**Mối quan hệ:**\n- Vanishing Gradients có nguyên nhân từ việc sử dụng hàm kích hoạt có đạo hàm nhỏ như sigmoid, khiến gradient giảm dần khi lan truyền về các lớp đầu."
        },
        "output_without_context": {
            "question": "So sánh các hàm kích hoạt Sigmoid, Tanh và ReLU, hàm nào có khả năng giúp mạng nơ-ron học tốt hơn trong các tình huống có gradient thấp?",
            "answer": "ReLU"
        }
    },
    {
        "topic_description": "Chủ đề này kiểm tra kiến thức của học sinh về phân cụm trong học máy, các thuật toán như K-Means và DBSCAN được trình bày trong tuần 6. Học sinh sẽ được yêu cầu thảo luận về các ứng dụng của phân cụm và cách mà các yếu tố như tính chất dữ liệu ảnh hưởng đến quá trình này, liên kết đến các ứng dụng thực tế mà học sinh đã học.",
        "output_with_context": {
            "question": "Trong thuật toán DBSCAN, tham số nào xác định khoảng cách tối đa giữa hai điểm để chúng được coi là hàng xóm?",
            "answer": "ε (epsilon)",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n   - Merge chúng thành 1 cluster\n3. Until: Chỉ còn 1 cluster\n\n**Steps chi tiết:**\n- Initialize: N clusters\n- Iteration 1: N-1 clusters\n- Iteration 2: N-2 clusters\n- ...\n- Final: 1 cluster\n\n**2. Divisive (Top-Down - Phân Chia):**\n\n**Thuật toán:**\n1. Start: Tất cả điểm trong 1 cluster\n2. Repeat:\n   - Chọn cluster để split\n   - Chia thành 2 sub-clusters\n3. Until: Mỗi điểm là 1 cluster\n\n**Ít phổ biến:** Computationally expensive hơn\n\n**Linkage Methods (Cách Đo Khoảng Cách Giữa Clusters):**\n\n**1. Single Linkage (Minimum):**\n$$d(C_i, C_j) = \\min_{x \\in C_i, y \\in C_j}d(x,y)$$\n- Khoảng cách giữa 2 điểm gần nhất\n- Tạo long, chain-like clusters\n- Sensitive to noise và outliers\n\n**2. Complete Linkage (Maximum):**\n$$d(C_i, C_j) = \\max_{x \\in C_i, y \\in C_j}d(x,y)$$\n- Khoảng cách giữa 2 điểm xa nhất\n- Tạo compact, spherical clusters\n- Ít sensitive to outliers\n\n**3. Average Linkage:**\n$$d(C_i, C_j) = \frac{1}{|C_i||C_j|}\\sum_{x \\in C_i}\\sum_{y \\in C_j}d(x,y)$$\n- Trung bình tất cả pairwise distances\n- Balance giữa single và complete\n- Phổ biến choice\n\n**4. Ward's Method:**\n- Minimize within-cluster variance sau khi merge\n- Maximize between-cluster variance\n- Tạo balanced, compact clusters\n- Thường cho kết quả tốt nhất\n- Phổ biến nhất trong thực tế\n\n**Dendrogram (Biểu Đồ Cây):**\n\nTree diagram showing cluster hierarchy.\n\n**Đọc Dendrogram:**\n- Vertical axis: Distance/dissimilarity\n- Horizontal axis: Samples\n- Height của merge: Distance giữa clusters\n- Càng cao merge càng dissimilar\n\n**Cutting Dendrogram:**\n- Vẽ horizontal line\n- Number of intersections = Number of clusters\n- Height của cut = dissimilarity threshold\n\n**Ưu Điểm:**\n- Không cần specify K trước\n- Dendrogram provides insights\n- Flexible - có thể chọn K sau\n- Deterministic (no randomness)\n\n**Nhược Điểm:**\n- Computationally expensive: O(N²log N) or O(N³)\n- Không scale với large datasets\n- Một khi merge không thể undo\n- Memory intensive\n\n**Khi Nào Dùng:**\n- Small-medium datasets (< 10,000)\n- Cần understand hierarchy\n- Không biết K optimal\n- Exploratory analysis\n\n### DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n\nNhóm các điểm có mật độ cao, robust to outliers và arbitrary shapes.\n\n**Tham Số:**\n\n**1. ε (epsilon):**\n- Maximum distance giữa 2 điểm để được coi là neighbors\n- Định nghĩa neighborhood radius\n- Quá nhỏ: Nhiều noise points\n- Quá lớn: Merge nhiều clusters\n\n**2. MinPts (Minimum Points):**\n- Minimum số điểm trong ε-neighborhood để là core point\n- Thường: 4, 5, hoặc 2×dim\n- Larger MinPts: Ít core points, stricter\n\n**Các Loại Điểm:**\n\n**1. Core Point:**\n- Có ≥ MinPts điểm khác trong ε-neighborhood (bao gồm cả chính nó)\n- Trung tâm của clusters\n- Can form clusters\n\n**2. Border Point:**\n- Nằm trong ε-neighborhood của core point\n- Có < MinPts neighbors\n- Thuộc cluster nhưng không core\n- Ở biên của cluster\n\n\n**Các khái niệm quan trọng:**\n- DBSCAN (Density-Based Spatial Clustering of Applications with Noise) là một thuật toán phân cụm học không giám sát dựa trên mật độ, không yêu cầu chỉ định số lượng cụm K trước. Thuật toán này có khả năng tìm các cụm có hình dạng tùy ý, nhóm các điểm có mật độ cao và mạnh mẽ với nhiễu (outliers). DBSCAN hoạt động bằng cách mở rộng các cụm từ các \"core points\" dựa trên hai tham số ε (bán kính) và MinPts (số điểm tối thiểu), có tốc độ trung bình và phù hợp cho dữ liệu không gian có nhiễu.\n- Hierarchical Clustering (Phân cụm phân cấp) là một loại thuật toán phân cụm xây dựng một hệ thống phân cấp các cụm, thường được biểu diễn dưới dạng cây (dendrogram). Không giống như K-Means, nó không yêu cầu chỉ định số lượng cụm K trước, mà số lượng cụm có thể được chọn sau khi cây phân cấp đã được xây dựng. Có hai phương pháp chính: Agglomerative (tích tụ, từ dưới lên) và Divisive (phân chia, từ trên xuống). Agglomerative Clustering là một thuật toán phân cụm phân cấp theo phương pháp Bottom-Up (từ dưới lên), bắt đầu với mỗi điểm dữ liệu là một cụm riêng biệt. Sau đó, nó lặp lại việc tìm và hợp nhất hai cụm gần nhất thành một cụm lớn hơn cho đến khi chỉ còn một cụm duy nhất hoặc đạt được một tiêu chí dừng nào đó, tạo ra một cấu trúc cây (dendrogram) thể hiện mối quan hệ phân cấp giữa các cụm.\n\n**Mối quan hệ:**\n- DBSCAN là một thuật toán thuộc lĩnh vực Học Không Giám Sát, được sử dụng để phân cụm dữ liệu không nhãn.\n- DBSCAN cải thiện khả năng phân cụm bằng cách mạnh mẽ với các điểm ngoại lai, tự động coi chúng là nhiễu và không gộp vào các cụm chính.\n- DBSCAN cải thiện khả năng phân cụm bằng cách xử lý các cụm có hình dạng tùy ý, không giới hạn bởi giả định hình cầu.\n- Agglomerative Clustering là một thuật toán thuộc lĩnh vực Học Không Giám Sát, được sử dụng để phân cụm dữ liệu không nhãn.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n**3. Affinity Propagation:**\n\n**Nguyên lý:**\n- Message passing between data points\n- Points \"vote\" on their exemplars\n- Automatically determines K\n\n**Messages:**\n- **Responsibility:** Điểm $i$ chọn điểm $k$ làm exemplar\n- **Availability:** Điểm $k$ available làm exemplar cho $i$\n\n**Ưu điểm:**\n- Không cần specify K\n- Flexible\n- Finds exemplars (representative points)\n\n**Nhược điểm:**\n- Slow (O(N²T), T = iterations)\n- Memory intensive\n- Sensitive to preferences\n\n**4. OPTICS (Ordering Points To Identify Clustering Structure):**\n\n**Nguyên lý:**\n- Extension của DBSCAN\n- Tạo ordering của points\n- Handle varying densities better\n\n**Output:**\n- Reachability plot\n- Extract clusters ở different density levels\n\n**Ưu điểm:**\n- Varying densities\n- Không cần ε cụ thể\n- Hierarchical view\n\n**Nhược điểm:**\n- Complex interpretation\n- Still need MinPts\n\n**So Sánh Các Thuật Toán:**\n\n| Algorithm | K needed | Shape | Outliers | Speed | Best for |\n|-----------|----------|-------|----------|-------|----------|\n| K-Means | Yes | Spherical | Sensitive | Fast | Large, simple |\n| Hierarchical | No | Any | Sensitive | Slow | Small, hierarchy |\n| DBSCAN | No | Arbitrary | Robust | Medium | Spatial, noise |\n| GMM | Yes | Elliptical | Sensitive | Slow | Probabilistic |\n| Mean Shift | No | Arbitrary | Robust | Slow | Non-uniform |\n| Spectral | Yes | Complex | Sensitive | Slow | Graph-like |\n\n### Giảm Số Chiều (Dimensionality Reduction)\n\nĐã được cover chi tiết trong phần Feature Selection & Model Optimization, đây là summary.\n\n### Principal Component Analysis (PCA)\n\n**Nguyên lý:**\n- Linear transformation sang orthogonal components\n- Components ordered by variance\n- Maximize variance retained\n\n**Công thức:**\n$$Z = XW_k$$\n\nTrong đó $W_k$ là matrix của k eigenvectors.\n\n**Steps:**\n1. Standardize data: $X' = \frac{X - \\mu}{\\sigma}$\n2. Covariance matrix: $\\Sigma = \frac{1}{n}X'^TX'$\n3. Eigendecomposition: $\\Sigma = V\\Lambda V^T$\n4. Chọn top k eigenvectors\n5. Transform: $Z = X'W_k$\n\n**Variance Explained:**\n$$\frac{\\lambda_k}{\\sum_{i=1}^{n}\\lambda_i} \times 100\\%$$\n\n**Chọn số components:**\n- Cumulative variance ≥ 95% hoặc 99%\n- Scree plot (elbow)\n- Kaiser criterion (eigenvalue > 1)\n\n**Ứng dụng:**\n- Visualization (2D/3D)\n- Noise reduction\n- Feature extraction\n- Speed up learning\n- Preprocessing\n\n### Singular Value Decomposition (SVD)\n\n**Matrix factorization:**\n$$X = U\\Sigma V^T$$\n\n- $U$: Left singular vectors (m × m)\n- $\\Sigma$: Singular values (m × n, diagonal)\n- $V^T$: Right singular vectors (n × n)\n\n**Quan hệ với PCA:**\n- PCA eigenvectors = right singular vectors\n- PCA eigenvalues = squared singular values\n\n**Ứng dụng:**\n- PCA computation\n- Latent Semantic Analysis (LSA)\n- Recommender systems (matrix completion)\n- Image compression\n- Data compression\n\n**Truncated SVD:**\n- Giữ top k components\n- Approximation: $X \\approx U_k\\Sigma_kV_k^T$\n\n### Independent Component Analysis (ICA)\n\n**Nguyên lý:**\n- Tách signal thành independent components\n- Maximize statistical independence\n- Non-Gaussian components\n\n**Model:**\n$$X = AS$$\n\nTrong đó:\n- $X$: Observed signals (mixed)\n- $A$: Mixing matrix (unknown)\n- $S$: Source signals (independent, unknown)\n\n**Mục tiêu:** Estimate $A$ và $S$ from $X$\n\n**Cocktail Party Problem:**\n- Multiple people talking simultaneously\n\n**Các khái niệm quan trọng:**\n- DBSCAN (Density-Based Spatial Clustering of Applications with Noise) là một thuật toán phân cụm học không giám sát dựa trên mật độ, không yêu cầu chỉ định số lượng cụm K trước. Thuật toán này có khả năng tìm các cụm có hình dạng tùy ý, nhóm các điểm có mật độ cao và mạnh mẽ với nhiễu (outliers). DBSCAN hoạt động bằng cách mở rộng các cụm từ các \"core points\" dựa trên hai tham số ε (bán kính) và MinPts (số điểm tối thiểu), có tốc độ trung bình và phù hợp cho dữ liệu không gian có nhiễu.\n\n**Mối quan hệ:**\n- DBSCAN là một thuật toán thuộc lĩnh vực Học Không Giám Sát, được sử dụng để phân cụm dữ liệu không nhãn.\n- DBSCAN cải thiện khả năng phân cụm bằng cách mạnh mẽ với các điểm ngoại lai, tự động coi chúng là nhiễu và không gộp vào các cụm chính.\n- DBSCAN cải thiện khả năng phân cụm bằng cách xử lý các cụm có hình dạng tùy ý, không giới hạn bởi giả định hình cầu.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Không Giám Sát (Unsupervised Learning)\n**Bước 4: Repeat**\n- Lặp lại Steps 2-3 cho đến khi convergence\n\n**Convergence khi:**\n- Centroids không đổi\n- Assignments không đổi\n- Đạt max iterations\n\n**Objective Function (WCSS - Within-Cluster Sum of Squares):**\n$$J = \\sum_{k=1}^{K}\\sum_{x \\in C_k}||x - \\mu_k||^2$$\n\nMục tiêu: Minimize J\n\n**Chọn K (Số Clusters):**\n\n**1. Elbow Method:**\n- Vẽ WCSS vs K\n- Tìm \"khuỷu tay\" (elbow) - điểm mà WCSS giảm chậm lại\n- Tradeoff giữa số clusters và fit\n\n**Ví dụ:**\n```\nWCSS\n  |  \\\n  |    \\\n  |      \\___\n  |          ----___\n  +----------------->\n  1  2  3  4  5  6  K\n       ↑ Elbow ~ K=3\n```\n\n**2. Silhouette Score:**\n$$s(i) = \frac{b(i) - a(i)}{\\max(a(i), b(i))}$$\n\nTrong đó:\n- $a(i)$: Average distance đến các điểm trong cùng cluster\n- $b(i)$: Average distance đến các điểm trong nearest cluster\n- Score: -1 đến 1\n  - ~1: Tốt, điểm xa cluster khác\n  - ~0: Gần boundary\n  - Negative: Có thể assign sai\n\n**Average Silhouette Score:**\n- Trung bình trên tất cả điểm\n- Chọn K có score cao nhất\n\n**3. Gap Statistic:**\n- So sánh WCSS với expected WCSS dưới null distribution\n- Chọn K where gap lớn nhất\n\n**4. Domain Knowledge:**\n- Business requirements\n- Interpretability\n- Practical constraints\n\n**Ưu Điểm:**\n- Đơn giản, dễ implement\n- Nhanh, scalable\n- Hoạt động tốt với spherical clusters\n- Dễ interpret\n\n**Nhược Điểm:**\n\n**1. Phải chỉ định K trước:**\n- Không biết K optimal\n- Cần thử nhiều giá trị\n\n**2. Nhạy cảm với initialization:**\n- Different initializations → different results\n- Có thể stuck ở local minima\n\n**3. Giả định spherical clusters:**\n- Không tốt với elongated/irregular shapes\n- Equal-sized clusters\n\n**4. Nhạy cảm với outliers:**\n- Outliers ảnh hưởng đến centroids\n- Có thể tạo clusters cho outliers\n\n**5. Phụ thuộc vào scale:**\n- Features có scale lớn dominate\n- Cần scaling trước\n\n**Cải Tiến:**\n\n**K-Means++:**\n- Better initialization strategy\n- Chọn centroids xa nhau\n- Giảm chance của bad initialization\n- Convergence nhanh hơn\n\n**Mini-batch K-Means:**\n- Sử dụng random mini-batches\n- Nhanh hơn nhiều với large datasets\n- Trade-off: Hơi kém chính xác\n- Good cho online learning\n\n**Practical Tips:**\n- Luôn standardize features\n- Run multiple times với different initializations\n- Use K-Means++ initialization\n- Try different K values\n- Visualize results nếu có thể\n\n### Hierarchical Clustering (Phân Cụm Phân Cấp)\n\nXây dựng hierarchy của clusters mà không cần chỉ định K trước.\n\n**Đặc điểm:**\n- Tạo tree structure (dendrogram)\n- Có thể chọn số clusters sau\n- Two approaches: Agglomerative và Divisive\n\n**1. Agglomerative (Bottom-Up - Tích Tụ):**\n\n**Thuật toán:**\n1. Start: Mỗi điểm là một cluster (N clusters)\n2. Repeat:\n   - Tìm 2 clusters gần nhất\n\n**Các khái niệm quan trọng:**\n- K là tham số trong thuật toán K-Means (K-Means Clustering), đại diện cho số lượng cụm (clusters) mà dữ liệu sẽ được phân chia thành. Việc chọn giá trị K tối ưu hoặc phù hợp là một thách thức trong học không giám sát và có thể được thực hiện bằng các phương pháp như Elbow Method, Silhouette Score, Gap Statistic hoặc dựa trên kiến thức miền (domain knowledge).\n- Hierarchical Clustering (Phân cụm phân cấp) là một loại thuật toán phân cụm xây dựng một hệ thống phân cấp các cụm, thường được biểu diễn dưới dạng cây (dendrogram). Không giống như K-Means, nó không yêu cầu chỉ định số lượng cụm K trước, mà số lượng cụm có thể được chọn sau khi cây phân cấp đã được xây dựng. Có hai phương pháp chính: Agglomerative (tích tụ, từ dưới lên) và Divisive (phân chia, từ trên xuống). Agglomerative Clustering là một thuật toán phân cụm phân cấp theo phương pháp Bottom-Up (từ dưới lên), bắt đầu với mỗi điểm dữ liệu là một cụm riêng biệt. Sau đó, nó lặp lại việc tìm và hợp nhất hai cụm gần nhất thành một cụm lớn hơn cho đến khi chỉ còn một cụm duy nhất hoặc đạt được một tiêu chí dừng nào đó, tạo ra một cấu trúc cây (dendrogram) thể hiện mối quan hệ phân cấp giữa các cụm.\n- Spherical clusters (cụm hình cầu) là một giả định của thuật toán K-Means, cho rằng các cụm dữ liệu có hình dạng gần giống hình cầu và có kích thước tương đương. K-Means hoạt động kém hiệu quả với các cụm có hình dạng kéo dài (elongated) hoặc không đều, vì nó cố gắng tìm các tâm cụm dựa trên khoảng cách Euclidean, phù hợp nhất với các cụm hình cầu.\n\n**Mối quan hệ:**\n- K-Means giả định rằng các cụm dữ liệu có hình dạng spherical clusters, điều này có thể hạn chế hiệu quả của nó với các hình dạng cụm phức tạp hơn.\n- Mean Shift là một thuật toán phân cụm không cần chỉ định số lượng cụm K trước, mà tự động xác định K dựa trên mật độ dữ liệu.\n- Agglomerative Clustering là một thuật toán thuộc lĩnh vực Học Không Giám Sát, được sử dụng để phân cụm dữ liệu không nhãn."
        },
        "output_without_context": {
            "question": "Trong phân cụm, thuật toán nào thường được sử dụng để nhóm các điểm dữ liệu dựa trên khoảng cách giữa chúng?",
            "answer": "K-Means"
        }
    },
    {
        "topic_description": "Chủ đề này tập trung vào quy trình lan truyền ngược trong mạng nơ-ron, yêu cầu học sinh mô tả quy trình và ứng dụng của nó trong việc huấn luyện mạng. Qua đó, sinh viên sẽ cần nắm rõ lý thuyết đằng sau việc cập nhật trọng số và vai trò của gradient trong hệ thống học máy, có liên hệ với các kỹ thuật tối ưu hóa đã học trước đây.",
        "output_with_context": {
            "question": "Trong quy trình lan truyền ngược, công thức nào được sử dụng để tính gradient của hàm loss theo trọng số tại lớp thứ l?",
            "answer": "\\frac{\\partial L}{\\partial W^{[l]}} = \\frac{\\partial L}{\\partial z^{[l]}} \\cdot (a^{[l-1]})^T",
            "rag_context": "**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\n- **RMSE (Root Mean Squared Error):** $\\sqrt{MSE}$ - có cùng đơn vị với dữ liệu\n- **MAE (Mean Absolute Error):** $\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$ - ít nhạy với outliers\n\n**2. Binary Cross-Entropy (Phân Loại Nhị Phân):**\n$$L = -\frac{1}{n}\\sum_{i=1}^{n}[y_i\\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)]$$\n\n**Đặc điểm:**\n- **Sử dụng:** Phân loại nhị phân (2 lớp)\n- $y_i \\in \\{0, 1\\}$: nhãn thực tế\n- $\\hat{y}_i \\in (0, 1)$: xác suất dự đoán (output của sigmoid)\n\n**Cách hoạt động:**\n- Nếu $y_i = 1$: loss = $-\\log(\\hat{y}_i)$ → minimize khi $\\hat{y}_i \to 1$\n- Nếu $y_i = 0$: loss = $-\\log(1-\\hat{y}_i)$ → minimize khi $\\hat{y}_i \to 0$\n\n**Ưu điểm:**\n- Phù hợp với sigmoid activation\n- Gradient tốt, không bị vanishing\n- Có ý nghĩa xác suất\n\n**Lưu ý:** \n- Cần thêm epsilon nhỏ để tránh log(0): $\\log(\\hat{y}_i + \\epsilon)$\n- Còn gọi là log loss\n\n**3. Categorical Cross-Entropy (Phân Loại Đa Lớp):**\n$$L = -\\sum_{i=1}^{n}\\sum_{c=1}^{C}y_{i,c}\\log(\\hat{y}_{i,c})$$\n\n**Đặc điểm:**\n- **Sử dụng:** Phân loại đa lớp (nhiều hơn 2 lớp)\n- $y_{i,c}$: nhãn thực tế dạng one-hot encoding (chỉ 1 phần tử = 1, còn lại = 0)\n- $\\hat{y}_{i,c}$: xác suất dự đoán cho lớp $c$ (output của softmax)\n- $C$: số lớp\n\n**Ví dụ:** Với 3 lớp, $y = [0, 1, 0]$ (lớp 2), $\\hat{y} = [0.1, 0.7, 0.2]$\n$$L = -(0 \\cdot \\log(0.1) + 1 \\cdot \\log(0.7) + 0 \\cdot \\log(0.2)) = -\\log(0.7) \\approx 0.357$$\n\n**Biến thể:**\n- **Sparse Categorical Cross-Entropy:** Nhãn là integer (0, 1, 2,...) thay vì one-hot, tiết kiệm bộ nhớ\n\n**4. Huber Loss (Hồi Quy Bền Vững):**\n$$L_{\\delta}(y, \\hat{y}) = \begin{cases} \frac{1}{2}(y - \\hat{y})^2 & \text{nếu } |y - \\hat{y}| \\leq \\delta \\ \\delta(|y - \\hat{y}| - \frac{1}{2}\\delta) & \text{ngược lại} \\end{cases}$$\n\n**Đặc điểm:**\n- Kết hợp MSE và MAE\n- Ít nhạy cảm với outliers hơn MSE\n- $\\delta$ là hyperparameter kiểm soát điểm chuyển đổi\n\n**Sử dụng:**\n- Hồi quy khi có outliers\n- Reinforcement learning (ví dụ: DQN)\n\n### Lan Truyền Ngược (Backpropagation)\n\n\n**Các khái niệm quan trọng:**\n- Backpropagation (Lan Truyền Ngược) là một thuật toán cốt lõi và quan trọng trong việc huấn luyện mạng nơ-ron sâu. Nó được sử dụng để tính toán gradient của hàm loss đối với tất cả các tham số của mạng (weights và biases) một cách hiệu quả. Thuật toán này hoạt động bằng cách lan truyền ngược gradient (hoặc lỗi) từ output layer về input layer thông qua đồ thị tính toán, sử dụng quy tắc chuỗi (chain rule) để phân rã gradient phức tạp thành các phần đơn giản. Quá trình này cho phép cập nhật hiệu quả các tham số của mô hình. Backpropagation bao gồm một forward pass để tính giá trị (activations) và một backward pass để tính gradients. Độ phức tạp tính toán của nó tương đương với forward pass, nhưng cần lưu trữ các activations từ forward pass, dẫn đến yêu cầu về bộ nhớ.\n\n**Mối quan hệ:**\n- Backpropagation tính toán gradient để cập nhật biases của mạng nơ-ron thông qua các optimizer.\n- Backpropagation tính toán gradient để cập nhật weights của mạng nơ-ron thông qua các optimizer.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\nBackpropagation là thuật toán cốt lõi để huấn luyện mạng nơ-ron sâu, cho phép tính gradient một cách hiệu quả thông qua quy tắc chuỗi (chain rule).\n\n**Ý tưởng cơ bản:**\n- Tính toán gradient của loss function theo tất cả các tham số (weights và biases)\n- Lan truyền gradient từ output về input qua các lớp\n- Sử dụng quy tắc chuỗi để phân rã gradient phức tạp thành các phần đơn giản\n\n**Quy tắc chuỗi (Chain Rule):**\n$$\frac{\\partial L}{\\partial w^{[l]}} = \frac{\\partial L}{\\partial a^{[l]}} \\cdot \frac{\\partial a^{[l]}}{\\partial z^{[l]}} \\cdot \frac{\\partial z^{[l]}}{\\partial w^{[l]}}$$\n\nTrong đó:\n- $\frac{\\partial L}{\\partial a^{[l]}}$: Gradient của loss theo activation\n- $\frac{\\partial a^{[l]}}{\\partial z^{[l]}}$: Đạo hàm của hàm kích hoạt\n- $\frac{\\partial z^{[l]}}{\\partial w^{[l]}}$: Gradient của pre-activation theo weights\n\n**Các bước chi tiết:**\n\n**1. Forward Pass (Lan truyền xuôi):**\n- Tính toán output của mỗi lớp từ input đến output\n- Lưu trữ tất cả các giá trị $z^{[l]}$ và $a^{[l]}$ (cần cho backward pass)\n\n**2. Tính Loss:**\n- So sánh prediction với ground truth\n- Tính giá trị loss: $L = Loss(y, \\hat{y})$\n\n**3. Backward Pass (Lan truyền ngược):**\n- Bắt đầu từ lớp output, tính gradient của loss theo output\n- Với mỗi lớp từ L về 1:\n  - Tính $\frac{\\partial L}{\\partial z^{[l]}} = \frac{\\partial L}{\\partial a^{[l]}} \\odot \\sigma'(z^{[l]})$ (element-wise product)\n  - Tính $\frac{\\partial L}{\\partial W^{[l]}} = \frac{\\partial L}{\\partial z^{[l]}} \\cdot (a^{[l-1]})^T$\n  - Tính $\frac{\\partial L}{\\partial b^{[l]}} = \frac{\\partial L}{\\partial z^{[l]}}$\n  - Lan truyền về lớp trước: $\frac{\\partial L}{\\partial a^{[l-1]}} = (W^{[l]})^T \\cdot \frac{\\partial L}{\\partial z^{[l]}}$\n\n**4. Cập nhật Weights:**\n- Sử dụng gradient descent hoặc các optimizer khác\n- $W^{[l]} := W^{[l]} - \\alpha \frac{\\partial L}{\\partial W^{[l]}}$\n- $b^{[l]} := b^{[l]} - \\alpha \frac{\\partial L}{\\partial b^{[l]}}$\n\n**Ví dụ minh họa:**\nMạng 2 lớp: Input → Hidden → Output\n- Forward: $a^{[1]} = \\sigma(W^{[1]}x + b^{[1]})$, $\\hat{y} = \\sigma(W^{[2]}a^{[1]} + b^{[2]})$\n- Loss: $L = (y - \\hat{y})^2$\n- Backward:\n  - $\frac{\\partial L}{\\partial \\hat{y}} = -2(y - \\hat{y})$\n  - $\frac{\\partial L}{\\partial W^{[2]}} = \frac{\\partial L}{\\partial \\hat{y}} \\cdot \\sigma'(z^{[2]}) \\cdot a^{[1]}$\n  - Lan truyền về hidden layer tương tự\n\n**Computational Graph:**\n\n**Các khái niệm quan trọng:**\n- Backpropagation (Lan Truyền Ngược) là một thuật toán cốt lõi và quan trọng trong việc huấn luyện mạng nơ-ron sâu. Nó được sử dụng để tính toán gradient của hàm loss đối với tất cả các tham số của mạng (weights và biases) một cách hiệu quả. Thuật toán này hoạt động bằng cách lan truyền ngược gradient (hoặc lỗi) từ output layer về input layer thông qua đồ thị tính toán, sử dụng quy tắc chuỗi (chain rule) để phân rã gradient phức tạp thành các phần đơn giản. Quá trình này cho phép cập nhật hiệu quả các tham số của mô hình. Backpropagation bao gồm một forward pass để tính giá trị (activations) và một backward pass để tính gradients. Độ phức tạp tính toán của nó tương đương với forward pass, nhưng cần lưu trữ các activations từ forward pass, dẫn đến yêu cầu về bộ nhớ.\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n\n**Mối quan hệ:**\n- Backpropagation tính toán gradient để cập nhật biases của mạng nơ-ron thông qua các optimizer.\n- Backpropagation tính toán gradient để cập nhật weights của mạng nơ-ron thông qua các optimizer.\n- Gradient Descent cập nhật weights của mô hình bằng cách trừ đi tích của learning rate và gradient của loss theo weights: $W^{[l]} := W^{[l]} - \\alpha \frac{\\partial L}{\\partial W^{[l]}}$.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Học Sâu (Deep Learning)\nBackpropagation có thể được hiểu thông qua đồ thị tính toán (computational graph), trong đó:\n- Mỗi node là một operation\n- Edges mang giá trị và gradients\n- Forward pass tính giá trị, backward pass tính gradients\n\n**Vấn đề Vanishing/Exploding Gradients:**\n- **Vanishing:** Gradient giảm dần khi lan truyền về các lớp đầu → các lớp đầu học chậm\n  - Nguyên nhân: Hàm kích hoạt có đạo hàm nhỏ (sigmoid, tanh)\n  - Giải pháp: ReLU, batch normalization, residual connections\n- **Exploding:** Gradient tăng dần → weights cập nhật quá mạnh, không ổn định\n  - Giải pháp: Gradient clipping, proper weight initialization\n\n**Lưu ý về hiệu suất:**\n- Độ phức tạp tính toán của backpropagation tương đương forward pass\n- Matrix operations có thể vectorize → tính toán hiệu quả trên GPU\n- Cần lưu trữ activations từ forward pass → tốn memory\n\n### Thuật Toán Tối Ưu (Optimization Algorithms)\n\nCác thuật toán tối ưu quyết định cách cập nhật weights để minimize loss function.\n\n**1. Gradient Descent (Hạ Gradient):**\n$$w := w - \\alpha\frac{\\partial L}{\\partial w}$$\n\n**Đặc điểm:**\n- $\\alpha$ (learning rate): Hyperparameter quan trọng nhất\n- Cập nhật dựa trên toàn bộ training set (batch gradient descent)\n\n**Ưu điểm:**\n- Đơn giản, dễ hiểu\n- Hội tụ ổn định với learning rate phù hợp\n- Đảm bảo tìm được local minimum với hàm convex\n\n**Nhược điểm:**\n- Chậm với dữ liệu lớn (phải xử lý toàn bộ dataset mỗi iteration)\n- Có thể bị kẹt ở local minima hoặc saddle points\n- Learning rate cố định không phù hợp mọi giai đoạn training\n\n**2. Stochastic Gradient Descent (SGD):**\n$$w := w - \\alpha\frac{\\partial L_i}{\\partial w}$$\n\n**Đặc điểm:**\n- Cập nhật sau **mỗi** mẫu dữ liệu (sample)\n- Gradient ước lượng từ 1 sample → noisy nhưng nhanh\n\n**Ưu điểm:**\n- Rất nhanh, có thể train trên dữ liệu lớn\n- Noise giúp thoát khỏi local minima\n- Có thể train online (dữ liệu đến liên tục)\n\n**Nhược điểm:**\n- Quá trình hội tụ không ổn định, dao động mạnh\n- Có thể không hội tụ chính xác đến minimum\n- Khó song song hóa (sequential updates)\n\n**3. Mini-batch Gradient Descent:**\n$$w := w - \\alpha\frac{1}{m}\\sum_{i=1}^{m}\frac{\\partial L_i}{\\partial w}$$\n\n**Đặc điểm:**\n- Cập nhật sau một **batch nhỏ** (thường 32, 64, 128, 256)\n- Kết hợp ưu điểm của batch GD và SGD\n- **Là phương pháp được sử dụng phổ biến nhất trong thực tế**\n\n**Ưu điểm:**\n- Tốc độ nhanh, ổn định hơn SGD\n- Có thể vectorize, tận dụng GPU hiệu quả\n- Gradient ổn định hơn SGD nhưng vẫn có noise tốt\n- Batch size là hyperparameter điều chỉnh được\n\n**Lựa chọn batch size:**\n\n**Các khái niệm quan trọng:**\n- Backpropagation (Lan Truyền Ngược) là một thuật toán cốt lõi và quan trọng trong việc huấn luyện mạng nơ-ron sâu. Nó được sử dụng để tính toán gradient của hàm loss đối với tất cả các tham số của mạng (weights và biases) một cách hiệu quả. Thuật toán này hoạt động bằng cách lan truyền ngược gradient (hoặc lỗi) từ output layer về input layer thông qua đồ thị tính toán, sử dụng quy tắc chuỗi (chain rule) để phân rã gradient phức tạp thành các phần đơn giản. Quá trình này cho phép cập nhật hiệu quả các tham số của mô hình. Backpropagation bao gồm một forward pass để tính giá trị (activations) và một backward pass để tính gradients. Độ phức tạp tính toán của nó tương đương với forward pass, nhưng cần lưu trữ các activations từ forward pass, dẫn đến yêu cầu về bộ nhớ.\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n\n**Mối quan hệ:**\n- Backpropagation tính toán gradient để cập nhật biases của mạng nơ-ron thông qua các optimizer.\n- Backpropagation tính toán gradient để cập nhật weights của mạng nơ-ron thông qua các optimizer.\n- Gradient Descent cập nhật weights của mô hình bằng cách trừ đi tích của learning rate và gradient của loss theo weights: $W^{[l]} := W^{[l]} - \\alpha \frac{\\partial L}{\\partial W^{[l]}}$.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Phân Loại (Classification)\n$$P(y=1|x) = \\sigma(\beta^Tx) = \frac{1}{1 + e^{-\beta^Tx}}$$\n- Dự đoán xác suất lớp dương (y=1)\n- Nếu $P(y=1|x) \\geq 0.5$: Dự đoán lớp 1\n- Nếu $P(y=1|x) < 0.5$: Dự đoán lớp 0\n\n**Quyết Định Ranh Giới (Decision Boundary):**\n- Tuyến tính trong không gian đặc trưng: $\beta^Tx = 0$\n- Phi tuyến có thể đạt được bằng polynomial features\n- Ngưỡng quyết định có thể điều chỉnh (không nhất thiết 0.5)\n\n**Hàm Chi Phí (Cross-Entropy Loss):**\n$$J(\beta) = -\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}\\log(h_\beta(x^{(i)})) + (1-y^{(i)})\\log(1-h_\beta(x^{(i)}))]$$\n\n**Lý do không dùng MSE:**\n- MSE với sigmoid tạo hàm non-convex\n- Nhiều cực tiểu địa phương\n- Gradient descent khó hội tụ\n\n**Cross-entropy:**\n- Hàm convex\n- Gradient descent hội tụ toàn cục\n- Phạt nặng dự đoán sai với confidence cao\n\n**Tối Ưu Hóa:**\n- Gradient descent (hoặc các biến thể)\n- Đạo hàm: $\frac{\\partial J}{\\partial\beta_j} = \frac{1}{m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$\n- Giống với linear regression nhưng $h_\beta$ khác\n\n**Regularization trong Logistic Regression:**\n\n**L2 (Ridge):**\n$$J(\beta) = -\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}\\log(h_\beta(x^{(i)})) + (1-y^{(i)})\\log(1-h_\beta(x^{(i)}))] + \frac{\\lambda}{2m}\\sum_{j=1}^{n}\beta_j^2$$\n\n**L1 (Lasso):**\n$$J(\beta) = -\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}\\log(h_\beta(x^{(i)})) + (1-y^{(i)})\\log(1-h_\beta(x^{(i)}))] + \frac{\\lambda}{m}\\sum_{j=1}^{n}|\beta_j|$$\n\n### Phân Loại Đa Lớp\n\n**1. One-vs-Rest (OvR) / One-vs-All (OvA):**\n- Huấn luyện K bộ phân loại nhị phân cho K lớp\n- Mỗi bộ phân loại: Một lớp vs tất cả lớp còn lại\n- Dự đoán: Chọn lớp có confidence cao nhất\n- Ưu điểm: Đơn giản, phù hợp với mọi thuật toán nhị phân\n- Nhược điểm: Mất cân bằng lớp, K mô hình riêng biệt\n\n**Ví dụ:** 3 lớp (A, B, C)\n- Mô hình 1: A vs (B, C)\n- Mô hình 2: B vs (A, C)\n- Mô hình 3: C vs (A, B)\n\n**2. One-vs-One (OvO):**\n- Huấn luyện $\frac{K(K-1)}{2}$ bộ phân loại nhị phân\n- Mỗi cặp lớp có một bộ phân loại\n- Dự đoán: Voting - lớp thắng nhiều nhất\n\n**Các khái niệm quan trọng:**\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n\n**Mối quan hệ:**\n- Gradient Descent cập nhật weights của mô hình bằng cách trừ đi tích của learning rate và gradient của loss theo weights: $W^{[l]} := W^{[l]} - \\alpha \frac{\\partial L}{\\partial W^{[l]}}$.\n\n**Nội dung từ tài liệu:**\n# Học Máy (Machine Learning)\n## Hồi Quy Tuyến Tính (Linear Regression)\n- Giải pháp nếu vi phạm: Biến đổi đặc trưng (log, căn bậc hai, đa thức)\n\n**2. Tính Độc Lập (Independence):**\n- Các quan sát độc lập với nhau\n- Quan trọng với dữ liệu chuỗi thời gian\n- Vi phạm: Tự tương quan (autocorrelation)\n- Kiểm tra: Durbin-Watson test\n\n**3. Phương Sai Đồng Nhất (Homoscedasticity):**\n- Phương sai của phần dư không đổi theo giá trị dự đoán\n- Kiểm tra: Vẽ biểu đồ phần dư vs giá trị dự đoán\n- Nếu vi phạm (heteroscedasticity): Sử dụng weighted least squares hoặc biến đổi log\n\n**4. Tính Chuẩn (Normality):**\n- Phần dư tuân theo phân phối chuẩn\n- Kiểm tra: Q-Q plot, Shapiro-Wilk test\n- Quan trọng cho suy diễn thống kê (khoảng tin cậy, kiểm định giả thuyết)\n\n**5. Không Có Đa Cộng Tuyến (No Multicollinearity):**\n- Các đặc trưng không tương quan cao với nhau\n- Kiểm tra: VIF (Variance Inflation Factor)\n- VIF > 10 cho thấy đa cộng tuyến nghiêm trọng\n- Giải pháp: Loại bỏ đặc trưng tương quan cao, PCA, regularization\n\n**Công Thức VIF:**\n$$VIF_j = \frac{1}{1 - R_j^2}$$\nTrong đó $R_j^2$ là $R^2$ khi hồi quy $x_j$ với các đặc trưng còn lại.\n\n### Tối Ưu Hóa Bằng Gradient Descent\n\nGradient Descent là phương pháp lặp để tìm hệ số tối ưu, đặc biệt hữu ích với dữ liệu lớn.\n\n**Thuật Toán:**\n$$\beta_j := \beta_j - \\alpha\frac{\\partial J(\beta)}{\\partial\beta_j}$$\n\nTrong đó:\n- $\\alpha$ là tốc độ học (learning rate)\n- $\frac{\\partial J(\beta)}{\\partial\beta_j}$ là đạo hàm riêng của hàm chi phí\n\n**Đạo Hàm Riêng:**\n$$\frac{\\partial J(\beta)}{\\partial\beta_j} = \frac{1}{m}\\sum_{i=1}^{m}(h_\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$$\n\n**Các Loại Gradient Descent:**\n\n**1. Batch Gradient Descent:**\n- Sử dụng toàn bộ tập dữ liệu trong mỗi lần cập nhật\n- Ưu điểm: Hội tụ ổn định, tối ưu toàn cục\n- Nhược điểm: Chậm với dữ liệu lớn\n- Công thức cập nhật: $\beta := \beta - \\alpha\nabla J(\beta)$\n\n**2. Stochastic Gradient Descent (SGD):**\n- Sử dụng từng mẫu một để cập nhật\n- Ưu điểm: Nhanh, có thể thoát khỏi cực tiểu địa phương\n- Nhược điểm: Dao động nhiều, không hội tụ chính xác\n- Phù hợp: Dữ liệu rất lớn, học trực tuyến\n\n**3. Mini-batch Gradient Descent:**\n- Sử dụng các batch nhỏ (thường 32-256 mẫu)\n\n**Các khái niệm quan trọng:**\n- Gradient Descent là một thuật toán tối ưu hóa lặp đi lặp lại, cơ bản được sử dụng để tìm cực tiểu (minimize) một hàm mục tiêu (hàm loss hoặc hàm chi phí) bằng cách di chuyển theo hướng ngược lại của gradient của hàm đó. Thuật toán này cập nhật các tham số mô hình (weights $w$, $W^{[l]}$, $b^{[l]}$, hoặc hệ số $\\beta$) theo công thức chung: $w := w - \\alpha \\cdot \\nabla L$ (hoặc $w := w - \\eta \\cdot \\nabla L$, $W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}$, $b^{[l]} := b^{[l]} - \\alpha \\frac{\\partial L}{\\partial b^{[l]}}$, $\\beta_j := \\beta_j - \\alpha \\cdot \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$), trong đó $\\alpha$ (hoặc $\\eta$) là learning rate và $\\nabla L$ (hoặc $\\frac{\\partial L}{\\partial w}$, $\\frac{\\partial J(\\beta)}{\\partial \\beta_j}$) là gradient của hàm loss $L$ (hoặc hàm chi phí $J$) đối với các tham số. Thuật toán này được áp dụng rộng rãi trong huấn luyện các mô hình học máy, đặc biệt là neural networks và Logistic Regression (để cực tiểu hóa Cross-Entropy Loss, với công thức đạo hàm $\\frac{\\partial J}{\\partial \\beta_j} = \\frac{1}{m} \\sum (h_\\beta(x^{(i)}) - y^{(i)})x_j^{(i)}$). Khi cập nhật dựa trên toàn bộ training set (batch gradient descent), nó đảm bảo tìm được local minimum với hàm convex nhưng có thể chậm với dữ liệu lớn và có nguy cơ bị kẹt ở local minima hoặc saddle points. Gradient Descent đặc biệt hữu ích với dữ liệu lớn.\n\n**Mối quan hệ:**\n- Gradient Descent cập nhật weights của mô hình bằng cách trừ đi tích của learning rate và gradient của loss theo weights: $W^{[l]} := W^{[l]} - \\alpha \frac{\\partial L}{\\partial W^{[l]}}$."
        },
        "output_without_context": {
            "question": "Trong quy trình lan truyền ngược, điều gì là cần thiết để cập nhật trọng số của mạng nơ-ron nhằm tối ưu hóa hàm mất mát?",
            "answer": "Gradient của hàm mất mát."
        }
    }
]