{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c3dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lite_llm import LiteLLMService, LiteLLMEmbeddingInput, LiteLLMSetting \n",
    "from pydantic import HttpUrl, SecretStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e22cb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiteLLMService(litellm_setting=LiteLLMSetting(url=HttpUrl('http://localhost:9510/'), token=SecretStr('**********'), model='gemini-2.5-flash', frequency_penalty=0.0, n=1, temperature=0.0, top_p=1.0, max_completion_tokens=10000, dimension=1536, embedding_model='gemini-embedding'), async_client=None, client=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "litellm_service=LiteLLMService(\n",
    "    litellm_setting=LiteLLMSetting(\n",
    "        url=HttpUrl(\"http://localhost:9510\"),\n",
    "        token=SecretStr(\"abc123\"),\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        frequency_penalty=0.0,\n",
    "        n=1,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        max_completion_tokens=10000,\n",
    "        dimension=1536,\n",
    "        embedding_model=\"gemini-embedding\"\n",
    "    )\n",
    ")\n",
    "litellm_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dd4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await litellm_service.embedding_llm_async(\n",
    "    inputs=LiteLLMEmbeddingInput(\n",
    "        text=\"Hello, world!\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acbc55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0253c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 embeddings, each with dimension 1536\n"
     ]
    }
   ],
   "source": [
    "options = [\n",
    "    \"By explicitly computing feature vectors in a higher-dimensional space and then applying a linear SVM.\",\n",
    "    \"By replacing the inner product of mapped feature vectors with a kernel function, avoiding explicit computation in high-dimensional space.\",  # correct\n",
    "    \"By directly adjusting the weights `w` and bias `b` to create a non-linear decision boundary in the input space.\",\n",
    "    \"By reducing the dimensionality of the input data before applying a linear SVM.\"\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get embeddings for each option\n",
    "option_embeddings = []\n",
    "for option in options:\n",
    "    embedding_output = await litellm_service.embedding_llm_async(\n",
    "        inputs=LiteLLMEmbeddingInput(text=option)\n",
    "    )\n",
    "    option_embeddings.append(np.array(embedding_output.embedding))\n",
    "\n",
    "print(f\"Generated {len(option_embeddings)} embeddings, each with dimension {len(option_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63e17509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "def cosine_similarity(vector1: np.ndarray, vector2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Args:\n",
    "        vector1: First vector as numpy array\n",
    "        vector2: Second vector as numpy array\n",
    "    \n",
    "    Returns:\n",
    "        Cosine similarity value between -1 and 1\n",
    "    \"\"\"\n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    \n",
    "    # Calculate magnitudes (L2 norms)\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def compute_similarity_matrix(texts: List[str], embeddings: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute a similarity matrix for a list of text embeddings.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings\n",
    "        embeddings: List of embedding vectors\n",
    "    \n",
    "    Returns:\n",
    "        NxN similarity matrix where N is the number of texts\n",
    "    \"\"\"\n",
    "    n = len(embeddings)\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            similarity_matrix[i, j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0ab60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4x4 Cosine Similarity Matrix:\n",
      "==================================================\n",
      "Option 1: 1.0000  0.8497  0.6905  0.7976  \n",
      "Option 2: 0.8497  1.0000  0.6641  0.7329  \n",
      "Option 3: 0.6905  0.6641  1.0000  0.6729  \n",
      "Option 4: 0.7976  0.7329  0.6729  1.0000  \n",
      "\n",
      "Detailed Matrix with Labels:\n",
      "================================================================================\n",
      "\n",
      "Option 1: By explicitly computing feature vectors in a highe...\n",
      "  vs Option 1: 1.0000\n",
      "  vs Option 2: 0.8497\n",
      "  vs Option 3: 0.6905\n",
      "  vs Option 4: 0.7976\n",
      "\n",
      "Option 2: By replacing the inner product of mapped feature v...\n",
      "  vs Option 1: 0.8497\n",
      "  vs Option 2: 1.0000\n",
      "  vs Option 3: 0.6641\n",
      "  vs Option 4: 0.7329\n",
      "\n",
      "Option 3: By directly adjusting the weights `w` and bias `b`...\n",
      "  vs Option 1: 0.6905\n",
      "  vs Option 2: 0.6641\n",
      "  vs Option 3: 1.0000\n",
      "  vs Option 4: 0.6729\n",
      "\n",
      "Option 4: By reducing the dimensionality of the input data b...\n",
      "  vs Option 1: 0.7976\n",
      "  vs Option 2: 0.7329\n",
      "  vs Option 3: 0.6729\n",
      "  vs Option 4: 1.0000\n",
      "\n",
      "Numpy Array:\n",
      "[[1.         0.84968432 0.69050761 0.79757521]\n",
      " [0.84968432 1.         0.66406493 0.73291624]\n",
      " [0.69050761 0.66406493 1.         0.67288202]\n",
      " [0.79757521 0.73291624 0.67288202 1.        ]]\n",
      "\n",
      "Matrix Shape: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "# Compute the 4x4 similarity matrix\n",
    "similarity_matrix = compute_similarity_matrix(options, option_embeddings)\n",
    "\n",
    "print(\"4x4 Cosine Similarity Matrix:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Print matrix with proper formatting\n",
    "for i in range(len(options)):\n",
    "    row_str = \"\"\n",
    "    for j in range(len(options)):\n",
    "        row_str += f\"{similarity_matrix[i, j]:.4f}  \"\n",
    "    print(f\"Option {i+1}: {row_str}\")\n",
    "\n",
    "print(\"\\nDetailed Matrix with Labels:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Print with option labels for clarity\n",
    "for i, option1 in enumerate(options):\n",
    "    print(f\"\\nOption {i+1}: {option1[:50]}...\")\n",
    "    for j, option2 in enumerate(options):\n",
    "        print(f\"  vs Option {j+1}: {similarity_matrix[i, j]:.4f}\")\n",
    "\n",
    "# Also display as a clean numpy array\n",
    "print(f\"\\nNumpy Array:\\n{similarity_matrix}\")\n",
    "print(f\"\\nMatrix Shape: {similarity_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74af856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from lite_llm import LiteLLMEmbeddingInput, LiteLLMService, LiteLLMSetting\n",
    "from pydantic import HttpUrl, SecretStr\n",
    "\n",
    "litellm_setting=LiteLLMSetting(\n",
    "    url=HttpUrl(\"http://localhost:9510\"),\n",
    "    token=SecretStr(\"abc123\"),\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    frequency_penalty=0.0,\n",
    "    n=1,\n",
    "    temperature=0.0,\n",
    "    top_p=1.0,\n",
    "    max_completion_tokens=10000,\n",
    "    dimension=1536,\n",
    "    embedding_model=\"gemini-embedding\"\n",
    ")\n",
    "\n",
    "litellm_service = LiteLLMService(litellm_setting=litellm_setting)\n",
    "client = chromadb.PersistentClient(path=\"./vector_database/rl2025\")\n",
    "collection = client.get_or_create_collection(name=\"questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b8574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lehoangvu/KLTN/rl2025/mcqs.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"rl2025/mcqs.json\")\n",
    "absolute_path = file_path.resolve()\n",
    "print(absolute_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1d98e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [01:13<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from uuid import uuid4\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "\n",
    "\n",
    "with open(\"/home/lehoangvu/KLTN/services/generation/src/generation/shared/static_files/rl2025/mcqs.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for item in tqdm(data):\n",
    "    embedding = await litellm_service.embedding_llm_async(\n",
    "        inputs=LiteLLMEmbeddingInput(\n",
    "            text=item['question']\n",
    "        )\n",
    "    )\n",
    "    options = [\n",
    "        f\"{key}. {value}\"\n",
    "        for key, value in item['options'].items()\n",
    "    ]\n",
    "    collection.add(\n",
    "        ids=[str(uuid4())],\n",
    "        embeddings=[embedding.embedding],\n",
    "        documents=[item['question']],   # text để search\n",
    "        metadatas=[{\n",
    "            \"options\": \"\\n\".join(options),\n",
    "            \"answer\": item['answer'],\n",
    "            \"explanation\": item['explanation'],\n",
    "        }]\n",
    "    )\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8727082f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['17c7414e-5923-4042-9319-d0cf48f2ad6f',\n",
       "   'a55249c6-1670-4abb-acba-5649f88c7a1c',\n",
       "   '8b244a37-c701-4cfa-834a-6df2e32cbda2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Agent trong học tăng cường là gì?',\n",
       "   'Thành phần nào trong học tăng cường xác định hành vi của agent?',\n",
       "   'Bạn biểu diễn trạng thái của agent trong học tăng cường bằng gì?']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'explanation': 'Agent là một thực thể thực hiện hành động và khám phá môi trường.',\n",
       "    'answer': 'Agent là một thực thể khám phá môi trường.',\n",
       "    'options': 'A. Agent là tình huống mà trong đó phần thưởng được trao đổi\\nB. Agent là một giá trị đơn giản trong học tăng cường.\\nC. Agent là một thực thể khám phá môi trường.'},\n",
       "   {'options': 'A. Chính sách\\nB. Tín hiệu phần thưởng\\nC. Hàm giá trị\\nD. Mô hình môi trường',\n",
       "    'answer': 'Chính sách',\n",
       "    'explanation': 'Chính sách (Policy) xác định hành vi của agent.'},\n",
       "   {'explanation': 'Trạng thái của agent thường được biểu diễn bằng trạng thái Markov.',\n",
       "    'options': 'A. Trạng thái chiết khấu\\nB. Hệ số chiết khấu\\nC. Trạng thái Markov',\n",
       "    'answer': 'Trạng thái Markov'}]],\n",
       " 'distances': [[0.06585059314966202, 0.15563052892684937, 0.1893446296453476]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Agent trong reinforcement learning là gì?\"\n",
    "\n",
    "embeddings = await litellm_service.embedding_llm_async(\n",
    "    inputs=LiteLLMEmbeddingInput(\n",
    "        text=query\n",
    "    )\n",
    ")\n",
    "results = collection.query(\n",
    "    query_embeddings=[embeddings.embedding],\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cf2cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hàm merge trong MergeSort thực hiện hành động chính gì?',\n",
       " 'Tại sao QuickSort thường được ưa thích hơn MergeSort khi sắp xếp mảng trong thực tế?',\n",
       " 'Nguyên tắc mà các thuật toán chia để trị (divide and conquer) sử dụng là gì?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941ce8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Gộp các mảng con đã sắp xếp',\n",
       "  'explanation': 'Hàm merge kết hợp hai mảng con đã sắp xếp thành một mảng duy nhất đã được sắp xếp, đây là bước then chốt để đạt được thứ tự tổng thể.',\n",
       "  'options': 'A. Chia mảng\\nB. Sắp xếp các mảng con\\nC. Gộp các mảng con đã sắp xếp\\nD. So sánh từng phần tử'},\n",
       " {'explanation': 'QuickSort thường được ưa chuộng vì khả năng sắp xếp tại chỗ (in-place), cung cấp độ phức tạp không gian thấp hơn so với MergeSort, vốn cần bộ nhớ phụ để hợp nhất.',\n",
       "  'options': 'A. Độ phức tạp không gian thấp hơn\\nB. Thời gian trung bình nhanh hơn\\nC. Dễ cài đặt hơn\\nD. Đảm bảo sắp xếp ổn định',\n",
       "  'answer': 'Độ phức tạp không gian thấp hơn'},\n",
       " {'explanation': 'Các thuật toán như MergeSort và QuickSort chia dữ liệu thành các phần nhỏ, sắp xếp độc lập các phần đó và sau đó kết hợp chúng để tạo thành kết quả đã sắp xếp.',\n",
       "  'options': 'A. Chia dữ liệu thành các phần nhỏ hơn và sắp xếp từng phần độc lập\\nB. Chọn phần tử ngẫu nhiên\\nC. Duyệt tuyến tính\\nD. Đổi chỗ trực tiếp các phần tử',\n",
       "  'answer': 'Chia dữ liệu thành các phần nhỏ hơn và sắp xếp từng phần độc lập'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['metadatas'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
