litellm:
  model: "gemini-2.5-flash"
  temperature: 0.0
  top_p: 1.0
  n: 1
  frequency_penalty: 0.0
  max_completion_tokens: 10000
  dimension: 1024
  embedding_model: "qwen3-embedding:0.6b"

quiz: 
  concept_card_extractor:
    model: "gemini-2.5-flash"
    temperature: 0.0
    top_p: 1.0
    n: 1
    frequency_penalty: 0.0
    max_completion_tokens: 10000

  topic_generator:
    model: "gemini-2.5-flash"
    temperature: 0.5
    top_p: 1.0
    n: 1
    frequency_penalty: 0.0
    max_completion_tokens: 10000
    reasoning_effort: "medium"

  question_answer_generator:
    model: "gemini-2.5-flash"
    temperature: 0.5
    top_p: 1.0
    n: 1
    frequency_penalty: 0.0
    max_completion_tokens: 10000
    reasoning_effort: "medium"

  distractors_generator:
    model: "gemini-2.5-flash"
    temperature: 0.5
    top_p: 1.0
    n: 1
    frequency_penalty: 0.0
    max_completion_tokens: 10000
    reasoning_effort: "medium"

  explanation_generator:
    model: "gemini-2.5-flash"
    temperature: 0.0
    top_p: 1.0
    n: 1
    frequency_penalty: 0.0
    max_completion_tokens: 10000

  validator:
    factual:
      model: "gemini-2.5-flash"
      temperature: 0.0
      top_p: 1.0
      n: 1
      frequency_penalty: 0.0
      max_completion_tokens: 10000
    pedagogical:
      model: "gemini-2.5-flash"
      temperature: 0.0
      top_p: 1.0
      n: 1
      frequency_penalty: 0.0
      max_completion_tokens: 10000
    psychometric:
      model: "gemini-2.5-flash"
      temperature: 0.0
      top_p: 1.0
      n: 1
      frequency_penalty: 0.0
      max_completion_tokens: 10000

  correction:
    model: "gemini-2.5-flash"
    temperature: 0.0
    top_p: 1.0
    n: 1
    frequency_penalty: 0.0
    max_completion_tokens: 10000
    reasoning_effort: "medium"

  max_feedback_attempts: 3

  acceptance_score_threshold: 80

  max_concurrent_tasks: 8